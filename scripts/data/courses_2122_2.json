{"Bioinfo": {"supervisions": 3, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Bioinformatics.html", "description": "<h2>Aims</h2>\n<p>This course focuses on algorithms used in Bioinformatics and\n  System Biology. Most of the algorithms are general and can be\n  applied in other fields on multidimensional and noisy data. All\n  the necessary biological terms and concepts useful for the course\n  and the examination will be given in the lectures. The most\n  important software implementing the described algorithms will be\n  demonstrated.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction to biological data:</strong>\n    Bioinformatics as an interesting field in computer science.\n    Computing and storing information with DNA (including Adleman\u2019s\n    experiment).</li>\n<li><strong>Dynamic programming.</strong> Longest common\n    subsequence, DNA global and local alignment, linear space\n    alignment, Nussinov algorithm for RNA, heuristics for multiple\n    alignment. (Vol. 1, chapter 5)</li>\n<li><strong>Sequence database search.</strong> Blast. (see\n    notes and textbooks)</li>\n<li><strong>Genome sequencing.</strong> De Bruijn graph. (Vol.\n    1, chapter 3)</li>\n<li><strong>Phylogeny.</strong> Distance based algorithms\n    (UPGMA, Neighbour-Joining). Parsimony-based algorithms.\n    Examples in Computer Science. (Vol. 2, chapter 7)</li>\n<li><strong>Clustering.</strong> Hard and soft K-means\n    clustering, use of Expectation Maximization in clustering,\n    Hierarchical clustering, Markov clustering algorithm. (Vol. 2,\n    chapter 8)</li>\n<li><strong>Genomics Pattern Matching.</strong> Suffix Tree\n    String Compression and the Burrows-Wheeler Transform. (Vol. 2,\n    chapter 9)</li>\n<li><strong>Hidden Markov Models.</strong> The Viterbi\n    algorithm, profile HMMs for sequence alignment, classifying\n    proteins with profile HMMs, soft decoding problem, Baum-Welch\n    learning. (Vol. 2, chapter 10)</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of this course students should</p>\n<ul>\n<li>understand Bioinformatics terminology;</li>\n<li>have mastered the most important algorithms in the\n    field;</li>\n<li>be able to work with bioinformaticians and biologists;</li>\n<li>be able to find data and literature in repositories.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>* Compeau, P. and Pevzner, P.A. (2015). <em>Bioinformatics\n  algorithms: an active learning approach</em>. Active Learning\n  Publishers.<br/>\n  Durbin, R., Eddy, S., Krough, A. and Mitchison, G. (1998).\n  <em>Biological sequence analysis: probabilistic models of\n  proteins and nucleic acids</em>. Cambridge University Press.<br/>\n  Jones, N.C. and Pevzner, P.A. (2004). <em>An introduction to\n  bioinformatics algorithms</em>. MIT Press.<br/>\n  Felsenstein, J. (2003). <em>Inferring phylogenies</em>. Sinauer\n  Associates.</p>\n", "course_name": "Bioinformatics", "course_code": "Bioinfo", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/Bioinfo", "lecturers": ["pl219"], "lectures": 12, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "Business": {"supervisions": 2, "prerequisite_for": ["ECommerce"], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-BusinessStudies.html", "description": "<h2>Aims</h2>\n<p>How to start and run a computer company; the aims of this\n  course are to introduce students to all the things that go to\n  making a successful project or product other than just the\n  programming. The course will survey some of the issues that\n  students are likely to encounter in the world of commerce and\n  that need to be considered when setting up a new computer\n  company.</p>\n<p>See also Business Seminars in the Easter Term.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>So you\u2019ve got an idea?</strong> Introduction. Why\n    are you doing it and what is it? Types of company. Market\n    analysis. The business plan.</li>\n<li><strong>Money and tools for its management.</strong>\n    Introduction to accounting: profit and loss, cash flow, balance\n    sheet, budgets. Sources of finance. Stocks and shares. Options\n    and futures.</li>\n<li><strong>Setting up: legal aspects.</strong> Company\n    formation. Brief introduction to business law; duties of\n    directors. Shares, stock options, profit share schemes and the\n    like. Intellectual Property Rights, patents, trademarks and\n    copyright. Company culture and management theory.</li>\n<li><strong>People.</strong> Motivating factors. Groups and\n    teams. Ego. Hiring and firing: employment law. Interviews.\n    Meeting techniques.</li>\n<li><strong>Project planning and management.</strong> Role of a\n    manager. PERT and GANTT charts, and critical path analysis.\n    Estimation techniques. Monitoring.</li>\n<li><strong>Quality, maintenance and documentation.</strong>\n    Development cycle. Productization. Plan for quality. Plan for\n    maintenance. Plan for documentation.</li>\n<li><strong>Marketing and selling.</strong> Sales and marketing\n    are different. Marketing; channels; marketing communications.\n    Stages in selling. Control and commissions.</li>\n<li><strong>Growth and exit routes.</strong> New markets:\n    horizontal and vertical expansion. Problems of growth; second\n    system effects. Management structures. Communication. Exit\n    routes: acquisition, floatation, MBO or liquidation. Futures:\n    some emerging ideas for new computer businesses. Summary.\n    Conclusion: now you do it!</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>be able to write and analyse a business plan;</li>\n<li>know how to construct PERT and GANTT diagrams and perform\n    critical path analysis;</li>\n<li>appreciate the differences between profitability and cash\n    flow, and have some notion of budget estimation;</li>\n<li>have an outline view of company formation, share structure,\n    capital raising, growth and exit routes;</li>\n<li>have been introduced to concepts of team formation and\n    management;</li>\n<li>know about quality documentation and productization\n    processes;</li>\n<li>understand the rudiments of marketing and the sales\n    process.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Lang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook:\n  how to start and run a high-tech company</em>.\n  FT.COM/Prentice\u00a0Hall.</p>\n<p>Students will be expected to be able to use Microsoft Excel\n  and Microsoft Project.</p>\n<p>For additional reading on a lecture-by-lecture basis, please\n  see the course website.</p>\n<p>Students are strongly recommended to enter the CU\n  Entrepreneurs Business Ideas Competition <a href=\"http://www.cue.org.uk/\" id=\"tex2html16\" name=\"tex2html16\">http://www.cue.org.uk/</a></p>\n", "course_name": "Business Studies", "course_code": "Business", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/Business", "lecturers": [], "lectures": 8, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "DenotSem": {"supervisions": 2, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-DenotationalSemantics.html", "description": "<h2>Aims</h2>\n<p>The aims of this course are to introduce domain theory and\n  denotational semantics, and to show how they provide a\n  mathematical basis for reasoning about the behaviour of\n  programming languages.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction.</strong>The denotational approach to\n    the semantics of programming languages.Recursively defined\n    objects as limits of successive approximations.</li>\n<li><strong>Least fixed points.</strong>Complete partial\n    orders\u00a0(cpos) and least elements.Continuous functions and\n    least fixed points.</li>\n<li><strong>Constructions on domains.</strong>Flat\n    domains.Product domains. Function domains.</li>\n<li><strong>Scott induction.</strong>Chain-closed and\n    admissible subsets of cpos and domains.Scott\u2019s fixed-point\n    induction principle.</li>\n<li><strong>PCF.</strong>The Scott-Plotkin\n    language\u00a0PCF.Evaluation. Contextual equivalence.</li>\n<li><strong>Denotational semantics of PCF.</strong>Denotation\n    of types and terms. Compositionality. Soundness with respect to\n    evaluation. [2\u00a0lectures].</li>\n<li><strong>Relating denotational and operational\n    semantics.</strong>Formal approximation relation and its\n    fundamental property.Computational adequacy of the PCF\n    denotational semantics with respect to evaluation.\n    Extensionality properties of contextual equivalence.\n    [2\u00a0lectures].</li>\n<li><strong>Full abstraction.</strong>Failure of full\n    abstraction for the domain model. PCF with\n    parallel\u00a0or.</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>be familiar with basic domain theory: cpos, continuous\n    functions, admissible subsets, least fixed points, basic\n    constructions on domains;</li>\n<li>be able to give denotational semantics to simple\n    programming languages with simple types;</li>\n<li>be able to apply denotational semantics; in particular, to\n    understand the use of least fixed points to model recursive\n    programs and be able to reason about least fixed points and\n    simple recursive programs using fixed point induction;</li>\n<li>understand the issues concerning the relation between\n    denotational and operational semantics, adequacy and full\n    abstraction, especially with respect to the\n    language\u00a0PCF.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Winskel, G. (1993). <em>The formal semantics of programming\n  languages: an introduction</em>. MIT Press.<br/>\n  Gunter, C. (1992). <em>Semantics of programming languages:\n  structures and techniques</em>. MIT Press.<br/>\n  Tennent, R. (1991). <em>Semantics of programming languages</em>.\n  Prentice Hall.</p>\n", "course_name": "Denotational Semantics", "course_code": "DenotSem", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/DenotSem", "lecturers": ["mpf23"], "lectures": 10, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "TeX+MATLAB": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Introduction to two widely-used languages for typesetting\n  dissertations and scientific publications, for prototyping\n  numerical algorithms and to visualize results.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>L<sup>A</sup>T<sub>E</sub>X.</strong>\u00a0Workflow\n    example, syntax, typesetting conventions, non-ASCII characters,\n    document structure, packages, mathematical typesetting,\n    graphics and figures, cross references, build tools.</li>\n<li><strong>MATLAB.</strong>\u00a0Tools for technical computing\n    and visualization. The matrix type and its operators, 2D/3D\n    plotting, common functions, function definitions, toolboxes,\n    vectorized audio demonstration.</li>\n</ul>\n<h2>Objectives</h2>\n<p>Students should be able to avoid the most\n  common\u00a0L<sup>A</sup>T<sub>E</sub>X\u00a0mistakes, to\n  prototype simple image and signal processing algorithms in\n  MATLAB, and to visualize the results.</p>\n<h2>Recommended reading</h2>\n<p>* Lamport, L.\n  (1994).\u00a0<em>L<sup>A</sup>T<sub>E</sub>X\u00a0\u2013 a\n  documentation preparation system user\u2019s guide and reference\n  manual</em>. Addison-Wesley (2nd ed.).<br/>\n  Mittelbach, F., et al.\n  (2004).\u00a0<em>The\u00a0L<sup>A</sup>TEX\u00a0companion</em>.\n  Addison-Wesley (2nd ed.).</p>\n", "course_name": "LaTeX and MATLAB", "course_code": "TeX+MATLAB", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/TeX+MATLAB", "lecturers": ["mgk25"], "lectures": 2, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "PrincComm": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-PrinciplesofCommunications.html", "description": "<h2>Aims</h2>\n<p>This course aims to provide a detailed understanding of the\n  underlying principles for how communications systems operate.\n  Practical examples (from wired and wireless communications, the\n  Internet, and other communications systems) are used to\n  illustrate the principles.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction.</strong> Course overview.\n    Abstraction, layering. Review of structure of real networks,\n    links, end systems and switching systems. [1\u00a0lecture]</li>\n<li><strong>Routing.</strong> Central versus Distributed\n    Routing Policy Routing. Multicast Routing Circuit Routing\n    [6\u00a0lectures]</li>\n<li><strong>Flow control and resource optimisation.</strong>\n<sup><a href=\"#footnote-1\">1</a></sup>[Control theory] is a\n    branch of engineering familiar to people building dynamic\n    machines. It can be applied to network traffic. Stemming the\n    flood, at source, sink, or in between? Optimisation as a model\n    of networkand user. TCP in the wild. [3\u00a0lectures]</li>\n<li><strong>Packet Scheduling.</strong> Design choices for\n    scheduling and queue management algorithms for packet\n    forwarding, and fairness. [2\u00a0lectures]</li>\n<li><strong>The big picture for managing traffic.</strong>\n    Economics and policy are relevant to networks in many ways.\n    Optimisation and game theory are both relevant topics discussed\n    here. [2\u00a0lectures]</li>\n<li><strong>System Structures and Summary.</strong>\n    Abstraction, layering. The structure of real networks, links,\n    end systems and switching. [2\u00a0lectures]</li>\n</ul>\n<p><sup>1</sup> Control theory was not taught and will not be the\n  subject of any exam question.</p>\n<h2>Objectives</h2>\n<p>At the end of the course students should be able to explain\n  the underlying design and behaviour of protocols and networks,\n  including capacity, topology, control and use. Several specific\n  mathematical approaches are covered (control theory,\n  optimisation).</p>\n<h2>Recommended reading</h2>\n<p>* Keshav, S. (2012). <em>Mathematical Foundations of Computer\n  Networking</em>. Addison Wesley. ISBN 9780321792105<br/>\n  Background reading:<br/>\n  Keshav, S. (1997). <em>An engineering approach to computer\n  networking</em>. Addison-Wesley (1st ed.). ISBN 0201634422<br/>\n  Stevens, W.R. (1994). <em>TCP/IP illustrated, vol.\u00a01: the\n  protocols</em>. Addison-Wesley (1st ed.). ISBN 0201633469</p>\n", "course_name": "Principles of Communications", "course_code": "PrincComm", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/PrincComm", "lecturers": ["jac22"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "Types": {"supervisions": 3, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Types.html", "description": "<h2>Aims</h2>\n<p>The aim of this course is to show by example how type systems\n  for programming languages can be defined and their properties\n  developed, using techniques that were introduced in the\n  Part\u00a0IB course on <em>Semantics of Programming\n  Languages</em>. The emphasis is on type systems for functional\n  languages and their connection to constructive logic.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction.</strong> The role of type systems in\n    programming languages. Review of rule-based formalisation of\n    type systems. [1\u00a0lecture]</li>\n<li><strong>Propositions as types.</strong> The Curry-Howard\n    correspondence between intuitionistic propositional calculus\n    and simply-typed lambda calculus. Inductive types and\n    iteration. Consistency and termination. [2\u00a0lectures]</li>\n<li><strong>Polymorphic lambda calculus (PLC).</strong> PLC\n    syntax and reduction semantics. Examples of datatypes definable\n    in the polymorphic lambda calculus. Type inference.\n    [3\u00a0lectures]</li>\n<li><strong>Monads and effects</strong>. Explicit versus\n    implicit effects. Using monadic types to control effects.\n    References and polymorphism. Recursion and looping.\n    [2\u00a0lectures]</li>\n<li><strong>Continuations and classical logic</strong>.\n    First-class continuations and control operators. Continuations\n    as Curry-Howard for classical logic. Continuation-passing\n    style. [2\u00a0lectures]</li>\n<li><strong>Dependent types.</strong> Dependent function types.\n    Indexed datatypes. Equality types and combining proofs with\n    programming. [2\u00a0lectures]</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>be able to use a rule-based specification of a type system\n    to carry out type checking and type inference;</li>\n<li>understand by example the Curry-Howard correspondence\n    between type systems and logics;</li>\n<li>understand how types can be used to control side-effects in\n    programming;</li>\n<li>appreciate the expressive power of parametric polymorphism\n    and dependent types.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>* Pierce, B.C. (2002). <em>Types and programming\n  languages</em>. MIT Press.<br/>\n  Pierce, B. C. (Ed.) (2005). <em>Advanced Topics in Types and\n  Programming Languages</em>. MIT Press.<br/>\n  Girard, J-Y. (tr. Taylor, P. and Lafont, Y.) (1989). <em>Proofs\n  and types</em>. Cambridge University Press.</p>\n", "course_name": "Types", "course_code": "Types", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/Types", "lecturers": ["nk480"], "lectures": 12, "year": "2122", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "AdComArch": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-AdvancedComputerArchitecture.html", "description": "<h2>Aims</h2>\n<p>This course examines the techniques and underlying principles\n  that are used to design high-performance computers and\n  processors. Particular emphasis is placed on understanding the\n  trade-offs involved when making design decisions at the\n  architectural level. A range of processor architectures are\n  explored and contrasted. In each case we examine their merits and\n  limitations and how ultimately the ability to scale performance\n  is restricted.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction</strong>. The impact of technology\n    scaling and market trends.</li>\n<li><strong>Fundamentals of Computer Design</strong>. Amdahl\u2019s\n    law, energy/performance trade-offs, ISA design.</li>\n<li><strong>Advanced pipelining</strong>. Pipeline hazards;\n    exceptions; optimal pipeline depth; branch prediction; the\n    branch target buffer [2\u00a0lectures]</li>\n<li><strong>Superscalar techniques</strong>. Instruction-Level\n    Parallelism (ILP); superscalar processor architecture\n    [2\u00a0lectures]</li>\n<li><strong>Software approaches to exploiting ILP</strong>.\n    VLIW architectures; local and global instruction scheduling\n    techniques; predicated instructions and support for speculative\n    compiler optimisations.</li>\n<li><strong>Multithreaded processors</strong>. Coarse-grained,\n    fine-grained, simultaneous multithreading</li>\n<li><strong>The memory hierarchy</strong>. Caches; programming\n    for caches; prefetching [2\u00a0lectures]</li>\n<li><strong>Vector processors</strong>. Vector machines; short\n    vector/SIMD instruction set extensions; stream processing</li>\n<li><strong>Chip multiprocessors</strong>. The communication\n    model; memory consistency models; false sharing; multiprocessor\n    memory hierarchies; cache coherence protocols; synchronization\n    [2\u00a0lectures]</li>\n<li><strong>On-chip interconnection networks</strong>.\n    Bus-based interconnects; on-chip packet switched networks</li>\n<li><strong>Special-purpose architectures</strong>. Converging\n    approaches to computer design</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>understand what determines processor design goals;</li>\n<li>appreciate what constrains the design process and how\n    architectural trade-offs are made within these\n    constraints;</li>\n<li>be able to describe the architecture and operation of\n    pipelined and superscalar processors, including techniques such\n    as branch prediction, register renaming and out-of-order\n    execution;</li>\n<li>have an understanding of vector, multithreaded and\n    multi-core processor architectures;</li>\n<li>for the architectures discussed, understand what ultimately\n    limits their performance and application domain.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>* Hennessy, J. and Patterson, D. (2012). <em>Computer\n  architecture: a quantitative approach</em>. Elsevier (5th ed.)\n  ISBN\u00a09780123838728. (the 3rd and 4th editions are also\n  good)</p>\n", "course_name": "Advanced Computer Architecture", "course_code": "AdComArch", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/AdComArch", "lecturers": ["rdm34"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "Crypto": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Cryptography.html", "description": "<h2>Aims</h2>\n<p>This course provides an overview of basic modern cryptographic\n  techniques and covers essential concepts that users of\n  cryptographic standards need to understand to achieve their\n  intended security goals.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Cryptography.</strong> Overview, private vs.\n    public-key ciphers, MACs vs. signatures, certificates,\n    capabilities of adversary, Kerckhoffs\u2019 principle.</li>\n<li><strong>Classic ciphers.</strong> Attacks on substitution\n    and transposition ciphers, Vigen\u00e9re. Perfect secrecy: one-time\n    pads.</li>\n<li><strong>Private-key encryption.</strong> Stream ciphers,\n    pseudo-random generators, attacking linear-congruential RNGs\n    and LFSRs. Semantic security definitions, oracle queries,\n    advantage, computational security, concrete-security\n    proofs.</li>\n<li><strong>Block ciphers.</strong> Pseudo-random functions and\n    permutations. Birthday problem, random mappings.\n    Feistel/Luby-Rackoff structure, DES, TDES, AES.</li>\n<li><strong>Chosen-plaintext attack security.</strong> Security\n    with multiple encryptions, randomized encryption. Modes of\n    operation: ECB, CBC, OFB, CNT.</li>\n<li><strong>Message authenticity.</strong> Malleability, MACs,\n    existential unforgeability, CBC-MAC, ECBC-MAC, CMAC, birthday\n    attacks, Carter-Wegman one-time MAC.</li>\n<li><strong>Authenticated encryption.</strong>\n    Chosen-ciphertext attack security, ciphertext integrity,\n    encrypt-and-authenticate, authenticate-then-encrypt,\n    encrypt-then-authenticate, padding oracle example, GCM.</li>\n<li><strong>Secure hash functions.</strong> One-way functions,\n    collision resistance, padding, Merkle-Damg\u00e5rd construction,\n    sponge function, duplex construct, entropy pool, SHA\n    standards.</li>\n<li><strong>Applications of secure hash functions.</strong>\n    HMAC, stream authentication, Merkle tree, commitment protocols,\n    block chains, Bitcoin.</li>\n<li><strong>Key distribution problem.</strong>\n    Needham-Schroeder protocol, Kerberos, hardware-security\n    modules, public-key encryption schemes, CPA and CCA security\n    for asymmetric encryption.</li>\n<li><strong>Number theory, finite groups and fields.</strong>\n    Modular arithmetic, Euclid\u2019s algorithm, inversion, groups,\n    rings, fields, GF(2<sup>n</sup>), subgroup order, cyclic\n    groups, Euler\u2019s theorem, Chinese remainder theorem, modular\n    roots, quadratic residues, modular exponentiation, easy and\n    difficult problems. [2 lectures]</li>\n<li><strong>Discrete logarithm problem.</strong>\n    Baby-step-giant-step algorithm, computational and decision\n    Diffie-Hellman problem, DH key exchange, ElGamal encryption,\n    hybrid cryptography, Schnorr groups, elliptic-curve systems,\n    key sizes. [2 lectures]</li>\n<li><strong>Trapdoor permutations.</strong> Security\n    definition, turning one into a public-key encryption scheme,\n    RSA, attacks on \u201ctextbook\u201d RSA, RSA as a trapdoor permutation,\n    optimal asymmetric encryption padding, common factor\n    attacks.</li>\n<li><strong>Digital signatures.</strong> One-time signatures,\n    RSA signatures, Schnorr identification scheme, ElGamal\n    signatures, DSA, PS3 hack, certificates, PKI.</li>\n</ul>\n<h2>Objectives</h2>\n<p>By the end of the course students should</p>\n<ul>\n<li>be familiar with commonly used standardized cryptographic\n    building blocks;</li>\n<li>be able to match application requirements with concrete\n    security definitions and identify their absence in naive\n    schemes;</li>\n<li>understand various adversarial capabilities and basic\n    attack algorithms and how they affect key sizes;</li>\n<li>understand and compare the finite groups most commonly used\n    with discrete-logarithm schemes;</li>\n<li>understand the basic number theory underlying the most\n    common public-key schemes, and some efficient implementation\n    techniques.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Katz, J., Lindell, Y. (2015). <em>Introduction to modern\n  cryptography</em>. Chapman and Hall/CRC (2nd ed.).</p>\n", "course_name": "Cryptography", "course_code": "Crypto", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/Crypto", "lecturers": ["mk428"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "ECommerce": {"supervisions": 2, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-E-Commerce.html", "description": "<h2>Aims</h2>\n<p>This course aims to give students an outline of the issues\n  involved in setting up an e-commerce site.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>The history of electronic commerce.</strong> Mail\n    order; EDI; web-based businesses, credit card processing, PKI,\n    identity and other hot topics.</li>\n<li><strong>Network economics.</strong> Real and virtual\n    networks, supply-side <em>versus</em> demand-side scale\n    economies, Metcalfe\u2019s law, the dominant firm model, the\n    differentiated pricing model Data Protection Act, Distance\n    Selling regulations, business models.</li>\n<li><strong>Web site design.</strong> Stock and price control;\n    domain names, common mistakes, dynamic pages, transition\n    diagrams, content management systems, multiple targets.</li>\n<li><strong>Web site implementation.</strong> Merchant systems,\n    system design and sizing, enterprise integration, payment\n    mechanisms, CRM and help desks. Personalisation and\n    internationalisation.</li>\n<li><strong>The law and electronic commerce.</strong> Contract\n    and tort; copyright; binding actions; liabilities and remedies.\n    Legislation: RIP; Data Protection; EU Directives on Distance\n    Selling and Electronic Signatures.</li>\n<li><strong>Putting it into practice.</strong> Search engine\n    interaction, driving and analysing traffic; dynamic pricing\n    models. Integration with traditional media. Logs and audit,\n    data mining modelling the user. collaborative filtering and\n    affinity marketing brand value, building communities, typical\n    behaviour.</li>\n<li><strong>Finance.</strong> How business plans are put\n    together. Funding Internet ventures; the recent hysteria;\n    maximising shareholder value. Future trends.</li>\n<li><strong>UK and International Internet Regulation.</strong>\n    Data Protection Act and US Privacy laws; HIPAA, Sarbanes-Oxley,\n    Security Breach Disclosure, RIP Act 2000, Electronic\n    Communications Act 2000, Patriot Act, Privacy Directives, data\n    retention; specific issues: deep linking, Inlining, brand\n    misuse, phishing.</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should know how to apply\n  their computer science skills to the conduct of e-commerce with\n  some understanding of the legal, security, commercial, economic,\n  marketing and infrastructure issues involved.</p>\n<h2>Recommended reading</h2>\n<p>Shapiro, C. and Varian, H. (1998). <em>Information rules</em>.\n  Harvard Business School Press.</p>\n<p>Additional reading:</p>\n<p>Standage, T. (1999). <em>The Victorian Internet</em>. Phoenix\n  Press. Klemperer, P. (2004). <em>Auctions: theory and\n  practice</em>. Princeton Paperback ISBN 0-691-11925-2.</p>\n", "course_name": "E-Commerce", "course_code": "ECommerce", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/ECommerce", "lecturers": [], "lectures": 8, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "InfoTheory": {"supervisions": 3, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-InformationTheory.html", "description": "<h2>Aims</h2>\n<p>This course introduces the principles and applications of\n  information theory: how information is measured in terms of\n  probability and various entropies, how these are used to\n  calculate the capacity of communication channels, with or without\n  noise, and to measure how much random variables reveal about each\n  other. Coding schemes including error correcting codes are\n  studied along with data compression, spectral analysis,\n  transforms, and wavelet coding. Applications of information\n  theory are reviewed, from astrophysics to pattern\n  recognition.</p>\n<h2>Lectures</h2>\n<ul>\n<li style=\"list-style-type:disc\"><strong>Information,\n    probability, uncertainty, and surprise.</strong> How concepts\n    of randomness and uncertainty are related to information. How\n    the metrics of information are grounded in the rules of\n    probability. Shannon Information. Weighing problems and other\n    examples.</li>\n<li><strong>Entropy of discrete variables.</strong> Definition\n    and link to Shannon information. Joint entropy, Mutual\n    information. Visual depictions of the relationships between\n    entropy types. Why entropy gives fundamental measures of\n    information content.</li>\n<li><strong>Source coding theorem and data compression; prefix,\n    variable-, and fixed-length codes.</strong> Information rates;\n    Asymptotic equipartition principle; Symbol codes; Huffman codes\n    and the prefix property. Binary symmetric channels. Capacity of\n    a noiseless discrete channel. Stream codes.</li>\n<li><strong>Noisy discrete channel coding.</strong> Joint\n    distributions; mutual information; Conditional Entropy;\n    Error-correcting codes; Capacity of a discrete channel. Noisy\n    channel coding theorem.</li>\n<li><strong>Entropy of continuous variables.</strong>\n    Differential entropy; Mutual information; Channel Capacity;\n    Gaussian channels.</li>\n<li><strong>Entropy for comparing probability distributions and\n    for machine learning.</strong> Relative entropy/KL divergence;\n    cross-entropy; use as loss function.</li>\n<li><strong>Applications of information theory in other\n    sciences.\u00a0</strong></li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should be able to</p>\n<ul>\n<li>calculate the information content of a random variable from\n    its probability distribution;</li>\n<li>relate the joint, conditional, and marginal entropies of\n    variables in terms of their coupled probabilities;</li>\n<li>define channel capacities and properties using Shannon\u2019s\n    Theorems;</li>\n<li>construct efficient codes for data on imperfect\n    communication channels;</li>\n<li>generalize the discrete concepts to continuous signals on\n    continuous channels;</li>\n<li>understand encoding and communication schemes in terms of\n    the spectral properties of signals and channels;</li>\n<li>describe compression schemes, and efficient coding using\n    wavelets and other representations for data.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p><span style=\"font-size:11.0pt\"><span style='font-family:\"Calibri\",sans-serif'>\u00a0 Mackay's\n  <em>Information Theory, inference and Learning\n  Algorithms</em></span></span></p>\n<p><span style=\"font-size:11.0pt\"><span style='font-family:\"Calibri\",sans-serif'>\u00a0Stone's\n  <em>Information Theory: A Tutorial\n  Introduction</em>.</span></span></p>\n", "course_name": "Information Theory", "course_code": "InfoTheory", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/InfoTheory", "lecturers": ["rkh23"], "lectures": 12, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "MLBayInfer": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-MachineLearningandBayesianInference.html", "description": "<h2>Aims</h2>\n<p>The Part 1B course <em>Artificial Intelligence</em> introduced\n  simple neural networks for supervised learning, and logic-based\n  methods for knowledge representation and reasoning. This course\n  has two aims. First, to provide a rigorous introduction to\n  machine learning, moving beyond the supervised case and\n  ultimately presenting state-of-the-art methods. Second, to\n  provide an introduction to the wider area of probabilistic\n  methods for representing and reasoning with knowledge.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction to learning and inference.</strong>\n    Supervised, unsupervised, semi-supervised and reinforcement\n    learning. Bayesian inference in general. What the naive Bayes\n    method actually does. Review of backpropagation. Other kinds of\n    learning and inference. [1 lecture]</li>\n<li><strong>How to classify optimally.</strong> Treating\n    learning probabilistically. Bayesian decision theory and Bayes\n    optimal classification. Likelihood functions and priors. Bayes\n    theorem as applied to supervised learning. The maximum\n    likelihood and maximum <em>a posteriori</em> hypotheses. What\n    does this teach us about the backpropagation algorithm? [2\n    lectures]</li>\n<li><strong>Linear classifiers I.</strong> Supervised learning\n    via error minimization. Iterative reweighted least squares. The\n    maximum margin classifier. [2 lectures]</li>\n<li><strong>Gaussian processes.</strong> Learning and inference\n    for regression using Gaussian process models. [2 lectures]</li>\n<li><strong>Support vector machines (SVMs).</strong> The kernel\n    trick. Problem formulation. Constrained optimization and the\n    dual problem. SVM algorithm. [2 lectures]</li>\n<li><strong>Practical issues.</strong> Hyperparameters.\n    Measuring performance. Cross-validation. Experimental methods.\n    [1 lecture]</li>\n<li><strong>Linear classifiers II.</strong> The Bayesian\n    approach to neural networks. [1 lecture]</li>\n<li><strong>Unsupervised learning I.</strong> The\n    <em>k</em>-means algorithm. Clustering as a maximum likelihood\n    problem. [1 lecture]</li>\n<li><strong>Unsupervised learning II.</strong> The EM algorithm\n    and its application to clustering. [1 lecture]</li>\n<li><strong>Bayesian networks I.</strong> Representing\n    uncertain knowledge using Bayesian networks. Conditional\n    independence. Exact inference in Bayesian networks. [2\n    lectures]</li>\n<li><strong>Bayesian networks II.</strong> Markov random\n    fields. Approximate inference. Markov chain Monte Carlo\n    methods. [1 lecture]</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of this course students should:</p>\n<ul>\n<li>Understand how learning and inference can be captured\n    within a probabilistic framework, and know how probability\n    theory can be applied in practice as a means of handling\n    uncertainty in AI systems.</li>\n<li>Understand several algorithms for machine learning and\n    apply those methods in practice with proper regard for good\n    experimental practice.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>If you are going to buy a single book for this course I\n  recommend:</p>\n<p>* Bishop, C.M. (2006). Pattern recognition and machine\n  learning. Springer.</p>\n<p>The course text for Artificial Intelligence I:</p>\n<p>Russell, S. and Norvig, P. (2010). Artificial intelligence: a\n  modern approach. Prentice\u00a0Hall (3rd ed.).</p>\n<p>covers some relevant material but often in insufficient\n  detail. Similarly:</p>\n<p>Mitchell, T.M. (1997). Machine Learning. McGraw-Hill.</p>\n<p>gives a gentle introduction to some of the course material,\n  but only an introduction.</p>\n<p>Recently a few new books have appeared that cover a lot of\n  relevant ground well. For example:</p>\n<p>Barber, D. (2012). Bayesian Reasoning and Machine Learning.\n  Cambridge University Press.<br/>\n  Flach, P. (2012). Machine Learning: The Art and Science of\n  Algorithms that Make Sense of Data. Cambridge University\n  Press.<br/>\n  Murphy, K.P. (2012). Machine Learning: A Probabilistic\n  Perspective. MIT Press.</p>\n", "course_name": "Machine Learning and Bayesian Inference", "course_code": "MLBayInfer", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/MLBayInfer", "lecturers": ["sbh11"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "OptComp": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-OptimisingCompilers.html", "description": "<h2>Aims</h2>\n<p>The aims of this course are to introduce the principles of\n  program optimisation and related issues in decompilation. The\n  course will cover optimisations of programs at the abstract\n  syntax, flowgraph and target-code level. It will also examine how\n  related techniques can be used in the process of\n  decompilation.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Introduction and motivation.</strong> Outline of an\n    optimising compiler. Optimisation partitioned:\n    <em>analysis</em> shows a property holds which enables a\n    <em>transformation</em>. The flow graph; representation of\n    programming concepts including argument and result passing. The\n    phase-order problem.</li>\n<li><strong>Kinds of optimisation.</strong> Local optimisation:\n    peephole optimisation, instruction scheduling. Global\n    optimisation: common sub-expressions, code motion.\n    Interprocedural optimisation. The call graph.</li>\n<li><strong>Classical dataflow analysis.</strong> Graph\n    algorithms, <em>live</em> and <em>avail</em> sets. Register\n    allocation by register colouring. Common sub-expression\n    elimination. Spilling to memory; treatment of CSE-introduced\n    temporaries. Data flow anomalies. Static Single Assignment\n    (SSA) form.</li>\n<li><strong>Higher-level optimisations.</strong> Abstract\n    interpretation, Strictness analysis. Constraint-based analysis,\n    Control flow analysis for lambda-calculus. Rule-based inference\n    of program properties, Types and effect systems. Points-to and\n    alias analysis.</li>\n<li><strong>Target-dependent optimisations.</strong>\n    Instruction selection. Instruction scheduling and its\n    phase-order problem.</li>\n<li><strong>Decompilation.</strong> Legal/ethical issues. Some\n    basic ideas, control flow and type reconstruction.</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>be able to explain program analyses as dataflow equations\n    on a flowgraph;</li>\n<li>know various techniques for high-level optimisation of\n    programs at the abstract syntax level;</li>\n<li>understand how code may be re-scheduled to improve\n    execution speed;</li>\n<li>know the basic ideas of decompilation.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>* Nielson, F., Nielson, H.R. and Hankin, C.L. (1999).\n  <em>Principles of program analysis</em>. Springer. Good on part A\n  and part B.<br/>\n  Appel, A. (1997). <em>Modern compiler implementation in\n  Java/C/ML</em> (3 editions).<br/>\n  Muchnick, S. (1997). <em>Advanced compiler design and\n  implementation</em>. Morgan Kaufmann.<br/>\n  Wilhelm, R. (1995). <em>Compiler design</em>. Addison-Wesley.<br/>\n  Aho, A.V., Sethi, R. and Ullman, J.D. (2007). <em>Compilers:\n  principles, techniques and tools</em>. Addison-Wesley (2nd\n  ed.).</p>\n", "course_name": "Optimising Compilers", "course_code": "OptComp", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/OptComp", "lecturers": ["tmj32"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "QuantComp": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-QuantumComputing.html", "description": "<h2>Aims</h2>\n<p>The principal aim of the course is to introduce students to\n  the basics of the quantum model of computation. The model will be\n  used to study algorithms for searching, factorisation and quantum\n  chemistry as well as other important topics in quantum\n  information such as cryptography and super-dense coding. Issues\n  in the complexity of computation will also be explored. A second\n  aim of the course is to introduce student to near-term quantum\n  computing. To this end, error-correction and adiabatic quantum\n  computing are studied.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Bits and qubits.</strong> Introduction to quantum\n    states and measurements with motivating examples. Comparison\n    with discrete classical states.</li>\n<li><strong>Linear algebra.</strong> Review of linear algebra:\n    vector spaces, linear operators, Dirac notation, the tensor\n    product.</li>\n<li><strong>The postulates of quantum mechanics.</strong>\n    Postulates of quantum mechanics, incl. evolution and\n    measurement.</li>\n<li><strong>Important concepts in quantum mechanics.</strong>\n    Entanglement, distinguishing orthogonal and non-orthogonal\n    quantum states, no-cloning and no signalling.</li>\n<li><strong>The quantum circuit model.</strong> The circuit\n    model of quantum computation. Quantum gates and circuits.\n    Universality of the quantum circuit model, and efficient\n    simulation of arbitrary two-qubit gates with a standard\n    universal set of gates.</li>\n<li><strong>Some applications of quantum information.</strong>\n    Applications of quantum information (other than quantum\n    computation): quantum key distribution, superdense coding and\n    quantum teleportation.</li>\n<li><strong>Deutsch-Jozsa algorithm.</strong> Introducing\n    Deutsch\u2019s problem and Deutsch\u2019s algorithm leading onto its\n    generalisation, the Deutsch-Jozsa algorithm.</li>\n<li><strong>Quantum search.</strong> Grover\u2019s search algorithm:\n    analysis and lower bounds.</li>\n<li><strong>Quantum Fourier Transform and Quantum Phase\n    Estimation.</strong> Definition of the Quantum Fourier\n    Transform (QFT), and efficient representation thereof as a\n    quantum circuit. Application of the QFT to enable Quantum Phase\n    Estimation (QPE).</li>\n<li><strong>Application 1 of QFT / QPE: Factoring.</strong>\n    Shor\u2019s algorithm: reduction of factoring to period finding and\n    then using the QFT for period finding.</li>\n<li><strong>Application 2 of QFT / QPE: Quantum\n    Chemistry.</strong> Efficient simulation of quantum systems,\n    and applications to real-world problems in quantum\n    chemistry.</li>\n<li><strong>Quantum complexity.</strong> Quantum complexity\n    classes and their relationship to classical complexity.\n    Comparison with probabilistic computation.</li>\n<li><strong>Quantum error correction.</strong> Introducing the\n    concept of quantum error correction required for the following\n    lecture on fault-tolerance.</li>\n<li><strong>Fault tolerant quantum computing.</strong> Elements\n    of fault tolerant computing; the threshold theorem for\n    efficient suppression of errors.</li>\n<li><strong>Adiabatic quantum computing and quantum\n    optimisation.</strong> The quantum adiabatic theorem, and\n    adiabatic optimisation. Quantum annealing and D-Wave.</li>\n<li><strong>Case studies in near-term quantum\n    computation.</strong> Examples of state-of-the-art quantum\n    algorithms and computers, including superconducting and\n    networked quantum computers.</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should:</p>\n<ul>\n<li>understand the quantum model of computation and the basic\n    principles of quantum mechanics;</li>\n<li>be familiar with basic quantum algorithms and their\n    analysis;</li>\n<li>be familiar with basic quantum protocols such as\n    teleportation and superdense coding;</li>\n<li>see how the quantum model relates to classical models of\n    deterministic and probabilistic computation.</li>\n<li>appreciate the importance of efficient error-suppression if\n    quantum computation is to yield an advantage over classical\n    computation.</li>\n<li>gain a general understanding of the important topics in\n    near-term quantum computing, including adiabatic quantum\n    computing.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Books:<br/>\n  Nielsen M.A., Chuang I.L. (2010). <em>Quantum Computation and\n  Quantum Information</em>. Cambridge University Press.<br/>\n  Mermin N.D. (2007). <em>Quantum Computer Science: An\n  Introduction</em>. Cambridge University Press.<br/>\n  McGeoch, C. (2014). <em>Adiabatic Quantum Computation and Quantum\n  Annealing Theory and Practice</em>. Morgan and Claypool. <a href=\"https://ieeexplore.ieee.org/document/7055969\" id=\"tex2html22\" name=\"tex2html22\">https://ieeexplore.ieee.org/document/7055969</a></p>\n<p>Papers:</p>\n<p>Braunstein S.L. (2003). <em>Quantum computation tutorial</em>.\n  Available at: <a href=\"https://www-users.cs.york.ac.uk/~schmuel/comp/comp_best.pdf\" id=\"tex2html23\" name=\"tex2html23\">https://www-users.cs.york.ac.uk/~schmuel/comp/comp_best.pdf</a><br/>\n  Aharonov D., Quantum computation [arXiv:quant-ph/9812037]<br/>\n  Albash T., Adiabatic Quantum Computing <a href=\"https://arxiv.org/pdf/1611.04471.pdf\" id=\"tex2html24\" name=\"tex2html24\">https://arxiv.org/pdf/1611.04471.pdf</a><br/>\n  McCardle S. et al, Quantum computational chemistry <a href=\"https://arxiv.org/abs/1808.10402\" id=\"tex2html25\" name=\"tex2html25\">https://arxiv.org/abs/1808.10402</a></p>\n<p>Other lecture notes:</p>\n<p>Andrew Childs (University of Maryland): <a href=\"http://cs.umd.edu/~amchilds/qa/\" id=\"tex2html28\" name=\"tex2html28\">http://cs.umd.edu/~amchilds/qa/</a><br/>\n  \u00a0</p>\n", "course_name": "Quantum Computing", "course_code": "QuantComp", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/QuantComp", "lecturers": ["sjh227"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "RandAlgthm": {"supervisions": 4, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-RandomisedAlgorithms.html", "description": "<h2>Aims:</h2>\n<p>\u00a0</p>\n<p>The aim of this course is to introduce advanced techniques in\n  the design and analysis algorithms, with a strong focus on\n  randomised algorithms. It covers essential tools and ideas from\n  probability, optimisation and graph theory, and develops this\n  knowledge through a variety of examples of algorithms and\n  processes. This course will demonstrate that randomness is not\n  only an important design technique which often leads to simpler\n  and more elegant algorithms, but may also be essential in\n  settings where time and space are restricted.\u00a0 \u00a0</p>\n<p>\u00a0</p>\n<h2>Lectures:</h2>\n<p>\u00a0</p>\n<p><strong>Introduction.\u00a0</strong>Course Overview. Why\n  Randomised Algorithms? A first Randomised Algorithm for the\n  MAX-CUT problem. [1 Lecture]\u00a0</p>\n<p><strong>Markov Chains and Mixing Times.</strong>\u00a0Random\n  Walks on Graphs. Application: Randomised Algorithm for the 2-SAT\n  problem. Mixing Times of Markov Chains. Application: Load\n  Balancing on Networks. [approx. 2 Lectures]</p>\n<p><strong>Spectral Graph Theory and\n  Clustering.</strong>\u00a0Eigenvalues of Graphs and Matrices:\n  Relations between Eigenvalues and Graph Properties, Spectral\n  Graph Drawing. Spectral Clustering: Conductance, Cheeger's\n  Inequality. Spectral Partitioning Algorithm [approx. 2\n  Lectures]</p>\n<p><strong>Linear Programming and\n  Applications.</strong>\u00a0Definitions and Applications.\n  Formulating Linear Programs. The Simplex Algorithm. Finding\n  Initial Solutions. How to use Linear Programs and Branch &amp;\n  Bound to Solve a Classical TSP instance. [approx. 3 Lectures]</p>\n<p><strong>Randomised Approximation\n  Algorithms.</strong>\u00a0Randomised Approximation Schemes.\n  Linearity of Expectations, Derandomisation. Deterministic and\n  Randomised Rounding of Linear Programs. Applications: MAX3-SAT\n  problem, Weighted Vertex Cover, Weighted Set Cover, MAX-SAT.\n  [approx. 2 Lectures]</p>\n<p><strong>Concentration\n  Inequalities.</strong>\u00a0Moment-Generating Functions and\n  Chernoff Bounds. Extension: Method of Bounded Independent\n  Differences. Applications: Balls-into-Bins, Quick-Sort and Load\n  Balancing. [approx. 2 Lectures]</p>\n<p><strong>Streaming and Online\n  Algorithms.\u00a0</strong>Introduction to Streaming. Approximate\n  Counting using Morris Algorithm. Online Learning using Experts:\n  Weighted Majority and Randomised Weighted Majority. [approx. 2\n  Lectures]</p>\n<p><strong>Stochastic Bandits:</strong> Greedy, Epsilon-Greedy,\n  UCB Algorithm. Outlook to Adversarial Bandits: EXP3 Algorithm\n  [approx. 2 Lectures]</p>\n<p>\u00a0</p>\n<h2>Objectives:</h2>\n<p>\u00a0</p>\n<p>By the end of the course students should be able to:</p>\n<p>\u00a0</p>\n<ul>\n<li>learn how to use randomness in the design of algorithms, in\n    particular, approximation algorithms;</li>\n<li>learn the basics of linear programming, integer programming\n    and randomised rounding;</li>\n<li>apply randomisation to various problems coming from\n    optimisation, machine learning and data science;</li>\n<li>use results from probability theory to analyse the\n    performance of randomised algorithms.</li>\n</ul>\n<p>\u00a0</p>\n<h2>Recommended reading</h2>\n<p>\u00a0</p>\n<p><em>* Michael Mitzenmacher and Eli Upfal. Probability and\n  Computing: Randomized Algorithms and Probabilistic Analysis.,\n  Cambridge University Press, 2nd edition.</em></p>\n<p><em>* David P. Williamson and David B. Shmoys. The Design of\n  Approximation Algorithms, Cambridge University Press,\n  2011</em></p>\n<p><em>* Cormen, T.H., Leiserson, C.D., Rivest, R.L. and Stein,\n  C. (2009). Introduction to Algorithms. MIT Press (3rd ed.). ISBN\n  978-0-262-53305-8</em></p>\n<p><br/>\n  \u00a0</p>\n", "course_name": "Randomised Algorithms", "course_code": "RandAlgthm", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/RandAlgthm", "lecturers": ["tms41"], "lectures": 16, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "BusSeminrs": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course is a series of seminars by former members and\n  friends of the Laboratory about their real-world experiences of\n  starting and running high technology companies. It is a follow on\n  to the Business Studies course in the Michaelmas Term. It\n  provides practical examples and case studies, and the opportunity\n  to network with and learn from actual entrepreneurs.</p>\n<h2>Lectures</h2>\n<p>Eight lectures by eight different entrepreneurs.</p>\n<h2>Objectives</h2>\n<p>At the end of the course students should have a better\n  knowledge of the pleasures and pitfalls of starting a high tech\n  company.</p>\n<h2>Recommended reading</h2>\n<p>Lang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook:\n  how to start and run a high-tech company</em>. FT.COM/Prentice\n  Hall.<br/>\n  Maurya, A. (2012). <em>Running Lean: Iterate from Plan A to a\n  Plan That Works</em>. O\u2019Reilly.<br/>\n  Osterwalder, A. and Pigneur, Y. (2010). <em>Business Model\n  Generation: A Handbook for Visionaires, Game Changers, and\n  Challengers</em>. Wiley.<br/>\n  Kim, W. and Mauborgne, R. (2005). <em>Blue Ocean Strategy</em>.\n  Harvard Business School Press.</p>\n<p>See also the additional reading list on the Business Studies\n  web page.</p>\n", "course_name": "Business Studies Seminars", "course_code": "BusSeminrs", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/BusSeminrs", "lecturers": [], "lectures": null, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "HLog+ModC": {"supervisions": 3, "prerequisite_for": [], "past_exam_questions": "https://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-HoareLogicandModelChecking.html", "description": "<h2>Aims</h2>\n<p>The course introduces two verification methods, Hoare Logic\n  and Temporal Logic, and uses them to formally specify and verify\n  imperative programs and systems.</p>\n<p>The first aim is to introduce Hoare logic for a simple\n  imperative language and then to show how it can be used to\n  formally specify programs (along with discussion of soundness and\n  completeness), and also how to use it in a mechanised program\n  verifier.</p>\n<p>The second aim is to introduce model checking: to show how\n  temporal models can be used to represent systems, how temporal\n  logic can describe the behaviour of systems, and finally to\n  introduce model-checking algorithms to determine whether\n  properties hold, and to find counter-examples.</p>\n<p>Current research trends also will be outlined.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Part 1: Hoare logic.</strong> Formal versus\n    informal methods. Specification using preconditions and\n    postconditions.</li>\n<li><strong>Axioms and rules of inference.</strong> Hoare logic\n    for a simple language with assignments, sequences, conditionals\n    and while-loops. Syntax-directedness.</li>\n<li><strong>Loops and invariants.</strong> Various examples\n    illustrating loop invariants and how they can be found.</li>\n<li><strong>Partial and total correctness.</strong> Hoare logic\n    for proving termination. Variants.</li>\n<li><strong>Semantics and metatheory</strong> Mathematical\n    interpretation of Hoare logic. Semantics and soundness of Hoare\n    logic.</li>\n<li><strong>Separation logic</strong> Separation logic as a\n    resource-aware reinterpretation of Hoare logic to deal with\n    aliasing in programs with pointers.</li>\n<li><strong>Part 2: Model checking.</strong> Models.\n    Representation of state spaces. Reachable states.</li>\n<li><strong>Temporal logic</strong>. Linear and branching time.\n    Temporal operators. Path quantifiers. CTL, LTL, and CTL*.</li>\n<li><strong>Model checking.</strong> Simple algorithms for\n    verifying that temporal properties hold.</li>\n<li><strong>Applications and more recent developments</strong>\n    Simple software and hardware examples. CEGAR (counter-example\n    guided abstraction refinement).</li>\n</ul>\n<h2>Objectives</h2>\n<p>At the end of the course students should</p>\n<ul>\n<li>be able to prove simple programs correct by hand and\n    implement a simple program verifier;</li>\n<li>be familiar with the theory and use of separation\n    logic;</li>\n<li>be able to write simple models and specify them using\n    temporal logic;</li>\n<li>be familiar with the core ideas of model checking, and be\n    able to implement a simple model checker.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Huth, M. and Ryan M. (2004). <em>Logic in Computer Science:\n  Modelling and Reasoning about Systems</em>. Cambridge University\n  Press (2nd ed.).</p>\n", "course_name": "Hoare Logic and Model Checking", "course_code": "HLog+ModC", "course_url": "https://www.cl.cam.ac.uk/teaching/2122/HLog+ModC", "lecturers": ["cp526"], "lectures": 12, "year": "2122", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}}