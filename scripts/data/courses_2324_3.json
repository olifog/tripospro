{"L352": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Advanced Graphics covers topics related to rendering.\n  processing, perception and display of images. The focus of the\n  course is on the algorithms behind new emerging display\n  technologies, such as virtual reality, augmented reality, and\n  high dynamic range displays. The course covers three fundamental\n  aspects of a complete graphics pipeline: technology, rendering\n  methods and visual perception.</p>\n<h2>Lectures</h2>\n<ul>\n<li style=\"list-style-type:square\"><strong>Advanced image\n    processing</strong>: edge-stopping filters, pyramids,\n    optimization-based image processing.</li>\n<li style=\"list-style-type:square\"><strong>Rendering\n    equation:</strong> path tracing, surface reflection</li>\n<li style=\"list-style-type:square\"><strong>Image-based\n    rendering:</strong> : light fields, neural radiance\n    fields.</li>\n<li style=\"list-style-type:square\"><strong>Colour</strong>:\n    physical and perceptual representation of colour, colour\n    perception, colour spaces.</li>\n<li style=\"list-style-type:square\"><strong>Models of visual\n    perception</strong>: brightness perception, detection and\n    discrimination, contrast sensitivity function, contrast\n    constancy,, perceptually uniform spaces, depth perception.</li>\n<li style=\"list-style-type:square\"><strong>Image and video\n    quality assessment:</strong> subjective and objective\n    measurement of visual quality</li>\n<li style=\"list-style-type:square\"><strong>High Dynamic Range\n    and tone mapping</strong>: dynamic range, display model,\n    methods of tone-mapping.</li>\n<li style=\"list-style-type:square\"><strong>Display\n    technologies</strong>: 2D displays, 3D displays, temporal\n    display characteristic, HDR displays.</li>\n<li><strong>Virtual and Augmented Reality</strong>: VR\n    rendering, technology, perceptual considerations.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Hainich, R. and Bimber, O. (2016) <em>Displays: Fundamentals\n  and Applications</em>. CRC Press (2nd ed.).<br/>\n  Boreskov, A. and Shikin, E. (2013) <em>Computer Graphics: From\n  Pixels to Programmable Graphics Hardware</em>. CRC Press.<br/>\n  Reinhard, E., et. al. (2010) <em>High Dynamic Range Imaging:\n  Acquisition, Display, and Image-Based Lighting</em>. Morgan\n  Kaufmann (2nd ed.).</p>\n<h2>Assessment - Part II Students</h2>\n<ul>\n<li style=\"list-style-type:square\">One practical exercise,\n    worth 30% of the marks.</li>\n<li style=\"list-style-type:square\">One programming task and\n    presentation, worth 70% of the marks</li>\n</ul>\n", "course_name": "Advanced Graphics and Image Processing", "course_code": "L352", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L352", "lecturers": ["rkm38"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R265": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course aims to provide students with an introduction to a\n  range of advanced topics in computer architecture. It will\n  explore the current and future challenges facing the architects\n  of modern computers. These will also be used to illustrate the\n  many different influences and trade-offs involved in computer\n  architecture.</p>\n<h2>Objectives</h2>\n<p>On completion of this module students should:</p>\n<ul>\n<li>understand the challenges of designing and verifying modern\n    microprocessors</li>\n<li>be familiar with recent research themes and emerging\n    challenges</li>\n<li>appreciate the complex trade-offs at the heart of computer\n    architecture</li>\n</ul>\n<h2>Syllabus</h2>\n<p>Each seminar will focus on a different topic. The proposed\n  topics are listed below but there may be some minor changes to\n  this:</p>\n<ul>\n<li>Trends in computer architecture</li>\n<li>State-of-the-art microprocessor design</li>\n<li>Memory system design</li>\n<li>Hardware reliability</li>\n<li>Specification, verification and test <em>(may be be\n    replaced with a different topic)</em></li>\n<li>Hardware security (2)</li>\n<li>HW accelerators and accelerators for machine learning</li>\n</ul>\n<p>Each two hour seminar will include three student presentations\n  (15mins) questions (5mins) and a broader discussion of the topics\n  (around 30mins). The last part of the seminar will include a\n  short scene setting lecture (around 20mins) to introduce the\n  following week's topic.</p>\n<h2>Assessment</h2>\n<p>Each week students will compare and contrast two of the main\n  papers and submit a written summary and review in advance of each\n  seminar (except when presenting).</p>\n<p>Students will be expected to give a number of 15 minute\n  presentations.</p>\n<p>Essays and presentations will be marked out of 10. After\n  dropping the lowest mark, the remaining marks will be scaled to\n  give a final score out of 100.</p>\n<p>Students will give at least one presentation during the\n  course. They will not be required to submit an essay during the\n  weeks they are presenting.</p>\n<p>Each presentation will focus on a single paper from the\n  reading list. Marks will be awarded for clarity and the\n  communication of the paper's key ideas, an analysis of the work's\n  strengths and weaknesses and the work\u2019s relationship to related\n  work and broader trends and constraints.</p>\n<h2>Recommended prerequisite reading</h2>\n<p>Patterson, D. A., Hennessy, J. L. (2017). <em>Computer\n  organization and design: The Hardware/software interface RISC-V\n  edition</em> Morgan Kaufmann. ISBN 978-0-12-812275-4.</p>\n<p>Hennessy, J. and Patterson, D. (2012). <em>Computer\n  architecture: a quantitative approach</em>. Elsevier (5th ed.)\n  ISBN 9780123838728. (the 3rd and 4th editions are also\n  relevant)</p>\n", "course_name": "Advanced Topics in Computer Architecture", "course_code": "R265", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R265", "lecturers": ["swm11", "tmj32", "jdw57"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R277": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module explores various topics in programming languages\n  beyond the scope of undergraduate\u00a0courses. It aims to\n  introduce students to ideas, results and techniques found in the\n  literature and\u00a0prepare them for research in the field.</p>\n<h2>Syllabus and structure</h2>\n<p>The module consists of eight two-hour seminars, each on a\n  particular topic. Topics will vary from year\u00a0to year, but\n  may include, for example,</p>\n<ul>\n<li>Abstract interpretation</li>\n<li>Verified software</li>\n<li>Metaprogramming</li>\n<li>Behavioural types</li>\n<li>Program synthesis</li>\n<li>Verified compilation</li>\n<li>Partial evaluation</li>\n<li>Garbage collection</li>\n<li>Dependent types</li>\n<li>Automatic differentiation</li>\n<li>Delimited continuations</li>\n<li>Module systems</li>\n</ul>\n<p>There will be three papers assigned for each topic, which\n  students are expected to read before the\u00a0seminar.<br/>\n  Each seminar will include three 20 minute student presentations\n  (15 minutes + 5 minutes questions),\u00a0time for general\n  discussion of the topic, and a brief overview lecture for the\n  following week\u2019s topic.<br/>\n  Before each seminar, except in weeks in which they give\n  presentations, students will submit a short\u00a0essay about two\n  of the papers.</p>\n<h2><br/>\n  Objectives</h2>\n<p>On completion of this module, students should</p>\n<ul>\n<li>be able to identify some major themes in programming\n    language research</li>\n<li>be familiar with some classic papers and recent\n    advances</li>\n<li>have an understanding of techniques used in the field</li>\n</ul>\n<h2><br/>\n  Assessment</h2>\n<p>Assessment consists of:</p>\n<ul>\n<li>Presentation of one of the papers from the reading list\n    (typically once or twice in total for each\u00a0student,\n    depending on class numbers)</li>\n<li>One essay per week (except on the first week and on\n    presentation weeks)</li>\n</ul>\n<p>All essays and presentations carry equal numbers of marks.</p>\n<p>Essay marks are awarded for understanding, for insight and\n  analysis, and for writing quality. Essays\u00a0should be around\n  1500 words (with a lower limit of 1450 and upper limit of 1650).\n  Presentation marks\u00a0are awarded for clarity, for effective\n  communication, and for selection and organisation of topics.</p>\n<p>There will be seven submissions (essays or presentations) in\n  total and, as in other courses, the lowest\u00a0mark for each\n  student will be disregarded when computing the final mark.</p>\n<p>Marking, deadlines and extensions will be handled in\n  accordance with the <a href=\"https://www.cst.cam.ac.uk/teaching/exams/mphil-assessment\">MPhil\n  Assessment Guidelines</a>.</p>\n<h2>Recommended reading material and resources</h2>\n<p>Research and survey papers from programming language\n  conferences and journals (e.g. <a href=\"https://popl22.sigplan.org/series/POPL\">POPL</a>, <a href=\"https://pldi19.sigplan.org/series/pldi\">PLDI</a>,\u00a0<a href=\"https://dl.acm.org/journal/toplas\">TOPLAS</a>, <a href=\"https://www.nowpublishers.com/PGL\">FTPL</a>) will be assigned\n  each week. General background material may be found in:</p>\n<p>\u2022 <a href=\"https://www.cis.upenn.edu/~bcpierce/tapl/\">Types\n  and Programming Languages</a> (Benjamin C. Pierce)<br/>\n  \u00a0 \u00a0The MIT Press<br/>\n  \u00a0 \u00a0ISBN 0-262-16209-1</p>\n<p>\u2022 <a href=\"https://www.cis.upenn.edu/~bcpierce/attapl/\">Advanced Topics in\n  Types and Programming Languages</a> (ed. Benjamin C. Pierce)<br/>\n  \u00a0 \u00a0The MIT Press<br/>\n  \u00a0 \u00a0ISBN 0-262-16228-8</p>\n<p>\u2022 <a href=\"https://www.cs.cmu.edu/~rwh/pfpl/\">Practical\n  Foundations for Programming Languages</a> (Robert Harper)<br/>\n  \u00a0 \u00a0Cambridge University Press<br/>\n  \u00a0 \u00a09781107150300</p>\n", "course_name": "Advanced topics in programming languages", "course_code": "R277", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R277", "lecturers": ["jdy22"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L108": {"supervisions": 0, "prerequisite_for": ["L118"], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Category theory provides a unified treatment of mathematical\n  properties and constructions that can be expressed in terms of\n  'morphisms' between structures. It gives a precise framework for\n  comparing one branch of mathematics (organized as a category)\n  with another and for the transfer of problems in one area to\n  another. Since its origins in the 1940s motivated by connections\n  between algebra and geometry, category theory has been applied to\n  diverse fields, including computer science, logic and\n  linguistics. This course introduces the basic notions of category\n  theory: adjunction, natural transformation, functor and category.\n  We will use category theory to organize and develop the kinds of\n  structure that arise in models and semantics for logics and\n  programming languages.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>Introduction; some history. Definition of category. The\n    category of sets and functions.</li>\n<li>Commutative diagrams. Examples of categories: preorders and\n    monotone functions; monoids and monoid homomorphisms; a\n    preorder as a category; a monoid as a category. Definition of\n    isomorphism. Informal notion of a 'category-theoretic'\n    property.</li>\n<li>Terminal objects. The opposite of a category and the\n    duality principle. Initial objects. Free monoids as initial\n    objects.</li>\n<li>Binary products and coproducts. Cartesian categories.</li>\n<li>Exponential objects: in the category of sets and in\n    general. Cartesian closed categories: definition and\n    examples.</li>\n<li>Intuitionistic Propositional Logic (IPL) in Natural\n    Deduction style. Semantics of IPL in a cartesian closed\n    preorder.</li>\n<li>Simply Typed Lambda Calculus (STLC). The typing relation.\n    Semantics of STLC types and terms in a cartesian closed\n    category (ccc). The internal language of a ccc. The\n    Curry-Howard-Lawvere correspondence.</li>\n<li>Functors. Contravariance. Identity and composition for\n    functors.</li>\n<li>Size: small categories and locally small categories. The\n    category of small categories. Finite products of\n    categories.</li>\n<li>Natural transformations. Functor categories. The category\n    of small categories is cartesian closed.</li>\n<li>Hom functors. Natural isomorphisms. Adjunctions. Examples\n    of adjoint functors. Theorem characterising the existence of\n    right (respectively left) adjoints in terms of a universal\n    property.</li>\n<li>Dependent types. Dependent product sets and dependent\n    function sets as adjoint functors. Equivalence of categories.\n    Example: the category of I-indexed sets and functions is\n    equivalent to the slice category Set/I.</li>\n<li>Presheaves. The Yoneda Lemma. Categories of presheaves are\n    cartesian closed.</li>\n<li>Monads. Modelling notions of computation as monads. Moggi's\n    computational lambda calculus.</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>be familiar with some of the basic notions of category\n    theory and its connections with logic and programming language\n    semantics</li>\n</ul>\n<h2>Assessment</h2>\n<ul>\n<li>a graded exercise sheet (25% of the final mark), and</li>\n<li>a take-home test (75%)</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Awodey, S. (2010). <em>Category theory</em>. Oxford University\n  Press (2nd ed.).</p>\n<p>Crole, R. L. (1994). <em>Categories for types</em>. Cambridge\n  University Press.</p>\n<p>Lambek, J. and Scott, P. J. (1986). <em>Introduction to higher\n  order categorical logic</em>. Cambridge University Press.</p>\n<p>Pitts, A. M. (2000). <em>Categorical Logic</em>. Chapter 2 of\n  S. Abramsky, D. M. Gabbay and T. S. E. Maibaum (Eds) Handbook of\n  Logic in Computer Science, Volume 5. Oxford University Press.\n  (Draft copy available <a href=\"http://www.cl.cam.ac.uk/~amp12/papers/catl/catl.pdf\">here</a>.)</p>\n<h2>Class Size</h2>\n<p>This module can accommodate upto 15 Part II students plus 15\n  MPhil / Part III students.</p>\n", "course_name": "Category Theory", "course_code": "L108", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L108", "lecturers": ["mpf23"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R209": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course aims to provide students with an introduction to\n  the history and central themes of computer security, from its\n  1970s foundations to some current research topics, with a theme\n  of how to defend cloud-based systems against capable motivated\n  opponents. The course considers first local computer systems and\n  then distributed systems; however, we will rapidly discover that\n  this is an artificial distinction that only becomes more awkward\n  as we enter the current period. Throughout the course, we will\n  consider proposed systems along with the adversarial research\n  intended to identify gaps and vulnerabilities.</p>\n<h2>Syllabus</h2>\n<p>There will be eight two-hour seminars on topics along the\n  lines of the following. Students are expected to read the\n  required set papers before each class. All students are expected\n  to submit a brief written summary of the readings in advance of\n  each class, and students will be nominated to give brief\n  presentations of each paper, or of cross-cutting aspects of all\n  the papers, to lead discussion.</p>\n<ul>\n<li>Origins and foundations of computer security</li>\n<li>Adversarial Reasoning</li>\n<li>Access control</li>\n<li>Security economics</li>\n<li>Passwords</li>\n<li>Capability systems</li>\n<li>Cryptographic protocols</li>\n<li>Correctness vs. mitigation</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>understand the principles of computer security</li>\n<li>be familiar with long-term and recent research themes</li>\n<li>appreciate the challenges of defending high-value\n    systems</li>\n</ul>\n<h2>Coursework</h2>\n<p>Participants will be expected to undertake six hours of\n  preparatory work before each meeting. This will involve:</p>\n<ul>\n<li>Reading a set number of papers</li>\n<li>Following up references and other related work</li>\n<li>Writing a weekly essay summarising assigned papers\n    <strong>or</strong>, as assigned by the course instructor,\n    preparing and delivering a 20-minute presentation on a specific\n    paper</li>\n<li>Essay text or presentation slides must be submitted via\n    Moodle, by the specified deadline</li>\n<li>Participating in class discussion on both the assigned\n    papers and broader issues raised by the week's readings</li>\n</ul>\n<p>Each week, the lecturers will lead an interactive session to\n  discuss the assigned reading material, drawing on the\n  presentations and essays submitted by the students before the\n  start of the class.</p>\n<p>Weekly essays will be up to 1,250 words summarising the\n  complete set of assigned papers, identifying common themes,\n  discussing the broader context, and enumerating possible class\n  discussion topics. While essays need not be 1,250 words in\n  length, participants are advised that essays under 1000 words are\n  unlikely to contain sufficient detail or discussion to achieve\n  full marks.</p>\n<p>All participants are expected to attend and participate in\n  every class; the instructor must be notified of any absences in\n  advance.</p>\n<h2>Practical work</h2>\n<p>None</p>\n<h2>Assessment</h2>\n<p>From the second week onwards, course participants are awarded\n  a maximum of 10 marks each week reflecting the quality of the\n  submitted essay or presentation. The lowest essay or presentation\n  mark of the term will be dropped. Remaining marks will be scaled\n  to a maximum final score out of 100.\u00a0</p>\n<p>Neither essays nor presentations are due in the first week.\n  All submitted essays should provide a word count.</p>\n<h2>Recommended reading</h2>\n<p>Anderson, R. J. (2020). <em>Security Engineering</em>, Wiley\n  (third edition)<br/>\n  Gollmann, D. (2010). <em>Computer Security</em>, Wiley<br/>\n  Marshall Kirk McKusick, George V. Neville-Neil, and Robert N. M.\n  Watson. 'Chapter 5 - Security', The Design and Implementation of\n  the FreeBSD Operating System, 2nd Edition, Pearson Education,\n  Boston, MA, USA, September 2014</p>\n", "course_name": "Computer Security: Principles and Foundations", "course_code": "R209", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R209", "lecturers": ["rja14", "rnw24", "ah793"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L314": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course teaches the basic signal-processing principles\n  necessary to understand many modern high-tech systems, with\n  application examples focussing on audio processing, image coding,\n  communication systems and software-defined radio. Students will\n  gain practical experience from numerical experiments in\n  programming assignments (in Julia, MATLAB or NumPy).</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Signals and systems.</strong>\u00a0Discrete\n    sequences and systems: types and properties. Amplitude, phase,\n    frequency, modulation, decibels, root-mean square. Linear\n    time-invariant systems, convolution. Some examples from\n    electronics, optics and acoustics.</li>\n<li><strong>Phasors.</strong>\u00a0Eigen functions of linear\n    time-invariant systems. Review of complex arithmetic. Phasors\n    as orthogonal base functions.</li>\n<li><strong>Fourier transform.</strong>\u00a0Forms and\n    properties of the Fourier transform. Convolution theorem. Rect\n    and sinc.</li>\n<li><strong>Dirac\u2019s delta function.</strong>\u00a0Fourier\n    representation of sine waves, impulse combs in the time and\n    frequency domain. Amplitude-modulation in the frequency\n    domain.</li>\n<li><strong>Discrete sequences and\n    spectra.</strong>\u00a0Sampling of continuous signals, periodic\n    signals, aliasing, interpolation, sampling and reconstruction,\n    sample-rate conversion, oversampling, spectral inversion.</li>\n<li><strong>Discrete Fourier\n    transform.</strong>\u00a0Continuous\u00a0<em>versus</em>\u00a0discrete\n    Fourier transform, symmetry, linearity, FFT, real-valued FFT,\n    FFT-based convolution, zero padding, FFT-based resampling,\n    deconvolution exercise.</li>\n<li><strong>Spectral estimation.</strong>\u00a0Short-time\n    Fourier transform, leakage and scalloping phenomena, windowing,\n    zero padding. Audio and voice examples. DTFM exercise.</li>\n<li><strong>Finite impulse-response\n    filters.</strong>\u00a0Properties of filters, implementation\n    forms, window-based FIR design, use of frequency-inversion to\n    obtain high-pass filters, use of modulation to obtain band-pass\n    filters.</li>\n<li><strong>Infinite impulse-response\n    filters.</strong>\u00a0Sequences as\n    polynomials,\u00a0<em>z</em>-transform, zeros and poles, some\n    analog IIR design techniques (Butterworth, Chebyshev I/II,\n    elliptic filters, second-order cascade form).</li>\n<li><strong>Band-pass signals.</strong>\u00a0Band-pass sampling\n    and reconstruction, IQ up and down conversion, superheterodyne\n    receivers, software-defined radio front-ends, IQ representation\n    of AM and FM signals and their demodulation.</li>\n<li><strong>Digital\n    communication.</strong>\u00a0Pulse-amplitude modulation.\n    Matched-filter detector. Pulse shapes, inter-symbol\n    interference, equalization. IQ representation of ASK, BSK, PSK,\n    QAM and FSK signals.\u00a0[2 hours]</li>\n<li><strong>Random sequences and noise.</strong>\u00a0Random\n    variables, stationary and ergodic processes, autocorrelation,\n    cross-correlation, deterministic cross-correlation sequences,\n    filtered random sequences, white noise, periodic\n    averaging.</li>\n<li><strong>Correlation coding.</strong>\u00a0Entropy, delta\n    coding, linear prediction,\n    dependence\u00a0<em>versus</em>\u00a0correlation, random\n    vectors, covariance, decorrelation, matrix diagonalization,\n    eigen decomposition, Karhunen-Lo\u00e8ve transform, principal\n    component analysis. Relation to orthogonal transform coding\n    using fixed basis vectors, such as DCT.</li>\n<li><strong>Lossy versus lossless\n    compression.</strong>\u00a0What information is discarded by\n    human senses and can be eliminated by encoders? Perceptual\n    scales, audio masking, spatial resolution, colour coordinates,\n    some demonstration experiments.</li>\n<li><strong>Quantization, image coding\n    standards.</strong>\u00a0Uniform and logarithmic quantization,\n    A/\u00b5-law coding, dithering, JPEG.</li>\n</ul>\n<h2>Objectives</h2>\n<ul>\n<li>apply basic properties of time-invariant linear\n    systems;</li>\n<li>understand sampling, aliasing, convolution, filtering, the\n    pitfalls of spectral estimation;</li>\n<li>explain the above in time and frequency domain\n    representations;</li>\n<li>use filter-design software;</li>\n<li>visualize and discuss digital filters in\n    the\u00a0<em>z</em>-domain;</li>\n<li>use the FFT for convolution, deconvolution, filtering;</li>\n<li>implement, apply and evaluate simple DSP applications;</li>\n<li>familiarity with a number of signal-processing concepts\n    used in digital communication systems</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Lyons, R.G. (2010).\u00a0<em>Understanding digital signal\n  processing.</em>\u00a0Prentice Hall (3rd ed.).<br/>\n  Oppenheim, A.V. and Schafer, R.W. (2007).\u00a0<em>Discrete-time\n  digital signal processing.</em>\u00a0Prentice Hall (3rd ed.).<br/>\n  Stein, J. (2000).\u00a0<em>Digital signal processing \u2013 a computer\n  science perspective.</em>\u00a0Wiley.</p>\n<h2>Class size</h2>\n<p>This module can accommodate a maximum of 24 students (16 Part\n  II students and 8 MPhil students)</p>\n<h2>Assessment - Part II students</h2>\n<ul>\n<li>Three homework programming assignments, each comprising 20%\n    of the mark</li>\n<li>Written test, comprising 40% of the total mark.</li>\n</ul>\n", "course_name": "Digital Signal Processing", "course_code": "L314", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L314", "lecturers": ["mgk25"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L98": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This is a lecture-style course that introduces students to\n  various aspects of the semantics of\u00a0Natural Languages\n  (mainly English):</p>\n<ul>\n<li>Lexical Semantics, with an emphasis on theory and\n    phenomenology (4 sessions)</li>\n<li>Compositional Semantics (9 sessions)</li>\n<li>Discourse and pragmatics-related aspects of semantics (3\n    sessions)</li>\n</ul>\n<h2>Learning outcomes</h2>\n<ul>\n<li>Give an operational definition of what is meant by\n    \u201cmeaning\u201d (for instance, above and\u00a0beyond syntax);</li>\n<li>Name the types of phenomena in language that require\n    semantic consideration, in terms\u00a0of lexical, compositional\n    and discourse/pragmatic aspects, in other words, argue\n    why\u00a0semantics is important;</li>\n<li>Demonstrate an understanding of the basics of various\n    semantic representations,\u00a0including logic-based and\n    graph-based semantic representations, their properties,\n    how\u00a0they are used and why they are important, and how they\n    are different from syntactic\u00a0representations;</li>\n<li>Know how such semantic representations are derived during\n    or after parsing, and how\u00a0they can be analysed and mapped\n    to surface strings;</li>\n<li>Understand applications of semantic representations e.g.\n    reasoning, validation, and\u00a0methods how these are\n    approached.</li>\n<li>When designing NL tasks that clearly require semantic\n    processing (e.g.\u00a0knowledge-based QA), to be aware of and\n    reuse semantic representations and\u00a0algorithms when\n    designing the task, rather than reinventing the wheel.</li>\n</ul>\n<h2>Practical advantages of this course for NLP students</h2>\n<ul>\n<li>Knowledge of underlying semantic effects helps improve NLP\n    evaluation, for instance by\u00a0providing more meaningful\n    error analysis. You will be able to link particular errors\n    to\u00a0design decisions inside your system.</li>\n<li>You will learn methods for better benchmarking of your\n    system, whatever the task may\u00a0be. Supervised ML systems\n    (in particular black-box systems such as Deep Learning)\n    are\u00a0only as clever as the datasets they are based on. In\n    this course, you will learn to design\u00a0datasets so that\n    they are harder to trick without real understanding, or\n    critique existing\u00a0datasets.</li>\n<li>You will be able to design tests for ML systems that better\n    pinpoint which aspects of\u00a0language an end-to-end system\n    has \u201cunderstood\u201d.</li>\n<li>You will learn to detect ambiguity and ill-formed semantics\n    in human-human\u00a0communication. This can serve to write more\n    clearly and logically.</li>\n<li>You will learn about decomposing complex semantics-reliant\n    tasks sensibly so that you\u00a0can reuse the techniques\n    underlying semantic analyzers in a modular way. In this\n    way,\u00a0rather than being forced to treat complex tasks in an\n    end-to-end manner, you will be able\u00a0to profit from partial\n    explanations and a better error analysis already built into\n    the\u00a0system.</li>\n</ul>\n<h2>Syllabus</h2>\n<ul>\n<li>Week 1 \u00a0 \u00a0\n      <ul>\n<li>Two hour\u00a0lecture: General introduction + Event\n        \u00a0 \u00a0\u00a0</li>\n<li>Assignment 1: reading papers and corpora about crowd\n        sourcing annotations\u00a0</li>\n</ul>\n</li>\n<li>Week 2 \u00a0 \u00a0\n      <ul>\n<li>One hour lecture: Referentiality \u00a0 \u00a0</li>\n<li>One hour student presentation + discussion on homework\n        1 \u00a0 \u00a0\u00a0</li>\n<li>Reading assignment: coreference\u00a0</li>\n</ul>\n</li>\n<li>Week 3 \u00a0 \u00a0\u00a0\n      <ul>\n<li>One hour lecture: Truth-conditional semantics \u00a0\n        \u00a0\u00a0</li>\n<li>One hour student presentation + discussion on\n        coreference\u00a0</li>\n</ul>\n</li>\n<li>Week 4 \u00a0 \u00a0\u00a0\n      <ul>\n<li>Two hour\u00a0lecture: Graph-based MR + Semantic\n        parsing \u00a0 \u00a0\u00a0</li>\n<li>Assignment 2: evaluating cross-lingual semantic\n        parsers\u00a0</li>\n</ul>\n</li>\n<li>Week 5 \u00a0 \u00a0\u00a0\n      <ul>\n<li>Two hour\u00a0lecture: Compositionally + Weakly\n        compositional phenomena \u00a0 \u00a0</li>\n<li>Reading assignment: code generation\u00a0</li>\n</ul>\n</li>\n<li>Week 6 \u00a0 \u00a0\u00a0\n      <ul>\n<li>One hour lecture: i. Negation (including presupposition\n        and pragmatics) \u00a0 \u00a0\u00a0</li>\n<li>One hour student presentation + discussion on code\n        generation\u00a0</li>\n</ul>\n</li>\n<li>Week 7 \u00a0 \u00a0\u00a0\n      <ul>\n<li>One hour lecture: English Resource Semantics \u00a0\n        \u00a0\u00a0</li>\n<li>One hour student presentation + discussion on homework\n        2 \u00a0 \u00a0\u00a0</li>\n<li>Assignment 3: task-specific semantic parsing as\n        cross-lingual parsing\u00a0</li>\n</ul>\n</li>\n<li>Week 8 \u00a0 \u00a0\u00a0\n      <ul>\n<li>1.5 hour\u00a0lecture: Lexical semantics + Grounding\n        \u00a0 \u00a0\u00a0</li>\n<li>0.5 hour summary of the course \u00a0</li>\n</ul>\n</li>\n</ul>\n<h2>Assessment</h2>\n<ul>\n<li>Assignment 1: ticked exercise 5%</li>\n<li>Assignment 2: 30%</li>\n<li>Assignment 3: 45%</li>\n<li>Presentations:\u00a0Practice presentation 5%, Final\n    presentation 15%</li>\n</ul>\n", "course_name": "Introduction to Computational Semantics", "course_code": "L98", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L98", "lecturers": ["ws390", "sht25"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L95": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module aims to provide a brief introduction to\n  linguistics for computer scientists and then goes on to cover\n  some of the core tasks in natural language processing (NLP),\n  focussing on statistical parsing of sentences to yield syntactic\n  representations. We will look at how to evaluate parsers and see\n  how well state-of-the-art tools perform given current\n  techniques.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>Linguistics for NLP focusing on morphology and syntax</li>\n<li>Grammars and representations</li>\n<li>Statistical and neural parsing</li>\n<li>Treebanks and evaluation</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>understand the basic properties of human languages and be\n    familiar with descriptive and theoretical frameworks for\n    handling these properties;</li>\n<li>understand the design of tools for NLP tasks such as\n    parsing and be able to apply them to text and evaluate their\n    performance;</li>\n</ul>\n<h2>Practical work</h2>\n<ul>\n<li>Week 1-7: There will be non-assessed practical exercises\n    between sessions and during sessions.</li>\n<li>Week 8: Download and apply two parsers to a designated\n    text. Evaluate the performance of the tools quantitatively and\n    qualitatively.</li>\n</ul>\n<h2>Assessment</h2>\n<ul>\n<li>There will be one\u00a0presentation worth 10% of the final\n    mark; presentation topics will be allocated at the start of\n    term.</li>\n<li>An assessed practical report\u00a0of not more 8 pages in\n    ACL conference format. It will contribute 90% of the final\n    mark.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Jurafsky, D. and Martin, J. (2008). <em>Speech and Language\n  Processing</em>. Prentice-Hall (2nd ed.). (See also 3rd ed.\n  available online.)</p>\n", "course_name": "Introduction to Natural Language Syntax and Parsing", "course_code": "L95", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L95", "lecturers": ["pjb48"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L50": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Systems research refers to the study of a broad range of\n  behaviours arising from complex system design, including:\n  resource sharing and scheduling; interactions between hardware\n  and software; network topology, protocol and device design and\n  implementation; low-level operating systems; Interconnect,\n  storage and more. This module will:</p>\n<ol>\n<li>Teach performance characteristics and performance\n    measurement methodology and practice through profiling\n    experiments;</li>\n<li>Expose students to real-world systems artefacts evident\n    through different measurement tools;</li>\n<li>Develop scientific writing skills through a series of\n    laboratory reports;</li>\n<li>Provide research skills for characterization and modelling\n    of systems and networks using measurements.</li>\n</ol>\n<h2>Prerequisites</h2>\n<p>It is strongly recommended that students have previously (and\n  successfully) completed an undergraduate networking course -- or\n  have equivalent experience through project or open-source\n  work.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>Introduction to performance measurements, performance\n    characteristics [1 lecture]</li>\n<li>Performance measurements tools and techniques [2 lectures +\n    2 lab sessions]</li>\n<li>Reproducible experiments [1 lecture + 1 lab session]</li>\n<li>Common pitfalls in measurements [1 lecture]</li>\n<li>Device and system characterisation [1 lecture + 2 lab\n    sessions]</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>Describe the objectives of measurements, and what they can\n    achieve;</li>\n<li>Characterise and model a system using measurements;</li>\n<li>Perform reproducible measurements experiments;</li>\n<li>Evaluate the performance of a system using\n    measurements;</li>\n<li>Operate measurements tools and be aware of their\n    limitations;</li>\n<li>Detect anomalies in the network and avoid common\n    measurements pitfalls;</li>\n<li>Write system-style performance evaluations.</li>\n</ul>\n<h2>Practical work</h2>\n<p>Five 2-hour in-classroom labs will ask students to develop and\n  use skills in performance measurements as applied to real-world\n  systems and networking artefacts. Results from these labs (and\n  follow-up work by students outside of the classroom) will by the\n  primary input to lab reports.</p>\n<p>The first three labs will provide an introduction and hands on\n  experience with measurement tools and measurements methodologies,\n  while the last two labs will focus on practical measurements and\n  evaluation of specific platforms. Students may find it useful to\n  work in pairs within the lab, but must prepare lab reports\n  independently. The module lecturer will give a short introductory\n  at the start of each lab, and instructors will be on-hand\n  throughout labs to provide assistance.</p>\n<p>Lab participation is not directly included in the final mark,\n  but lab work is a key input to lab reports that are assessed.\n  Guided lab experiments resulting in practical write ups.</p>\n<h2>Assessment</h2>\n<p>Each student will write two lab reports. The first lab report\n  will summarise the experiments done in the first three labs\n  (20%). The second will be a lab report (5000 words) summarising\n  the evaluation of a device or a system (80%).</p>\n<h2>Recommended reading</h2>\n<p>The following list provides some background to the course\n  materials, but is not mandatory. A reading list, including\n  research papers, will be provided in the course materials.</p>\n<ul>\n<li>George Varghese. Network algorithmics. Chapman and\n    Hall/CRC, 2010.</li>\n<li>Mark Crovella and Balachander Krishnamurthy. Internet\n    measurement: infrastructure, traffic and applications. John\n    Wiley and Sons, Inc., 2006.</li>\n<li>Brendan Gregg. Systems Performance: Enterprise and the\n    Cloud, Prentice Hall Press, Upper Saddle River, NJ, USA,\n    October 2013.</li>\n<li>Raj Jain, The Art of Computer Systems Performance Analysis:\n    Techniques for Experimental Design, Measurement, Simulation,\n    and Modeling, Wiley - Interscience, New York, NY, USA, April\n    1991.</li>\n</ul>\n", "course_name": "Introduction to networking and systems measurements", "course_code": "L50", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L50", "lecturers": ["awm22"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R244": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module provides an introduction to large-scale data\n  processing, optimisation, and the impact on computer system's\n  architecture. Large-scale distributed applications with high\n  volume data processing such as training of machine learning will\n  grow ever more in importance. Supporting the design and\n  implementation of robust, secure, and heterogeneous large-scale\n  distributed systems is essential. To deal with distributed\n  systems with a large and complex parameter space, tuning and\n  optimising computer systems is becoming an important and complex\n  task, which also deals with the characteristics of input data and\n  algorithms used in the applications. Algorithm designers are\n  often unaware of the constraints imposed by systems and the best\n  way to consider these when designing algorithms with massive\n  volume of data. On the other hand, computer systems often miss\n  advances in algorithm design that can be used to cut down\n  processing time and scale up systems in terms of the size of the\n  problem they can address. Integrating machine learning approaches\n  (e.g. Bayesian Optimisation, Reinforcement Learning) for system\n  optimisation will be explored in this course.</p>\n<h2>Syllabus</h2>\n<p>This course provides perspectives on large-scale data\n  processing, including data-flow programming, graph data\n  processing, probabilistic programming and computer\n  system\u00a0optimisation, especially using machine learning\n  approaches, thus providing a solid basis to work on\u00a0the next\n  generation of distributed systems.</p>\n<p>The module consists of 8 sessions, with 5 sessions on specific\n  aspects of large-scale data processing\u00a0research. Each\n  session discusses 3-4 papers, led by the assigned students. One\n  session is a hands-on\u00a0tutorial on MapReduce using data flow\n  programming of\u00a0Deep Neural Networks training\u00a0using\n  Google TensorFlow also Bayersian Optimisation basics. The first\n  session advises on how to\u00a0read/review a paper together with\n  a brief introduction on different perspectives in large-scale\n  data<br/>\n  processing and optimisation. The last session is dedicated to the\n  student presentation of opensource\u00a0project studies.</p>\n<ol>\n<li>Introduction to large-scale data processing and\n    optimisation</li>\n<li>Data flow programming: Map/Reduce to TensorFlow</li>\n<li>Large-scale graph data processing: storage, processing\n    model and parallel processing</li>\n<li>Map/Reduce and Deep Neural Network using TensorFlow\n    hands-on tutorial</li>\n<li>Probabilistic Programming</li>\n<li>Many Aspects of Optimisation in\u00a0Computer Systems</li>\n<li>Optimisation of Computer Systems using ML</li>\n<li>Presentation of Open Source Project Study</li>\n</ol>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>Understand key concepts of scalable data processing\n    approaches in future computer systems.</li>\n<li>Obtain a clear understanding of building distributed\n    systems using data centric programming and large-scale data\n    processing.</li>\n<li>Understand a large and complex parameter space in computer\n    system's optimisation and applicability of Machine Learning\n    approach.</li>\n</ul>\n<h2>Coursework</h2>\n<h3>Reading Club:</h3>\n<ul>\n<li>The preparation for the reading club will involve 1-3\n    papers every week. At each session, around 3-4 papers are\n    selected under the given topic, and the students present their\n    review work.</li>\n<li>Hands-on tutorial session of data flow programming\n    including writing an application of processing streaming in\n    Twitter data and/or Deep Neural Networks using Google\n    TensorFlow using cluster computing.</li>\n</ul>\n<h3>Reports</h3>\n<p>The following three reports are required, which could be\n  extended from the assignment of the reading club, within the\n  scope of data centric systems.</p>\n<ol>\n<li>Review report on a full length paper (max 1800 words)\n      <ul>\n<li>Describe the contribution of the paper in depth with\n        criticisms</li>\n<li>Crystallise the significant novelty in contrast to\n        other related work</li>\n<li>Suggestions for future work</li>\n</ul>\n</li>\n<li>Survey report on sub-topic in large-scale data processing\n    and optimisation (max 2000 words)\n      <ul>\n<li>Pick up to 5 papers as core papers in the survey\n        scope</li>\n<li>Read the above and expand reading through related\n        work</li>\n<li>Comprehend the view and finish an own survey paper</li>\n</ul>\n</li>\n<li>Project study and exploration of a prototype (max 2500\n    words)\n      <ul>\n<li>What is the significance of the project in the research\n        domain?</li>\n<li>Compare with similar and succeeding projects</li>\n<li>Demonstrate the project by exploring its prototype</li>\n</ul>\n</li>\n</ol>\n<p>Reports 1 and 2 should be handed in by the end of 5th week and\n  7th week of the course. Report 3 should be handed in by the end\n  of the Michaelmas Term.</p>\n<h2>Assessment</h2>\n<p>The final grade for the course will be provided as a\n  percentage, and the assessment will consist of two parts:</p>\n<ol>\n<li>25%: for reading club (participation, presentation)</li>\n<li>75%: for the three reports:\n      <ul>\n<li>15%: Intensive review report</li>\n<li>25%: Survey report</li>\n<li>35%: Project study</li>\n</ul>\n</li>\n</ol>\n<h2>Recommended reading</h2>\n<ol>\n<li>M. Abadi et al. TensorFlow: A System for Large-Scale\n    Machine Learning, OSDI, 2016.</li>\n<li>D. Aken et al.: Automatic Database Management System Tuning\n    Through Large-scale Machine Learning, SIGMOD, 2017.</li>\n<li>J. Ansel et al. Opentuner: an extensible framework for\n    program autotuning. PACT, 2014.</li>\n<li>V. Dalibard, M. Schaarschmidt, E. Yoneki. BOAT: Building\n    Auto-Tuners with Structured Bayesian Optimization, WWW,\n    2017.</li>\n<li>J. Dean et al. Large scale distributed deep networks. NIPS,\n    2012.</li>\n<li>G. Malewicz, M. Austern, A. Bik, J. Dehnert, I. Horn, N.\n    Leiser, G. Czajkowski. Pregel: A System for Large-Scale Graph\n    Processing, SIGMOD, 2010.</li>\n<li>A. Mirhoseini et al. Device Placement Optimization with\n    Reinforcement Learning, ICML, 2017.</li>\n<li>D. Murray, F. McSherry, R. Isaacs, M. Isard, P. Barham, M.\n    Abadi. Naiad: A Timely Dataflow System, SOSP, 2013.</li>\n<li>M. Schaarschmidt, S. Mika, K. Fricke and E. Yoneki:\n    RLgraph: Modular Computation Graphs for Deep Reinforcement\n    Learning, SysML, 2019.</li>\n<li>Z. Jia, O. Padon, J. Thomas, T. Warszawski, M.\n    Zaharia,\u00a0 A. Aiken: <a href=\"https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R244_2020_2021/papers/jia_SOSP_2019.pdf\" style=\"color:#0563c1; text-decoration:underline\" target=\"_blank\">TASO: Optimizing Deep Learning Computation with\n    Automated Generation of Graph Substitutions</a>: SOSP,\n    2019.</li>\n<li>H. Mao et al.: <a href=\"https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R244_2020_2021/papers/mao_OR_2019.pdf\" style=\"color:#0563c1; text-decoration:underline\" target=\"_blank\">Park: An Open Platform for Learning-Augmented Computer\n    Systems</a>, OpenReview, 2019.</li>\n</ol>\n<p>A complete list can be found on the course material web page.\n  See also 2019-2020 course material on the previous course\n  <a href=\"https://www.cl.cam.ac.uk/teaching/1920/R244/materials.html\" target=\"_blank\">Large-Scale Data Processing and\n  Optimisation</a>.</p>\n", "course_name": "Large-scale data processing and optimisation", "course_code": "R244", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R244", "lecturers": ["ey204"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L48": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>The module \u201cMachine Learning and the Physical World\u201d is\n  focused on machine learning systems that interact directly with\n  the real world. Building artificial systems that interact with\n  the physical world have significantly different challenges\n  compared to the purely digital domain. In the real world data is\n  scares, often uncertain and decisions can have costly and\n  irreversible consequences. However, we also have the benefit of\n  centuries of scientific knowledge that we can draw from. This\n  module will provide the methodological background to machine\n  learning applied in this scenario. We will study how we can build\n  models with a principled treatment of uncertainty, allowing us to\n  leverage prior knowledge and provide decisions that can be\n  interrogated.</p>\n<p>There are three principle points about machine learning in the\n  real world that will concern us.</p>\n<ol>\n<li>We often have a mechanistic understanding of the real world\n    which we should be able to bootstrap to make decisions. For\n    example, equations from physics or an understanding of\n    economics.</li>\n<li>Real world decisions have consequences which may have\n    costs, and often these cost functions need to be assimilated\n    into our machine learning system.</li>\n<li>The real world is surprising, it does things that you do\n    not expect and accounting for these challenges requires us to\n    build more robust and or interpretable systems.</li>\n</ol>\n<p>Decision making in the real world hasn\u2019t begun only with the\n  advent of machine learning technologies. There are other domains\n  which take these areas seriously, physics, environmental\n  scientists, econometricians, statisticians, operational\n  researchers. This course identifies how machine learning can\n  contribute and become a tool within these fields. It will equip\n  you with an understanding of methodologies based on uncertainty\n  and decision making functions for delivering on these\n  challenges.</p>\n<h2>Objectives</h2>\n<p>You will gain detailed knowledge of</p>\n<ul>\n<li>surrogate models and uncertainty</li>\n<li>surrogate-based optimization</li>\n<li>sensitivity analysis</li>\n<li>experimental design</li>\n</ul>\n<p>You will gain knowledge of</p>\n<ul>\n<li>counterfactual analysis</li>\n<li>surrogate-based quadrature</li>\n</ul>\n<h2>Schedule</h2>\n<p>Week 1:\u00a0Introduction to the unit and foundation of\n  probabilistic modelling</p>\n<p>Week 2:\u00a0Gaussian processes and probablistic inference</p>\n<p>Week 3:\u00a0Simulation and Sequential decision making under\n  uncertainty</p>\n<p>Week 4:\u00a0Emulation and Experimental Design</p>\n<p>Week 5:\u00a0Sensitivity Analysis and Multifidelity\n  Modelling</p>\n<p>Week 6-8:\u00a0Case studies of applications and Projects</p>\n<h2>Practical work</h2>\n<p>During the first five weeks of the unit we will provide a\n  weekly worksheet that will focus on implementation and practical\n  exploration of the material covered in the lectures. The\n  worksheets will allow you to build up a these methods without\n  relying on extensive external libraries. You are free to use any\n  programming language of choice however we highly recommended the\n  use of =Python=.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Two individual tasks\u00a0(15% each)</li>\n<li>Group Project (70%).\u00a0Each group will work on an\n    application of uncertainty that covers the material of the\n    first 5 weeks of lectures in the unit. Each group will submit a\n    report which will form the basis of the assessment. In addition\n    to the report each group will also attend a short oral\n    examination based on the material covered both in the report\n    and the taught material.</li>\n</ul>\n<h2>Recommended Reading</h2>\n<p>Rasmussen, C. E. and Williams, C. K. I. (2006). <em>Gaussian\n  Processes for Machine Learning</em>. MIT Press</p>\n<p>Bishop, C. (2006). <em>Pattern recognition and machine\n  learning</em>. Springer.<br/>\n<a href=\"https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\" target=\"_blank\">https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf</a></p>\n<p>Laplace, P. S. (1902). <em>A Philosophical Essay on\n  Probabilities</em>. John Wiley &amp; Sons.<br/>\n<a href=\"https://archive.org/details/philosophicaless00lapliala\" target=\"_blank\">https://archive.org/details/philosophicaless00lapliala</a></p>\n", "course_name": "Machine Learning and the Physical World", "course_code": "L48", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L48", "lecturers": ["ndl21"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L101": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module aims to provide an introduction to machine\n  learning (ML) with specific application to tasks in natural\n  language processing (NLP). We will cover the concepts of\n  classification, structured prediction and language modelling,\n  with applications on sentiment analysis, named entity\n  recognition, machine translation and information extraction.\n  Methods will include both linear and non-linear models (aka deep\n  learning), including (multilayer) perceptrons, logistic\n  regression, recurrent neural networks, sequence2sequence and\n  transformers.</p>\n<h2>Syllabus</h2>\n<p>Classification by machine learning: classification, types of\n  classifier, generative vs. discriminative models,\n  (un-/semi-)supervised training.</p>\n<p>Structured prediction: sequence tagging, incremental language\n  generation with recurrent neural networks.</p>\n<p>Language modelling: self-supervised learning, conditional\n  language modelling, embeddings</p>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li style=\"list-style-type: square;\">understand the issues\n    involved in applying machine learning approaches to a range of\n    language processing applications;</li>\n<li style=\"list-style-type: square;\">understand the\n    optimization underlying a number of machine learning approaches\n    that have been applied to language processing, including:\n    Perceptron, Logistic Regression, and Multi-Layer Perceptron,\n    recurrent neural networks, transformers</li>\n<li style=\"list-style-type: square;\">understand some\n    applications and specific tasks including: document\n    classification, named entity recognition, machine translation,\n    natural language generation</li>\n</ul>\n<h2>Coursework</h2>\n<p>Students will be expected to undertake reading for assigned\n  lectures and seminars. Each student will give a 20 minute\n  presentation of one paper.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Students will receive one tick worth 5% for attendance at\n    seminar sessions, reading of assigned material, and\n    satisfactory contribution during seminars.</li>\n<li>Students will receive a second tick worth 5% for a\n    satisfactory presentation of an assigned paper.</li>\n<li>students will undertake a small project to be agreed with\n    the lecturers and write a project report of not more than 5000\n    words. The report will be due around the beginning of the Lent\n    Term (see academic calendar for precise date), will be assessed\n    by the lecturers, and will account for 90% of the module\n    marks.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Jurafsky, D. &amp; Martin, J. (2023). <em>Speech and language\n  processing</em>. Prentice Hall (3rd ed. draft, online).</p>\n<p>Goodfellow et al (2016), <em>Deep Learning</em> (Chaps\n  6-12).</p>\n<p>Eisenstein, J. (2019), <em>Introduction to Natural Language\n  Processing</em></p>\n<p>Murphy, K (2022), <em>Probabilistic Machine Learning: An\n  Introduction</em></p>\n", "course_name": "Machine Learning for Language Processing", "course_code": "L101", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L101", "lecturers": ["av308"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L335": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course aims at introducing the theoretical foundations\n  and practical techniques for machine perception, the capability\n  of computers to interpret data resulting from sensor\n  measurements. The course will teach the fundamentals and modern\n  techniques of machine perception, i.e. reconstructing the real\n  world starting from sensor measurements with a focus on machine\n  perception for visual data. The topics covered will be\n  image/geometry representations for machine perception, semantic\n  segmentation, object detection and recognition, geometry capture,\n  appearance modeling and acquisition, motion detection and\n  estimation, human-in-the-loop machine perception, select topics\n  in applied machine perception.</p>\n<p>Machine perception/computer vision is a rapidly expanding area\n  of research with real-world applications. An understanding of\n  machine perception is also important for robotics, interactive\n  graphics (especially AR/VR), applied machine learning, and\n  several other fields and industries. This course will provide a\n  fundamental understanding of and practical experience with the\n  relevant techniques.</p>\n<h2>Learning outcomes</h2>\n<ul>\n<li>Students will understand the theoretical underpinnings of\n    the modern machine perception techniques for reconstructing\n    models of reality starting from an incomplete and imperfect\n    view of reality.</li>\n<li>Students will be able to apply machine perception theory to\n    solve practical problems, e.g. classification of images,\n    geometry capture.</li>\n<li>Students will gain an understanding of which machine\n    perception techniques are appropriate for different tasks and\n    scenarios.</li>\n<li>Students will have hands-on experience with some of these\n    techniques via developing a functional machine perception\n    system in their projects.</li>\n<li>Students will have practical experience with the current\n    prominent machine perception frameworks.</li>\n</ul>\n<h2>Syllabus</h2>\n<ul>\n<li>The fundamentals of machine learning for machine\n    perception</li>\n<li>Deep neural networks and frameworks for machine\n    perception</li>\n<li>Semantic segmentation of objects and humans</li>\n<li>Object detection and recognition</li>\n<li>Motion estimation, tracking and recognition</li>\n<li>3D geometry capture</li>\n<li>Appearance modeling and acquisition</li>\n<li>Select topics in applied machine perception</li>\n</ul>\n<h2>Assessment</h2>\n<ul>\n<li>A practical exercise, worth 20% of the mark. This will\n    cover the basics and theory of machine perception and some of\n    the practical techniques the students will likely use in their\n    projects. This is individual work. No GPU hours will be needed\n    for the practical work.</li>\n</ul>\n<ul>\n<li>A machine perception project worth 80% of the marks:\n      <ul>\n<li>Course projects will be selected by the students\n        following the possible project\u00a0themes proposed by the\n        lecturer,\u00a0and will be checked by the lecturer for\n        appropriateness.\u00a0</li>\n</ul>\n<ul>\n<li>The students will form groups of 2-3 to design,\n        implement, report, and present a project to tackle a given\n        task in machine perception.</li>\n</ul>\n<ul>\n<li>The final mark will be composed of an\n        implementation/report mark (60%) and a presentation mark\n        (20%). Each team member will be evaluated based on her/his\n        contribution.</li>\n</ul>\n<ul>\n<li>Each project will have extensions to be completed only\n        by the ACS students. Each student will write a different\n        part of the report, whose author will be clearly marked.\n        Each student will further summarise her/his contributions\n        to the project in the same report.</li>\n</ul>\n</li>\n</ul>\n<h2>Recommended Reading List</h2>\n<ul>\n<li><em>Computer Vision: Algorithms and Applications, Richard\n    Szeliski, Springer, 2010.</em></li>\n<li><em>Deep Learning, Ian Goodfellow, Yoshua Bengio, and Aaron\n    Courville, MIT Press, 2016.</em></li>\n<li><em>Machine Learning and Visual Perception, Baochang Zhang,\n    De Gruyter, 2020.</em></li>\n</ul>\n", "course_name": "Machine Visual Perception", "course_code": "L335", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L335", "lecturers": ["cpt23"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R269": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module aims to introduce the latest research advancements\n  in mobile systems and mobile data machine learning, spanning a\n  range of domains including systems, data gathering, analytics and\n  machine learning, on device machine learning and applications\n  such as health, transportation, behavior monitoring,\n  cyber-physical systems, autonomous vehicles, drones. The course\n  will cover current and seminal research papers in the area of\n  research.</p>\n<h2>Syllabus</h2>\n<p>The course will consist of one introductory lecture, seven\n  two-hour, and one three-hour, sessions covering a variety of\n  topics roughly including the following material (some variation\n  in the topics might happen from year to year):</p>\n<ol>\n<li>System, Energy and Security</li>\n<li>Backscatter Communication, Battery Free and Energy\n    Harvesting Devices</li>\n<li>New Sensing Modalities</li>\n<li>Machine Learning on Wearable Data</li>\n<li>On Device Machine Learning</li>\n<li>Mobile and Wearable Health</li>\n<li>Mobile and Wearable Systems of Sustainability</li>\n</ol>\n<p>Each week, three class participants will be assigned to\n  introduce assigned three papers via 20-minute presentations,\n  conference-style and highlighting critically its features. Each\n  presentation will be followed by 10 minutes of questions. This\n  will be followed by 10 minutes of general discussion. Slides will\n  be used for presentation.</p>\n<p>Students will give one or more presentations each term. Each\n  student will submit a paper review each week for one of the three\n  papers presented except for the week they will be presenting\n  slides. Each review will follow a template and be up to 1,000\n  words. Each review will receive a maximum of 10 points. As a\n  result, each student will produce 6-7 reviews and at least one\n  presentation, probably two. All participants are expected to\n  attend and participate in every class; the instructor must be\n  notified of any absences in advance.</p>\n<h2>Objectives</h2>\n<p>On completion of this module students should have an\n  understanding of the recent key research in mobile and sensor\n  systems and mobile analytics as well as an improved critical\n  thinking over research papers.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Aggregate mark for 7 assignments from 6-7 reports and 1-2\n    presentations. Each report or presentation will contribute one\n    seventh of the course mark.</li>\n<li>A tick for presence and participation to each class will\n    also be awarded.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Readings from the most recent conferences such as AAAI, ACM\n  KDD, ACM MobiCom, ACM MobiSys, ACM SenSys, ACM UbiComp, ICLR,\n  ICML Neurips, and WWW pertinent to mobile systems and data.</p>\n", "course_name": "Mobile, Wearable Systems and Machine Learning", "course_code": "R269", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R269", "lecturers": ["cm542", "yl868"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L304": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>In recent years multiprocessors have become ubiquitous, but\n  building reliable concurrent systems with good performance\n  remains very challenging. The aim of this module is to introduce\n  some of the theory and the practice of concurrent programming,\n  from hardware memory models and the design of high-level\n  programming languages to the correctness and performance\n  properties of concurrent algorithms.</p>\n<h2>Lectures</h2>\n<p>Part 1: Introduction and relaxed-memory concurrency [Professor\n  P. Sewell]</p>\n<ul>\n<li><strong>Introduction</strong>. Sequential consistency,\n    atomicity, basic concurrent problems. [1 block]</li>\n<li><strong>Concurrency on real multiprocessors</strong>: the\n    relaxed memory model(s) for x86, ARM, and IBM Power, and\n    theoretical tools for reasoning about x86-TSO programs. [2\n    blocks]</li>\n<li><strong>High-level languages</strong>. An introduction to\n    C/C++11 and Java shared-memory concurrency. [1 block]</li>\n</ul>\n<p>Part 2: Concurrent algorithms [Dr T. Harris]</p>\n<ul>\n<li><strong>Concurrent programming</strong>. Simple algorithms\n    (readers/writers, stacks, queues) and correctness criteria\n    (linearisability and progress properties). Advanced\n    synchronisation patterns (e.g. some of the following:\n    optimistic and lazy list algorithms, hash tables,\n    double-checked locking, RCU, hazard pointers), with discussion\n    of performance and on the interaction between algorithm design\n    and the underlying relaxed memory models. [3 blocks]</li>\n<li><strong>Research topics</strong>, likely to include one\n    hour on transactional memory and one guest lecture. [1\n    block]</li>\n</ul>\n<h2>Objectives</h2>\n<p>By the end of the course students should:</p>\n<ul>\n<li>have a good understanding of the semantics of concurrent\n    programs, both at the multprocessor level and the C/Java\n    programming language level;</li>\n<li>have a good understanding of some key concurrent\n    algorithms, with practical experience.</li>\n</ul>\n<h2>Assessment - Part II Students</h2>\n<p>Two assignments each worth 50%</p>\n<h2>Recommended reading</h2>\n<p>Herlihy, M. and Shavit, N. (2008). <em>The art of\n  multiprocessor programming</em>. Morgan Kaufmann.</p>\n", "course_name": "Multicore Semantics and Programming", "course_code": "L304", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L304", "lecturers": ["pes20", "tlh20", "cp526"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "R02": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module aims to provide the world with more network\n  architects. The 2011-2012 version was oriented around the\n  evolution of IP to support new services like multicast, mobility,\n  multihoming, pub/sub and, in general, data oriented networking.\n  The course is a <em>paper reading</em> which puts the onus on the\n  student to do the work.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>IPng [2 lectures, Jon Crowcroft]</li>\n<li>New Architectures [2 lectures, Jon Crowcroft]</li>\n<li>Multicast [2 lectures, Jon Crowcroft]</li>\n<li>Content Distribution and Content Centric Networks [2\n    lectures, Jon Crowcroft]</li>\n<li>Resource Pooling [2 lectures, Jon Crowcroft]</li>\n<li>Green Networking [2 lectures, Jon Crowcroft]</li>\n<li>Alternative Router Implementions [2 lectures, Jon\n    Crowcroft]</li>\n<li>Data Center Networks [2 Lectures, Jon Crowcroft]</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should be able to:</p>\n<ul>\n<li>contribute to new network system designs;</li>\n<li>engineer evolutionary changes in network systems;</li>\n<li>identify and repair architectural design flaws in networked\n    systems;</li>\n<li>see that there are no perfect solutions (aside from\n    academic ones) for routing, addressing, naming;</li>\n<li>understand tradeoffs in modularisation and other pressures\n    on clean software systems implementation, and see how the world\n    is changing the proper choices in protocol layering, or non\n    layered or cross-layered.</li>\n</ul>\n<h2>Coursework</h2>\n<p>Assessment is through three graded essays (each chosen\n  individually from a number of suggested or student-chosen\n  topics), as follows:</p>\n<ol>\n<li>Analysis of two different architectures for a particular\n    scenario in terms of cost/performance tradeoffs for some\n    functionality and design dimension, for example:\n      <ul>\n<li>ATM \u2013 e.g. for hardware <em>versus</em> software\n        tradeoff</li>\n<li>IP \u2013 e.g. for mobility, multi-homing, multicast,\n        multipath</li>\n<li>3GPP \u2013 e.g. for plain complexity <em>versus</em>\n        complicatedness</li>\n</ul>\n</li>\n<li>A discursive essay on a specific communications systems\n    component, in a particular context, such as <em>ad hoc</em>\n    routing, or wireless sensor networks.</li>\n<li>A bespoke network design for a narrow, well specified\n    specialised target scenario, for example:\n      <ul>\n<li>A customer baggage tracking network for an\n        airport.</li>\n<li>in-flight entertainment system.</li>\n<li>in-car network for monitoring and control.</li>\n<li>inter-car sensor/control network for automatic\n        highways.</li>\n</ul>\n</li>\n</ol>\n<h2>Practical work</h2>\n<p>This course does not feature any implementation work due to\n  time constraints.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Three 1,200-word essays (worth 25% each), and</li>\n<li>an annotated bibliography (25%).</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Pre-course reading:</p>\n<p>Keshav, S. (1997). <em>An engineering approach to computer\n  networking</em>. Addison-Wesley (1st ed.). ISBN 0201634422<br/>\n  Peterson, L.L. and Davie, B.S. (2007). <em>Computer networks: a\n  systems approach</em>. Morgan Kaufmann (4th ed.).</p>\n<p>Design patterns:</p>\n<p>Day, John (2007). <em>Patterns in network architecture: a\n  return to fundamentals</em>. Prentice Hall.</p>\n<p>Example systems:</p>\n<p>Krishnamurthy, B. and Rexford, J. (2001). <em>Web protocols\n  and practice: HTTP/1.1, Networking protocols, caching, and\n  traffic measurement</em>. Addison-Wesley.</p>\n<p>Economics and networks:</p>\n<p>Frank, Robert H. (2008). <em>The economic naturalist: why\n  economics explains almost everything</em>.</p>\n<p>Papers:</p>\n<p>Certainly, a collection of papers (see <a href=\"http://ccr.sigcomm.org/\">ACM CCR</a> which publishes notable\n  network researchers' favourite ten papers every 6 months or\n  so).</p>\n", "course_name": "Network Architectures", "course_code": "R02", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R02", "lecturers": ["jac22"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L90": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course introduces the fundamental techniques of natural\n  language processing. It aims to explain the potential and the\n  main limitations of these techniques. Some current research\n  issues are introduced and some current and potential applications\n  discussed and evaluated. Students will also be introduced to\n  practical experimentation in natural language processing.</p>\n<h2>Lectures</h2>\n<ul>\n<li><strong>Overview.</strong>\u00a0Brief history\n    of\u00a0NLP\u00a0research, some current applications,\n    components of\u00a0NLP\u00a0systems.</li>\n<li><strong>Morphology and Finite State\n    Techniques.</strong>\u00a0Morphology in different languages,\n    importance of morphological analysis in\u00a0NLP, finite-state\n    techniques in\u00a0NLP.</li>\n<li><strong>Part-of-Speech Tagging and Log-Linear\n    Models.</strong>\u00a0Lexical categories, word tagging, corpora\n    and annotations, empirical evaluation.</li>\n<li><strong>Phrase Structure and Structure\n    Prediction.</strong>\u00a0Phrase structures, structured\n    prediction, context-free grammars, weights and probabilities.\n    Some limitations of context-free grammars.</li>\n<li><strong>Dependency Parsing.</strong>\u00a0Dependency\n    structure, grammar-free parsing,\n    incremental\u00a0processing.\u00a0</li>\n<li><strong>Gradient Descent and Neural\n    Nets.</strong>\u00a0Parameter optimisation by gradient descent.\n    Non-linear functions with neural network layers. Log-linear\n    model as softmax layer. Current findings of\n    Neural\u00a0NLP.</li>\n<li><strong>Word representations</strong>. Representing words\n    with vectors, count-based\u00a0and prediction-based approaches,\n    similarity metrics.</li>\n<li><strong>Recurrent Neural Networks.</strong>\u00a0Modelling\n    sequences, parameter sharing in recurrent neural networks,\n    neural\u00a0language\u00a0models, word prediction.</li>\n<li><strong>Compositional Semantics.</strong>\u00a0Logical\n    representations, compositional semantics, lambda calculus,\n    inference and robust entailment.</li>\n<li><strong>Lexical Semantics.</strong>\u00a0Semantic\n    relations, WordNet, word senses.</li>\n<li><strong>Discourse.</strong>\u00a0Discourse relations,\n    anaphora resolution, summarization.</li>\n<li>\n<strong>Natural\u00a0Language\u00a0Generation.</strong>\u00a0Challenges\n    of\u00a0natural\u00a0language\u00a0generation (NLG), tasks in\n    NLG, surface\u00a0realisation.</li>\n<li><strong>Practical and assignments.</strong>\u00a0Students\n    will build\n    a\u00a0natural\u00a0language\u00a0processing\u00a0system which\n    will be trained and evaluated on supplied data. The system will\n    be built from existing components, but students will be\n    expected to compare approaches and\n    some\u00a0programming\u00a0will be required for this. Several\n    assignments will be set during the practicals for\n    assessment.</li>\n</ul>\n<h2>Objectives</h2>\n<p>By the end of the course students should:</p>\n<ul>\n<li>be able to discuss the current and likely future\n    performance of several NLP applications;</li>\n<li>be able to describe briefly a fundamental technique for\n    processing language for several subtasks, such as morphological\n    processing, parsing, word sense disambiguation etc.;</li>\n<li>understand how these techniques draw on and relate to other\n    areas of computer science.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Jurafsky, D. &amp; Martin, J. (2023).\u00a0<em>Speech and\n  language processing</em>. Prentice Hall (3rd ed. draft, <a href=\"https://web.stanford.edu/~jurafsky/slp3/\" target=\"_blank\">online</a>).</p>\n<h2>Assessment - Part II Students</h2>\n<ul>\n<li>Assignment 1 - 10% of marks</li>\n<li>Assignment 2 - 25% of marks</li>\n<li>Assignment 3 - 65% of marks</li>\n</ul>\n", "course_name": "Overview of Natural Language Processing", "course_code": "L90", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L90", "lecturers": ["ws390"], "lectures": 18, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "P342": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This is an advanced course in human-computer interaction, with\n  a specialist focus on intelligent user interfaces and interaction\n  with machine-learning and artificial intelligence technologies.\n  The format will be largely Practical, with students carrying out\n  a mini-project involving empirical research investigation. These\n  studies will investigate human interaction with some kind of\n  model-based system for planning, decision-making, automation etc.\n  Possible study formats might include: System evaluation, Field\n  observation, Hypothesis testing experiment, Design intervention\n  or Corpus analysis, following set examples from recent research\n  publications. Project work will be formally evaluated through a\n  report and presentation.</p>\n<h2>Lectures</h2>\n<p>(note that Lectures 2-7 also include one hour class discussion\n  of practical work)<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Current research\n  themes in intelligent user interfaces<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Program\n  synthesis<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Mixed initiative\n  interaction<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Interpretability /\n  explainable AI<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Labelling as a\n  fundamental problem<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Machine learning\n  risks and bias<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Visualisation and\n  visual analytics<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 Student research\n  presentations</p>\n<h2>Objectives</h2>\n<p>By the end of the course students should:<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 be familiar with\n  current state of the art in intelligent interactive systems<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 understand the human\n  factors that are most critical in the design of such systems<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 be able to evaluate\n  evidence for and against the utility of novel systems<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 have experience of\n  conducting user studies meeting the quality criteria of this\n  field<br/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u2022 be able to write up\n  and present user research in a professional manner</p>\n<h2>Class Size</h2>\n<p>This module can accommodate upto 20 Part II, Part III and\n  MPhil students.</p>\n<h2>Recommended reading</h2>\n<p>Brad A. Myers and Richard McDaniel (2000). <a href=\"http://web.media.mit.edu/~lieber/Your-Wish/03-Myers.pdf\">Demonstrational\n  Interfaces: Sometimes You Need a Little Intelligence, Sometimes\n  You Need a Lot</a>.</p>\n<p>Alan Blackwell (2024). <a href=\"https://moralcodes.pubpub.org\">Moral Codes:\u00a0Designing\n  alternatives to AI</a></p>\n<h2>Assessment - Part II Students</h2>\n<p>The format will be largely practical, with students carrying\n  out an individual mini-project involving empirical research\n  investigation.</p>\n<p>Assignment 1: six incremental submissions which\u00a0together\n  contribute 20% to the final module mark.</p>\n<p>Assignment 2: Final report - 80% of the final module mark<br/>\n  \u00a0</p>\n", "course_name": "Practical Research in Human-centred AI", "course_code": "P342", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/P342", "lecturers": ["afb21"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L46": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course will examine the emerging principles and\n  methodologies that underpin scalable and efficient machine\n  learning systems. Primarily, the course will focus on an exciting\n  cross-section of algorithms and system techniques that are used\n  to support the training and inference of machine learning models\n  under a spectrum of computing systems that range from constrained\n  embedded systems up to large-scale distributed systems. It will\n  also touch upon the new engineering practices that are developing\n  in support of such systems at scale. When needed to appreciate\n  issues of scalability and efficiency, the course will drill down\n  to certain aspects of computer architecture, systems software and\n  distributed systems and explore how these interact with the usage\n  and deployment of state-of-the-art machine learning.</p>\n<h2>Syllabus</h2>\n<p>Topics covered may include the following, with confirmation a\n  month before the course begins:</p>\n<ul>\n<li>System Performance Trade-offs</li>\n<li>Distributed Learning Algorithms\u00a0</li>\n<li>Model Compression\u00a0</li>\n<li>Deep Learning Compilers\u00a0</li>\n<li>Frameworks and Run-times\u00a0</li>\n<li>Scalable Inference Serving\u00a0</li>\n<li>Development Practices\u00a0</li>\n<li>Automated Machine Learning\u00a0</li>\n<li>Federated Learning\u00a0</li>\n</ul>\n<p>Primarily, topics are covered with conventional lectures.\n  However, where appropriate, material will be delivered through\n  hands-on lab tutorials. Lab tutorials will make use of hardware\n  including ARM microcontrollers and multi-GPU machines to explore\n  forms of efficient machine learning (any necessary equipment will\n  be provided to students)</p>\n<h2>Assessment</h2>\n<p>Each student will be assessed on 3 labs which will be worth\n  30% of their grade. They will also undertake a written project\n  report which will be worth\u00a070% of the grade. This report\n  will detail an investigation into a particular aspect of machine\n  learning systems, this report will be made available\n  publicly.</p>\n", "course_name": "Principles of Machine Learning Systems", "course_code": "L46", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L46", "lecturers": [], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": true, "lent": false, "easter": false}, "L341": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p><em>Systems research</em> refers to the study of a broad range\n  of behaviours arising from complex system design, including:\n  low-level operating systems; resource sharing and scheduling;\n  interactions between hardware and software; network-protocol\n  design and implementation; separation of mutually distrusting\n  parties on a common platform; and control of distributed-system\n  behaviours such as concurrency and data replication. This module\n  will:</p>\n<ol>\n<li>Teach systems-analysis methodology and practice through\n    tracing and performance profiling experiments;</li>\n<li>Expose students to real-world systems artefacts such as\n    I/O, IPC,and network-stack implementations, and consider their\n    hardware-software interactions with CPUs;</li>\n<li>Develop scientific experimentation, analysis and\n    presentation skills through a series of laboratory assignments;\n    and</li>\n<li>Assign a selection of original research papers to give\n    insight into potential research topics and approaches.</li>\n</ol>\n<p>The teaching style will blend lectures and hands-on labs that\n  teach methodology, design principles, and practical skills.\n  Students will be taught about (and assessed via) a series of\n  lab\u00a0assignments based on practical work. The systems studied\n  are real, and all wires will be live.</p>\n<h2>Prerequisites</h2>\n<p>It is strongly recommended that students:</p>\n<ol>\n<li>Have previously (and successfully) completed an\n    undergraduate operating-system course\n     -- or have equivalent experience\n    through project or open-source work.</li>\n<li>Have reasonable comfort with the C and Python programming\n    languages. C is the primary implementation language for systems\n    that we will analyse, requiring reading fluency; userspace C\n    programs will also be written and extended as part of lab\n    exercises. Python will be used as our data-collection and\n    processing language, and provides useful tools for data\n    analysis and presentation.</li>\n<li>Review an undergraduate operating-system textbook (such as\n    the 'Dinosaur Book') to ensure that basic OS concepts such as\n    the <em>process model</em>, <em>inter-process\n    communication</em>, <em>filesystems</em>, <em>network\n    stacks</em>, and <em>virtual memory</em> are familiar.</li>\n</ol>\n<h2>Syllabus</h2>\n<p>The sessions are split up into three submodules:</p>\n<ol>\n<li>\n<strong>Introduction to kernels and kernel\n      tracing/analysis</strong>\n<p>The purpose of this submodule is to introduce students to\n      the structure of a contemporary operating system kernel\n      through tracing and profiling.</p>\n<ul>\n<li><strong>Lecture 1:</strong> Introduction: OSes, Systems\n        Research, tracing and this course</li>\n<li><strong>Lecture 2:</strong> Kernels and Tracing</li>\n<li><strong>Lab 1:</strong>\u00a0Getting Started with\n        Kernel TRacing</li>\n</ul><br/>\n</li>\n<li>\n<strong>The\u00a0Process Model</strong>\n<p>This submodule introduces students to concrete\n      implications of the UNIX process model: processes and threads\n      in both userspace and kernelspace, the hardware foundations\n      for kernel and process isolation, system calls, and\n      traps.</p>\n<ul>\n<li><strong>Lecture 3:</strong> The Process Model (1)</li>\n<li><strong>Lecture 4:</strong> The Process Model (2)</li>\n<li><strong>Lab 3:</strong> IPC</li>\n</ul><br/>\n</li>\n<li>\n<strong>TCP</strong>\n<p>This submodule introduces students to a\n      contemporary\u00a0network stack, with a particular interest\n      in the TCP protocol. abs will consider both the behaviour of\n      a single TCP connection, exploring the TCP state machine,\n      socket-buffer interactions with flow control, and TCP\n      congestion control. Students will use DUMMYNET to simulate\n      network latency and explore how TCP slow start and congestion\n      avoidance respond to network conditions. The second marked\n      lab assignment will be written.</p>\n<ul>\n<li><strong>Lecture 5:</strong> The Network Stack (1)</li>\n<li><strong>Lecture 6:</strong> The Network Stack (2)</li>\n<li><strong>Lab 3:</strong> TCP</li>\n</ul>\n</li>\n</ol>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>Have a good understanding of high-level OS kernel\n    structure</li>\n<li>Gained insight into hardware-software interactions for\n    compute and I/O</li>\n<li>Have practical skills in system tracing and performance\n    analysis</li>\n<li>Have been exposed to research ideas in system structure and\n    behaviour</li>\n<li>Have learned how to perform systems-style performance\n    evaluations</li>\n<li>Have learned how to present systems evaluation results</li>\n</ul>\n<h2>Recommended reading</h2>\n<h3>Primary module texts</h3>\n<p>Course texts provide instruction on statistics,\n  operating-system design and implementation, and system tracing.\n  You will be asked to read selected chapters from these, but will\n  likely find other content in them useful as you proceed with the\n  labs.</p>\n<p>Marshall Kirk McKusick, George V. Neville-Neil, and Robert N.\n  M. Watson. <em>The Design and Implementation of the FreeBSD\n  Operating System, 2nd Edition</em>, Pearson Education, Boston,\n  MA, USA, September 2014.</p>\n<p>Brendan Gregg and Jim Mauro. <em>DTrace: Dynamic Tracing in\n  Oracle Solaris, Mac OS X and FreeBSD</em>, Prentice Hall Press,\n  Upper Saddle River, NJ, USA, April 2011.</p>\n<h3>Additional texts</h3>\n<p>Abraham Silberschatz, Peter Baer Galvin, and Greg Gagne,\n  <em>Operating System Concepts, Eighth Edition</em>, John Wiley\n  and Sons, Inc., New York, NY, USA, July 2008.</p>\n<p>Brendan Gregg. <em>Systems Performance: Enterprise and the\n  Cloud</em>, Prentice Hall Press, Upper Saddle River, NJ, USA,\n  October 2013.</p>\n<h3>Research-paper readings</h3>\n<p>Research-paper readings will be announced as the terms\n  proceed, but will likely include original papers on BPF, DTrace,\n  OS scheduling, OS scalability, network stacks, and systems\n  modelling.</p>\n<h2>Assessment - Part II Students</h2>\n<ul>\n<li>Exercise 1: Getting started with Kernel tracing 20%</li>\n<li>Exercise 2:\u00a0Inter-Process Communication Performance\n    30%</li>\n<li>Exercise 3: TCP 50%</li>\n</ul>\n", "course_name": "Advanced Operating Systems", "course_code": "L341", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L341", "lecturers": ["rnw24"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L118": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Teaching</h2>\n<p>The teaching style will be lecture-based, but supported by a\n  practical component where students will learn to use a proof\n  assistant for higher category theory, and build a small portfolio\n  of proofs. Towards the end of the course we will explore some of\n  the exciting computer science research literature on monoidal and\n  higher categories, and students will choose a paper and present\n  it to the class.</p>\n<h2>Aims</h2>\n<p>The module will introduce advanced topics in category theory.\n  The aim is to train students to engage and start modern research\n  on the mathematical foundations of higher categories, the\n  graphical calculus, monoids and representations, type theories,\n  and their applications in theoretical computer science, both\n  classical and quantum.</p>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>Be familiar with the techniques of compositional category\n    theory.</li>\n<li>Have a strong understanding of basic categorical semantic\n    models.</li>\n<li>Begun exploring current research in monoidal categories and\n    higher structures.</li>\n</ul>\n<h2>Syllabus</h2>\n<p>Part 1, lecture course:<br/>\n  The first part of the course introduces concepts from monoidal\n  categories and higher categories, and explores their application\n  in computer science.<br/>\n  \u2010 Monoidal categories and the graphical calculus<br/>\n  \u2010 The proof assistant homotopy.io<br/>\n  \u2010 Coherence theorems and higher category theory<br/>\n  \u2010 Linearity, superposition, duality, quantum entanglement<br/>\n  \u2010 Monoids, Frobenius algebras and bialgebras<br/>\n  \u2010 Type theory for higher category theory</p>\n<p>Part 2, exploring the research frontier:<br/>\n  In the second part of the course, students choose a research\n  paper to study, and give a presentation to the class.<br/>\n  There is a nice varied literature related to the topics of the\n  course, and the lecturer will supply a list of suggested\n  papers.\u00a0</p>\n<h2>Classes</h2>\n<p>There will be four exercise sheets for homework, with\n  accompanying\u00a0classes by a teaching assistant to go over\n  them.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Problem sheets (50%)</li>\n<li>Class presentation (20%)</li>\n<li>Practical portfolio (30%)</li>\n</ul>\n<h2>Reading List</h2>\n<p>Chris Heunen and Jamie Vicary, \u201cCategory for Quantum Theory:\n  An Introduction\u201d, Oxford\u00a0University Press</p>\n", "course_name": "Advanced Topics in Category Theory", "course_code": "L118", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L118", "lecturers": ["jv258"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R01": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2><strong>Class limit</strong></h2>\n<p>Maximum 12 students; mininum 6 students</p>\n<h2>Aims</h2>\n<p>This module will attempt to provide an overview of \u201csystems\u201d\n  research. This is a very broad field which has existed for over\n  50 years and which has historically included areas such as\n  operating systems, database systems, file systems, distributed\n  systems and networking, to name but a few. The course will thus\n  necessarily cover only a tiny subset of the field.</p>\n<p>Many good ideas in systems research are the result of\n  discussing and debating previous work. A primary aim of this\n  course therefore will be to educate students in the art of\n  <em>critical thinking</em>: the ability to argue for and/or\n  against a particular approach or idea. This will be done by\n  having students read and critique a set of papers each week. In\n  addition, each week will include presentations from a number of\n  participants which aim to advocate or criticise each piece of\n  work.</p>\n<h2>Syllabus</h2>\n<p>The syllabus for this course will vary from year to year so as\n  to cover a mixture of older and more contemporary systems papers.\n  Contemporary papers will be generally selected from the past 5\n  years, primarily drawn from high quality conferences such as\n  SOSP, OSDI, ASPLOS, FAST, NSDI and EuroSys. Example topics might\n  include:</p>\n<ul>\n<li><em>Systems Research and System Design</em></li>\n<li><em>OS Structure and Virtual Memory</em></li>\n<li><em>Virtualisation</em></li>\n<li><em>Consensus</em></li>\n<li><em>Scheduling</em></li>\n<li><em>Privacy</em></li>\n<li><em>Data Intensive Computing</em></li>\n<li><em>Bugs</em></li>\n</ul>\n<p>The reading each week will involve a load equivalent to 3 full\n  length papers. Students will be expected to read these in detail\n  and prepare a written summary and review. In addition, each week\n  will contain one or more short presentations by students for each\n  paper. The types of presentation will include:</p>\n<ul>\n<li><strong>Overview</strong>: a balanced presentation of the\n    paper, covering both positive and negative aspects.</li>\n<li><strong>Advocacy</strong>: a positive spin on the paper,\n    aiming to convince others of its value.</li>\n<li><strong>Criticism</strong>: a negative take on the paper,\n    focusing on its weak spots and omissions.</li>\n</ul>\n<p>These presentation roles will be assigned in advance,\n  regardless of the <em>soi disant</em> absolute merit of the paper\n  or the preference of the student. Furthermore, all students \u2013\n  regardless of any assigned presentation role in a given week \u2013\n  will be expected to participate in the class by asking questions\n  and generally entering into the debate.</p>\n<h2>Objectives</h2>\n<p>On completion of this module students should have a broad\n  understanding of some key papers and concepts in computer systems\n  research, as well as an appreciation of how to argue for or\n  against any particular idea.</p>\n<h2>Coursework and practical work</h2>\n<p>Coursework will be the production of the weekly paper reviews.\n  Practical work will be presenting papers as appropriate, as well\n  as ongoing participation in the class.</p>\n<h2>Assessment</h2>\n<p>Assessment consists of:</p>\n<ul>\n<li>One essay per week for 7 weeks (10% each)</li>\n<li>Presentation (20%)</li>\n<li>Participation in class over the term (10%)</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Most of the reading for this course will be in the form of the\n  selected papers each week. However, the following may be useful\n  background reading to refresh your knowledge from undergraduate\n  courses:</p>\n<p>Silberschatz, A., Peterson, J.L. and Galvin, P.C. (2005).\n  <em>Operating systems concepts</em>. Addison-Wesley (7th\n  ed.).</p>\n<p>Tanenbaum, A.S. (2008). <em>Modern Operating Systems</em>.\n  Prentice-Hall (3rd ed.).</p>\n<p>Bacon, J. and Harris, T. (2003). <em>Operating systems</em>.\n  Addison-Wesley (3rd ed.).</p>\n<p>Anderson, T. and Dahlin, M. (2014). <em>Operating Systems:\n  Principles and Practice</em>. Recursive Books (2nd ed.).</p>\n<p>Hennessy, J. and Patterson, D. (2006). <em>Computer\n  architecture: a quantitative approach</em>. Elsevier (4th ed.).\n  ISBN\u00a0978-0-12-370490-0.</p>\n<p>Kleppmann M (2016) <em>Designing Data-Intensive\n  Applications</em>, O'Reilly (1st ed.)</p>\n", "course_name": "Advanced Topics in Computer Systems", "course_code": "R01", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R01", "lecturers": ["rmm1002"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R255": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course explores current research topics in machine\n  learning\u00a0in sufficient depth that, at the end of the course,\n  participants will be in a position to contribute to research on\n  their chosen topics. Each topic will be introduced with a lecture\n  which, building on the material covered in the prerequisite\n  courses, will make the current research literature accessible.\n  Each lecture will be followed by up to three sessions which will\n  typically be run as a reading group with student presentations on\n  recent papers from the literature followed by a discussion, or a\n  practical, or similar.</p>\n<h2>Structure</h2>\n<p>Each student will attend 3 topics and each topic's sessions\n  will be spread over 5 contact hours. Students will be expected to\n  undertake readings for their selected topics. There will be some\n  group work.</p>\n<p>There will be a briefing session in Michaelmas term.</p>\n<h2>Syllabus</h2>\n<p>Students choose five\u00a0<strong>topics</strong>\u00a0in\n  preferential order from a list to be published in Michaelmas\n  term. They will be assigned to three topics out of their list.\n  Students are assessed on one of these topics which may\u00a0not\n  necessarily be their first choice topic.</p>\n<p>The topics to be offered in 2023-24 are yet to be decided but\n  to give an indicative idea of the types of topics, the ones\n  offered\u00a0in 2022-23 were:</p>\n<ol start=\"1\">\n<li>Imitation learning\u00a0<em>Dr A. Vlachos</em></li>\n<li>Machine Learning for Collective intelligence <em>Prof A.\n    Prorok</em></li>\n<li>Bias in datasets\u00a0<em>Dr M.\u00a0Tomalin</em></li>\n<li>Probabilistic Numerics: Computation as Machine\n    Learning\u00a0<em>Dr C. H.\u00a0Ek</em></li>\n<li>Explainable AI <em>Prof M. Jamnik</em></li>\n<li>Unconventional approaches to AI\u00a0<em>Dr S.\n    Banerjee</em></li>\n<li>Bias, Variance and Fairness: Stochasticity in Decision\n    Making\u00a0<em>Prof N.\u00a0Lawrence</em></li>\n<li>Physics and Geometry in Machine Learning\u00a0<em>Dr\n    C.\u00a0Mishra</em></li>\n<li>AI Safety\u00a0<em>Dr F.\u00a0Huszar and\n    N.\u00a0Rajkumar</em></li>\n<li>Diffusion Models and SDEs\u00a0<em>Dr C.\u00a0H.\u00a0Ek\n    and F.\u00a0Vargas</em></li>\n</ol>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>be in a strong position to contribute to the research\n    topics covered;</li>\n<li>understand the fundamental methods (algorithms, data\n    analysis, specific tasks) underlying each topic;</li>\n<li>and be familiar with recent research papers and advances in\n    the field.</li>\n</ul>\n<h2>Coursework</h2>\n<p>Students will typically work in groups to give a presentation\n  on assigned papers.\u00a0Alternatively, a topic may include\n  practical sessions.\u00a0Each topic will typically consist of one\n  preliminary lecture followed by 3 reading and discussion\n  sessions, or several lectures followed by a practical session. A\n  typical topic can accommodate up to 9 students presenting papers.\n  There will be at least 10 minutes general discussion per\n  session.</p>\n<p>Full coursework details will be published by October.</p>\n<h2>Assessment</h2>\n<p>Coursework will be marked by the topic leaders and second\n  marked by the module conveners.</p>\n<ul>\n<li>Participation in all assigned\u00a0topics, 10%</li>\n<li>Presentation or practical work or similar (for one of the\n    chosen topics), 20%</li>\n<li>Topic coursework (for one of the chosen\u00a0topics),\n    70%</li>\n</ul>\n<p>Individual topic coursework will be published late Michaelmas\n  term.</p>\n<p>Assessment criteria for topic coursework will follow project\n  assessment criteria here:\u00a0<a href=\"https://www.cl.cam.ac.uk/teaching/exams/acs_project_marking.pdf\" style=\"color:blue; text-decoration:underline\">https://www.cl.cam.ac.uk/teaching/exams/acs_project_marking.pdf</a></p>\n<p><em>Please note that students will be assessed on one of their\n  three chosen topics\u00a0but this may not\n  be\u00a0their\u00a0first choice</em>.</p>\n<h2>Recommended reading</h2>\n<p>To be confirmed by each topic convenor.</p>\n", "course_name": "Advanced topics in machine learning", "course_code": "R255", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R255", "lecturers": ["mj201"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L44": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Computationally analysing and modelling people's\n  socio-emotional behaviours is very important for multiple domains\n  such as enhancing human-AI, human-agent and human-robot\n  interactions; creating personalized learning environments,\n  behavioural analytics for assessing and improving people\u2019s\n  comfort, healthcare and wellbeing; designing engaging and\n  adaptive training environments and games, etc.</p>\n<p>Accordingly, the aim of this module is to impart knowledge and\n  ability needed to make informed choices of models, data, and\n  machine learning techniques for sensing, recognition, and\n  generation of affective and social behaviour (e.g., smile, frown,\n  head nodding/shaking, agreement/disagreement), and its use in the\n  design of innovative interactive technology (e.g., interaction\n  with virtual agents, robots, and games; single and multi-user\n  smart environments, e.g., in-car/ virtual / augmented reality,\n  for public speaking and cognitive training; clinical and\n  biomedical studies, e.g., autism, depression, pain) while\n  addressing the ethical issues (e.g., privacy, bias) arising from\n  the real-world deployment of these systems</p>\n<h2>Syllabus</h2>\n<p>The following list provides a representative list of\n  topics:</p>\n<ul>\n<li>Introduction, definitions, and overview</li>\n<li>Emotion theories</li>\n<li>Sensing from multiple modalities (e.g., vision, audio, bio\n    signals, text)</li>\n<li>Data acquisition and annotation</li>\n<li>Signal processing / feature extraction</li>\n<li>Automatic recognition / prediction and evaluation</li>\n<li>Behaviour synthesis / generation (e.g., for embodied agents\n    / robots)</li>\n<li>Emotional design frameworks</li>\n<li>Advanced topics and ethical considerations (e.g., bias and\n    fairness)</li>\n<li>Applications (via seminar presentations and\n    discussions)</li>\n<li>Guest lectures (various topics - e.g., commercialising\n    affective computing products)</li>\n<li>Hands-on programming work (i.e., mini-project)</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students will:</p>\n<ul>\n<li>Understand the challenges in human-human affective and\n    communicative interaction (e.g. not<br/>\n    what is said but how it is said \u2013 using the body, head, face,\n    intonation, etc.) and its implication to<br/>\n    human-computer interaction;</li>\n<li>Demonstrate knowledge in current theories and trends in\n    designing emotionally and socially<br/>\n    sensitive interactive technology, as well as recent advances in\n    human audio/visual/bio signal<br/>\n    processing, and recognition using machine learning\n    techniques;</li>\n<li>Comprehend and apply (appropriate) methods for collection,\n    analysis, representation and<br/>\n    evaluation of human affective and communicative behaviour\n    data;</li>\n<li>Demonstrate ability to computationally analyse, recognise\n    and evaluate human affective and<br/>\n    social behaviour;</li>\n<li>Enhance programming skills for human affect and behaviour\n    analysis and understanding;</li>\n<li>Demonstrate critical thinking, analysis and synthesis while\n    making a decision on 'when' and<br/>\n    'how' to incorporate emotions and social signals in a specific\n    application context, and gain<br/>\n    practical experience in proposing and justifying computational\n    solution(s) of suitable nature and<br/>\n    scope.</li>\n</ul>\n<h2>Assessment</h2>\n<p>Seminar presentation: 20%<br/>\n  Participating in Q&amp;A and discussions: 10%<br/>\n  Mini-Project: 70% (proposal, mid-term written report, final\n  written report, code and presentation)</p>\n<h2>Recommended reading</h2>\n<p>Picard, R. (2000). Affective Computing. MIT Press.</p>\n<p>Jeon, M. (2017). Emotions and Affect in Human Factors and\n  Human-Computer Interaction. Academic Press. <a href=\"https://www.elsevier.com/books/emotions-and-affect-in-human-factors-and-human-computer-interaction/jeon/978-0-12-801851-4\" target=\"_blank\">https://www.elsevier.com/books/emotions-and-affect-in-human-factors-and-human-computer-interaction/jeon/978-0-12-801851-4</a></p>\n<p>Calvo, R., D'Mello, S., Gratch, J. and Kappas, A. (2014) The\n  Oxford Handbook of Affective Computing. Oxford University Press.\n  <a href=\"https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199942237.001.0001/oxfordhb-9780199942237\" target=\"_blank\">https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199942237.001.0001/oxfordhb-9780199942237</a></p>\n<p>Tian, L., Oviatt, S., Muszynski, M., Chamberlain, B. C.,\n  Healey, J. &amp; Sano, A. (2022) Applied Affective Computing.\n  Association for Computing Machinery, New York, United\n  States.\u00a0 <a href=\"https://dl.acm.org/doi/book/10.1145/3502398\" style=\"color:#0563c1; text-decoration:underline\">https://dl.acm.org/doi/book/10.1145/3502398</a></p>\n<p><strong>Journals:</strong></p>\n<ol>\n<li>IEEE Transactions on Affective Computing <a href=\"https://www.computer.org/csdl/journal/ta\" target=\"_blank\">https://www.computer.org/csdl/journal/ta</a></li>\n</ol>\n<p><strong>Conference proceedings:</strong></p>\n<ol>\n<li>ACII: Affective Computing and Intelligent\n    Interaction\u00a0<a href=\"https://dblp.org/db/conf/acii/index\" target=\"_blank\">https://dblp.org/db/conf/acii/index</a></li>\n<li>ICMI: ACM International Conference on Multimodal\n    Interaction <a href=\"https://dblp.org/db/conf/icmi/\" target=\"_blank\">https://dblp.org/db/conf/icmi/</a></li>\n<li>FGR: IEEE Conference on Automatic Face and Gesture\n    Recognition <a href=\"https://dblp.org/db/conf/fgr/\" target=\"_blank\">https://dblp.org/db/conf/fgr/</a></li>\n</ol>\n", "course_name": "Affective Computing", "course_code": "L44", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L44", "lecturers": ["hg410"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R254": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This course examines major topics relating to cybercrime from\n  an interdisciplinary perspective. These include offence types and\n  techniques, targets, victimisation, social and financial cost,\n  criminal marketplaces, offenders, detection and prevention, and\n  regulation and policing. The course outlines: key debates in\n  cybercrime research; how crime is committed using computer\n  systems; and provides an understanding of how cybercrime is\n  regulated, policed, detected, and prevented.</p>\n<h2>Syllabus</h2>\n<p>The course will consist of eight two-hour sessions\n  covering:</p>\n<ul>\n<li>Tools and techniques of cybercrime</li>\n<li>Cybercrime victimisation</li>\n<li>Costs and harms of cybercrime</li>\n<li>Criminal marketplaces</li>\n<li>Cybercrime offenders and offender pathways</li>\n<li>Cybercrime prevention (situational and social\n    approaches)</li>\n<li>Regulation and policy</li>\n<li>Cybercrime and the criminal justice system</li>\n</ul>\n<p>\u00a0</p>\n<p>All participants are expected to attend and participate in\n  every class, and to read the specified papers beforehand. The\n  instructor must be notified of any absences in advance.</p>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>Have a broad knowledge of the key themes, debates, theory,\n    and research in relation to cybercrime;</li>\n<li>Have developed further skills in critical analysis;</li>\n<li>Have developed skills in presenting a case study,\n    critically evaluating current issues, and writing about\n    cybercrime;</li>\n<li>Have a sound understanding of strategies to combat and\n    prevent cybercrime;</li>\n<li>Understand the ethical and practical challenges in\n    conducting cybercrime research.</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Please see Course Materials for recommended reading for each\n  session.</p>\n<h2>Assessment - Part II Students</h2>\n<p>You will assessed by 4 essays each worth 25% of the total\n  marks.</p>\n", "course_name": "Cybercrime", "course_code": "R254", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R254", "lecturers": ["ah793", "rja14", "rnc1"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L99": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>Teach theoretical background in linguistics that enables\n  systems to interpret sentences in the context of a task or in the\n  context of a large text, and introduce systems that provide such\n  analyses, when such systems exist. Discourse linguistics concerns\n  tasks such as summarization, language generation, reasoning and\n  text understanding. Pragmatics concerns problems of\n  interpretation of a linguistic signal in the utterance context.\n  Pragmatics concerns tasks such as dialogue systems. Pragmatics\n  and Discourse also affect evaluation of NLP systems. Upon\n  completing the course, students should be aware of the\n  theoretical phenomena in Discourse Linguistics and Pragmatics.\n  Students are prepared for research in building discourse\n  linguistics and pragmatics informed systems. Awareness of the\n  phenomena described the module also enable them to perform better\n  evaluation of NLP systems, for instance by identifying semantic\n  problems in NLP system output \u00a0which are not based on the\n  sentence semantics itself, but on the larger context.</p>\n<h2>Format</h2>\n<p>The house is half lecture, half reading class. There are 8\n  sessions. Each session consists of a one-hour lecture followed by\n  a student presentation of a paper and discussion of that paper\n  and related papers.</p>\n<h2>Topics</h2>\n<p>Session 1: Reference and Pronoun Resolution<br/>\n  Session 2: Speech Acts<br/>\n  Session 3: Coherence<br/>\n  Session 4: Grice's Maximes<br/>\n  Session 5: Entailment and Presupposition<br/>\n  Session 6: Information Status<br/>\n  Session 7: Inferential Relations<br/>\n  Session 8: Discourse Representation Theory (DRT)</p>\n<h2>Assessment</h2>\n<ul>\n<li>20% Presentation</li>\n<li>80% Coursework, to be delivered in 3 assessed homeworks\n    (week 3, 5 and 7):\n      <ul>\n<li>Homework 1: 20%\u00a0</li>\n<li>Homework 2: 20%\u00a0</li>\n<li>Homework 3: 40%\u00a0</li>\n</ul>\n</li>\n</ul>\n<p>Full details to follow by early Michalemas term.</p>\n", "course_name": "Discourse and Pragmatics", "course_code": "L99", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L99", "lecturers": ["sht25", "ws390"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R47": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This reading group course examines foundations and current\n  research into distributed ledger (blockchain) technologies and\n  their applications. Students will read, review, and present\n  seminal research papers in this area. Once completed, students\n  should be able to integrate blockchain technologies into their\n  own research and gain familiarity with a range of research\n  skills.</p>\n<h2>Lectures</h2>\n<ol>\n<li>Introduction</li>\n<li>Consensus protocols</li>\n<li>Bitcoin and its variants</li>\n<li>Ethereum, smart contracts, and other permissionless\n    DLTs</li>\n<li>Hybrid and permissioned DLTs</li>\n<li>Applications</li>\n</ol>\n<h2>Learning objectives</h2>\n<p>There are two broad objectives: to acquire familiarity with a\n  body of work in the area of distributed ledgers and to learn some\n  specific research skills:</p>\n<ol>\n<li><a href=\"http://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf\" target=\"_blank\">How to read a paper</a></li>\n<li><a href=\"http://pages.cs.wisc.edu/~markhill/the_task_of_the_referee.pdf\" target=\"_blank\">How to review a paper</a></li>\n<li><a href=\"http://blizzard.cs.uwaterloo.ca/keshav/wiki/index.php/Evaluating_a_research_paper\" target=\"_blank\">How to analyze a paper\u2019s strengths and\n    weaknesses</a></li>\n<li><a href=\"http://www-net.cs.umass.edu/kurose/talks/top_10_tips_for_writing_a_paper.ppt\" target=\"_blank\">Written</a> and <a href=\"http://blizzard.cs.uwaterloo.ca/keshav/wiki/index.php/Giving_and_attending_talks\" target=\"_blank\">oral</a> presentation skills</li>\n</ol>\n<h2>Assessment</h2>\n<p>You are expected to read all assigned papers and submit paper\n  reviews\u00a0each week. Each review must either follow the\n  provided review form [<a href=\"https://universityofcambridgecloud-my.sharepoint.com/:b:/g/personal/sk818_cam_ac_uk/ESpwszt8Nr5PtSF5b9GGH4EBT0WLI_z-bj-jPnRd5i2YYw?e=xrDeau\" target=\"_blank\">PDF</a>] [<a href=\"https://universityofcambridgecloud-my.sharepoint.com/:u:/g/personal/sk818_cam_ac_uk/Ecpv3poyjuVKgbvC8fL48jIBRnAGTdVLBFKvMPf2RJjYrw?e=rnWfGE\" target=\"_blank\">Latex source</a>]. Each \u201creview\u201d is worth 5% of\n  your total mark, and is marked out of 100 with 60 a passing\n  grade. Marks will be awarded and penalties for late submission\n  applied according to <a href=\"http://www.cl.cam.ac.uk/teaching/exams/acs_assessment.html\" target=\"_blank\">ACS Assessment Guidelines</a>.\u00a0</p>\n<ul>\n<li>One paper review for the first week, then two paper reviews\n    each week for 6 weeks (13 reviews, 5% each) 65% (approx 600\n    words per review)</li>\n<li>Summative essay 25% (max 3000 words)</li>\n<li>Presentation 5%</li>\n<li>100% attendance in class 5% (2 marks deducted per missed\n    class)</li>\n</ul>\n<h2>Recommended Reading</h2>\n<p>Narayanan, A. , Bonneau, J., Felten, E., Miller, A. and\n  Goldfeder, S. (2016). <em>Bitcoin and Cryptocurrency\n  Technologies: A Comprehensive Introduction</em>. Princeton\n  University Press.<br/>\n  (2016 Draft available here: <a href=\"https://d28rh4a8wq0iu5.cloudfront.net/bitcointech/readings/princeton_bitcoin_book.pdf\" target=\"_blank\">https://d28rh4a8wq0iu5.cloudfront.net/bitcointech/readings/princeton_bitcoin_book.pdf</a>)</p>\n", "course_name": "Distributed Ledger Technologies: Foundations and Applications", "course_code": "R47", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R47", "lecturers": ["sk818"], "lectures": null, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L361": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Objectives</h2>\n<p>This course aims to extend the machine learning knowledge\n  available to students in Part I (or present in typical\n  undergraduate degrees in other universities), and allow them to\n  understand how these concepts can manifest in a decentralized\n  setting. The course will consider both theoretical (e.g.,\n  decentralized optimization) and practical (e.g., networking\n  efficiency) aspects that combine to define this growing area of\n  machine learning.\u00a0</p>\n<p>At the end of the course students should:</p>\n<ul>\n<li>Understand popular methods used in federated learning</li>\n<li>Be able to construct and scale a simple federated\n    system</li>\n<li>Have gained an appreciation of the core limitations to\n    existing methods, and the approaches available to cope with\n    these issues</li>\n<li>Developed an intuition for related technologies like\n    differential privacy and secure aggregation, and are able to\n    use them within typical federated settings\u00a0</li>\n<li>Can reason about the privacy and security issues with\n    federated systems</li>\n</ul>\n<h2>Lectures</h2>\n<ol>\n<li>Course Overview. Introduction to Federated Learning.</li>\n<li>Decentralized Optimization.</li>\n<li>Statistical and Systems Heterogeneity.</li>\n<li>Variations of Federated Aggregation.</li>\n<li>Secure Aggregation.</li>\n<li>Differential Privacy within Federated Systems.</li>\n<li>Extensions to Federated Analytics.</li>\n<li>Applications to Speech, Video, Images and Robotics.</li>\n</ol>\n<h2>Lab sessions</h2>\n<ol>\n<li>Federating a Centralized ML Classifier.</li>\n<li>Behaviour under Heterogeneity.</li>\n<li>Scaling a Federated Implementation.</li>\n<li>Exploring Privacy with Federated Settings</li>\n</ol>\n<h2>Assessment</h2>\n<p>Four labs are performed during the course, and students\n  receive 12.5% of their total grade for work done as part of each\n  lab. (For a total of 50% of the total grade from lab work alone).\n  Labs will primarily provide hands-on teaching opportunities, that\n  are then utilized within the lab assignment which is completed\n  outside of the lab contact time. MPhil and Part III students will\n  be given additional questions to answer within their version of\n  the lab assignment which will differ from the assignment given to\n  Part II CST students.</p>\n<p>The remainder of the course grade (50%) will be given based on\n  a hands-on project that applies the concepts taught in lectures\n  and labs. This hands-on project will be assessed based on upon a\n  combination of source code, related documentation\u00a0and brief\n  8-minute pre-recorded talk that summarizes key project elements\n  (any slides used are also submitted\u00a0as part of the project).\n  Please note, that in the case of Part II CST students, the talk\n  itself is not examinable -- as such will be made optional to\n  those students.</p>\n<p>A range of possible practical projects will be described and\n  offered to students to select from, or alternatively students may\n  propose their own. MPhil and Part III students will select from a\n  project pool that is separate from those offered to Part II CST\n  students. MPhil and Part III projects will contain a greater\n  emphasis on a research element, and the pre-recorded talks\n  provided by this student group will focus on this research\n  contribution. The project will be assessed on the level of\n  student understanding demonstrated, the degree of difficulty,\n  correctness of implementation -- and for Part III/MPhil students\n  the additional criteria of the quality and execution of the\n  research methodology, and depth and quality of results\n  analysis.</p>\n<p>This project can be done individually or in groups -- although\n  individual projects will be strongly encouraged. It will be\n  required the project is performed using a code repository that\n  also will contain all documentation -- access to this repository\n  will be shared with course staff (e.g., lecturer and TAs). Where\n  needed, marks assigned to students within a group will be\n  differentiated using this repository as an input. Furthermore if\n  groups are formed, members must be either entirely from Part\n  III/MPhil students or Part II CST, i.e., these two student groups\n  should not mix to form a project group.</p>\n<p>Projects will be made available publicly. A maximum word count\n  for written contributions for the project will be\n  enforced.\u00a0</p>\n<h2>Recommended Reading</h2>\n<p>Readings will be assigned for each lecture. Readings will be\n  taken from either research papers, tutorials, source code or\n  blogs that provide more comprehensive treatment of taught\n  concepts.</p>\n", "course_name": "Federated Learning: Theory and Practice", "course_code": "L361", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L361", "lecturers": [], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L65": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims and Objectives</h2>\n<p>Most of the patterns we see in nature can be elegantly\n  reasoned about using spatial symmetries\u2014transformations that\n  leave underlying objects unchanged. This observation has had\n  direct implications for the development of modern deep learning\n  architectures that are seemingly able to escape the \u201ccurse of\n  dimensionality\u201d and fit complex high-dimensional tasks from noisy\n  real-world data. Beyond this, one of the most generic\n  symmetries\u2014the permutation\u2014will prove remarkably powerful in\n  building models that reason over graph structured-data, which is\n  an excellent abstraction to reason about naturally-occurring,\n  irregularly-structured data. Prominent examples include molecules\n  (represented as graphs of atoms and bonds, with three-dimensional\n  coordinates provided), social networks and transportation\n  networks. Several already-impacted application areas include\n  traffic forecasting, drug discovery, social network analysis and\n  recommender systems. The module will provide the students the\n  capability to analyse irregularly- and nontrivially-structured\n  data in an effective way, and position geometric deep learning in\n  a proper context with related fields. The main aim of the course\n  is to enable students to make direct contributions to the field,\n  thoroughly assimilate the key concepts in the area, and draw\n  relevant connections to various other fields (such as NLP,\n  Fourier Analysis and Probabilistic Graphical Models). We assume\n  only a basic background in machine learning with deep neural\n  networks.</p>\n<h2>Learning outcomes</h2>\n<ul>\n<li>The framework of geometric deep learning, and its key\n    building blocks: symmetries, representations, invariance and\n    equivariance</li>\n<li>Fundamentals of processing data on graphs, as well as\n    impactful application areas for graph representation\n    learning</li>\n<li>Theoretical principles of graph machine learning:\n    permutation invariance and equivariance</li>\n<li>The three \"flavours\" of spatial graph neural networks\n    (GNNs) (convolutional, attentional, message passing) and their\n    relative merits. The Transformer architecture as a special\n    case.</li>\n<li>Attaching symmetries to graphs: CNNs on images, spheres and\n    manifolds, Geometric Graphs and E(n)-equivariant GNNs</li>\n<li>Relevant connections of geometric deep learning to various\n    other fields (such as NLP, Fourier Analysis and Probabilistic\n    Graphical Models)</li>\n</ul>\n<h2>Lectures</h2>\n<p>The lectures will cover the following topics:</p>\n<ul>\n<li>Learning with invariances and symmetries: geometric deep\n    learning. Foundations of group theory and representation\n    theory.</li>\n<li>Why study data on graphs? Success stories: drug screening,\n    travel time estimation, recommender systems. Fundamentals of\n    graph data processing: network science, spectral clustering,\n    node embeddings.</li>\n<li>Permutation invariance and equivariance on sets and graphs.\n    The principal tasks of node, edge and graph classification.\n    Neural networks for point clouds: Deep Sets, PointNet;\n    universal approximation properties.</li>\n<li>The three flavours of spatial GNNs: convolutional,\n    attentional, message passing. Prominent examples: GCN, SGC,\n    ChebyNets, MoNet, GAT, GATv2, IN, MPNN, GraphNets. Tradeoffs of\n    using different GNN variants.</li>\n<li>Graph Rewiring: how to apply GNNs when there is no graph?\n    Links to natural language processing---Transformers as a\n    special case of attentional GNNs. Representative methodologies\n    for graph rewiring: GDC, SDRF, EGP, DGCNN.</li>\n<li>Expressive power of graph neural networks: the\n    Weisfeiler-Lehman hierarchy. GINs as a maximally expressive\n    GNN. Links between GNNs and graph algorithms: neural\n    algorithmic reasoning.</li>\n<li>Combining spatial symmetries with GNNs: E(n)-equivariant\n    GNNs, TFNs, SE(3)-Transformer. A deep dive into AlphaFold\n    2.</li>\n<li>Worked examples: Circulant matrices on grids, the discrete\n    Fourier transform, and convolutional networks on spheres. Graph\n    Fourier transform and the Laplacian eigenbasis.</li>\n</ul>\n<h2>Practicals</h2>\n<p>The practical is designed to complement the knowledge learnt\n  in lectures and teach students to derive additional important\n  results and architectures not directly shown in lectures. The\n  practical will be given as a series of individual exercises (each\n  either code implementation or proof/derivation). Each of these\n  exercises can be individually assessed based on a specified mark\n  budget.</p>\n<p>Possible practical topics include the study of higher-order\n  GNNs and equivariant message passing.</p>\n<h2>Assessment</h2>\n<ul>\n<li>(60%) Group Mini-project (writeup) at the end of the\n    course. The mini projects can either be self-proposed, or the\n    students can express their preference for one of the provided\n    topics, the list of which will be announced at the start of\n    term. The projects\u00a0will consist of implementing and/or\n    extending graph representation learning models in the\n    literature, applying them to publicly available datasets.\n    Students will undertake the project in pairs and submit a joint\n    writeup limited to 4,000 words (in line with other modules);\n    appendix of work logs to be included but ungraded;</li>\n<li style=\"list-style: none\"><br/></li>\n<li>(10%) Short presentation and viva: students will give a\n    short presentation to explain their individual contribution to\n    the mini-project and there will be a short viva following.</li>\n<li style=\"list-style: none\"><br/></li>\n<li>(30%) Practical work completion. Completing the exercises\n    specified in the practical\u00a0to a satisfactory standard. The\n    practical assessor should be satisfied that the student derived\n    their answers using insight gained from the course; coupled\n    with original thought, not by simple copy-pasting of relevant\n    related work. The students would submit code and a short\n    report, which would then be marked in line with the\n    predetermined mark budget for each practical item.</li>\n</ul>\n<p>The students will learn how to run advanced architectures on\n  GPU but no specific need for dedicated GPU resources. Practicals\n  will be made possible to do on CPU; if required, students can use\n  GPUs on publicly available free services (such as Colab) for\n  their mini-project work.</p>\n<h2>References</h2>\n<p>The course will be based on the following literature:</p>\n<ul>\n<li>\"Geometric Deep Learning: Grids, Graphs, Groups, Geodesics,\n    and Gauges\", by Michael Bronstein, Joan Bruna, Taco Cohen and\n    Petar Veli\u010dkovi\u0107</li>\n<li>\"Graph Representation Learning\", by Will Hamilton</li>\n<li>\"Deep Learning\", by Ian Goodfellow, Yoshua Bengio and Aaron\n    Courville.</li>\n</ul>\n", "course_name": "Geometric Deep Learning", "course_code": "L65", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L65", "lecturers": ["pl219"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L349": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>The course aims to explore how wearable and mobile systems\n  sensors can be used to gather data relevant to understand health,\n  how the data can be analysed with advanced signal processing and\n  machine learning and the performance of these systems in terms of\n  diagnostics and disease progression detection.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>Course Overview. Introduction to Mobile Health. Evaluation\n    metrics and methodology. Basics of Signal Processing.</li>\n<li>Inertial Measurement Units, Human Activity Recognition\n    (HAR) and Gait Analysis and Machine Learning for IMU data.</li>\n<li>Radios, Bluetooth, GPS and Cellular. Epidemiology and\n    contact tracing, Social interaction sensing and\n    applications.\u00a0Location tracking in health monitoring and\n    public health.</li>\n<li>Audio Signal Processing. Voice and Speech Analysis:\n    concepts and data analysis.\u00a0Body Sounds analysis.</li>\n<li>Photoplethysmogram and Light sensing for health (heart and\n    sleep)</li>\n<li>Contactless and wireless behaviour and physiological\n    monitoring</li>\n<li>Mobile Devices and Behaviour intervention</li>\n<li>Topical Guest Lectures</li>\n</ul>\n<h2>Objectives</h2>\n<p>The course aims to explore how wearable and mobile systems\n  sensors can be used to gather data relevant to understand health,\n  how the data can be analysed with advanced signal processing and\n  machine learning and the performance of these systems in terms of\n  diagnostics and disease progression detection.</p>\n<p>Roughly, each lecture contains a theory part about the working\n  of \u201csensor signals\u201d or \u201cdata analysis methods\u201d and an application\n  part which contextualises the concepts.</p>\n<p>At the end of the course students should: Understand how\n  mobile/wearable sensors capture data and their working.\n  Understand different approaches to acquiring and analysing sensor\n  data from different types of sensors. Understand the concept of\n  signal processing applied to time series data and their practical\n  application in health. Be able to extract sensor data and analyse\n  it with basic signal processing and machine learning techniques.\n  Be aware of the different health applications of the various\n  sensor techniques. The course will also touch on privacy and\n  ethics implications of the approaches developed in an orthogonal\n  fashion.</p>\n<h2>Recommended Reading</h2>\n<p>Please see Course Materials for recommended reading for each\n  session.</p>\n<h2>Assessment\u00a0-\u00a0Part II students</h2>\n<p>Two assignments will be based on two datasets which will be\n  provided to the students:</p>\n<p>Assignment 1 (shared for Part II and Part III/MPhil): this\n  will be based on a dataset and will be worth 40% of the final\n  mark. The task of the assessment will be to perform\n  pre-processing and basic data analysis in a \"colab\" and an answer\n  sheet of no more than 1000 words.</p>\n<p>Assignment 2 (Part II): This assignment (worth 60% of the\n  final mark) will be a fuller analysis of a dataset focusing on\n  machine learning algorithms and metrics. Discussion and\n  interpretation of the findings will be reported in a colab and a\n  report of no more than 1200 words.</p>\n", "course_name": "Mobile Health", "course_code": "L349", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L349", "lecturers": ["cm542"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R225": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module is a theoretically-oriented advanced introduction\n  to the broad field of human-computer interaction, extending to\n  consider topics such as intelligent user interfaces, critical and\n  speculative design, participatory design, cognitive models of\n  users, human-centred, as well as more-than-human-centred design,\n  and others. The course will not address purely engineering\n  approaches to the development of user interfaces (unless there is\n  a clear theoretical question being addressed), but allow students\n  to effectively link the political, social, and ethical\n  considerations in HCI to specific technical and conceptual design\n  challenges. The module builds on the Practical Research in\n  Human-Centred AI course offered in Michaelmas (developed with\n  researchers at Microsoft Research Cambridge) and a collaboration\n  with the Leverhulme Centre for the Future of Intelligence at\n  Cambridge. Participants may include visitors from these groups\n  and/or interdisciplinary research students and academic guests\n  from other University departments, including Cambridge Digital\n  Humanities.</p>\n<h2>Syllabus</h2>\n<p>The syllabus will remain broadly within the area of\n  human-computer interaction, including theories of design practice\n  and the social contexts of technology use. Individual seminar\n  topics will be selected in response to contemporary and recent\n  research developments, in consultation with members of the class\n  and visiting contributors.</p>\n<p>\u00a0</p>\n<p>Representative topics in the next year are likely to\n  include:</p>\n<ul>\n<li>Evaluation methods for interactive systems.</li>\n<li>Policy and regulation related to AI-based systems\n    (including the EU AI Act), and how to approach it in the design\n    process.</li>\n<li>Critique and applications of\n    human-centred/ethical/responsible AI design toolkits.</li>\n<li>Socio-political perspectives on software design and user\n    research</li>\n<li>Aesthetics and emotion in design.</li>\n<li>Cognitive or sociological accounts of user behaviour.</li>\n<li>Critical analysis of user interfaces and implications for\n    UI/UX design for AI-based systems.</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should have developed\n  facility in discussing and critiquing the aims of their research,\n  especially for an audience drawn from other academic disciplines,\n  including the following skills:</p>\n<ul>\n<li>Theoretical motivation and defence of a research\n    question.</li>\n<li>Consideration of a research proposal from one or more\n    alternative theoretical perspectives.</li>\n<li>Potential critique of the theoretical basis for a programme\n    of research.</li>\n</ul>\n<h2>Coursework</h2>\n<p>In advance of each seminar, all participants must read in\n  advance a current (or occasionally \"classic\") paper presenting\n  theoretical perspectives on the design of interactive and\n  socio-digital systems.</p>\n<p>At the start of the seminar, one or two group members will\n  present a brief critical introduction to the paper, after which\n  the remainder of the session consists of open discussion.</p>\n<p>Each member of the class must submit a written critical review\n  discussing the paper presented at one of the seminars - this will\n  usually be the session at which they have contributed the opening\n  introduction.</p>\n<p>Throughout the course, students will be expected to keep a\n  \"reflective diary\", recording the theoretical focus of each\n  seminar, a summary of the themes that arise in discussion, and\n  ways in which the discussion relates to their own research\n  interests, possibly including theoretical perspectives that they\n  have encountered in other modules.</p>\n<h2>Practical work</h2>\n<p>There is no practical work element in this course.</p>\n<h2>Assessment</h2>\n<ul>\n<li>Written critical review of a single discussion text\n    (20%)</li>\n<li>Reflective diary submitted at the end of the module\n    (60%)</li>\n<li>In advance of the session, each student will submit a\n    written commentary on the paper, either generated using a large\n    language model (LLM), or written in the style of an LLM. A\n    short original observation should be added (20%)</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>To be assigned during the module, as discussed above. Most set\n  readings will be available either from the ACM Digital Library,\n  or from institutional repositories of the authors.</p>\n", "course_name": "Theories of Socio-digital Design for Human Centred AI", "course_code": "R225", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R225", "lecturers": ["afb21"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "R252": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>The objectives of this course is to expose you to one of the\n  most active contemporary research\u00a0directions within machine\n  learning: the theory of deep learning (DL). While the first wave\n  of\u00a0modern DL has focussed on empirical breakthroughs and\n  ever more complex techniques, the\u00a0attention is now shifting\n  to building a solid mathematical understanding of why these\n  techniques<br/>\n  work so well in the first place. The purpose of this course is to\n  review this recent progress\u00a0through a mixture of reading\n  group sessions and invited talks by leading researchers in\n  the\u00a0topic, and prepare you to embark on a PhD in modern deep\n  learning research. Compared to\u00a0typical, non-mathematical\n  courses on deep learning, this advanced module will appeal to\n  those\u00a0who have strong foundations in mathematics and\n  theoretical computer science. In a way, this\u00a0course is our\n  answer to the question \u201cWhat should the world\u2019s best computer\n  science students\u00a0know about deep learning in 2023?\u201d</p>\n<h2>Learning Outcomes</h2>\n<p>This course should prepare the best students to start a PhD in\n  the theory and mathematics of\u00a0deep learning, and to start\n  formulating their own hypotheses in this space. You will\n  be\u00a0introduced to a range of empirical and mathematical tools\n  developed in recent years for the\u00a0study of deep learning\n  behaviour, and you will build an awareness of the main open\n  questions\u00a0and current lines of attack. At the end of the\n  course you will:</p>\n<ol>\n<li>be able to explain why classical learning theory is\n    insufficient to describe the\u00a0phenomenon of generalization\n    in DL</li>\n<li>be able to design and interpret empirical studies aimed at\n    understanding generalization</li>\n<li>be able to explain the role of overparameterization: be\n    able to use deep linear models as\u00a0a model to study\n    implicit regularisation of gradient-based learning</li>\n<li>be able to state PAC-Bayes and Information-theoretic\n    bounds, and apply them to DL</li>\n<li>be able to explain the connection between Gaussian\n    processes and neural networks,\u00a0and will be able to study\n    learning dynamics in the neural tangent kernel (NTK)\n    regime.</li>\n<li>be able to formulate your own hypotheses about DL and\n    choose tools to prove/test them</li>\n<li>leverage your deeper theoretical understanding to produce\n    more robust, rigorous and\u00a0reproducible solutions to\n    practical machine learning problems.</li>\n</ol>\n<h2>Syllabus</h2>\n<p>Each week we'll have two to four student-lead presentations\n  about a research paper chosen from a reading list.\u00a0The\n  reading list loosely follows the weekly breakdown below (but we\n  adapt it each year based as this is an active research area):</p>\n<p>Week 1: Introduction to the topic<br/>\n  Week 2: Empirical Studies of Deep Learning Phenomena<br/>\n  Week 3: Interpolation Regime and \u201cDouble Descent\u201d Phenomena<br/>\n  Week 4: Implicit Regularization in Deep Linear Models<br/>\n  Week 5: Approximation Theory<br/>\n  Week 6: Networks in the Infinite Width Limit<br/>\n  Week 7: PAC-Bayes and Information Theoretic Bounds for SGD<br/>\n  Week 8: Discussion and Coursework Spotlight Session</p>\n<h2>Assessment</h2>\n<p>Students will be assessed on the following basis:</p>\n<ol>\n<li>20% for presentation/content contributed to the module:\n    Each student will have an\u00a0opportunity to present one of\n    the recommended papers during Weeks 1-7 (30 minute\u00a0slot\n    including Q&amp;A). For the presentation, students should aim\n    to communicate the core\u00a0ideas behind the paper, and\n    clearly present the results, conclusions, and\n    future\u00a0directions. Where possible, students are encouraged\n    to comment on how the work itself\u00a0fits into broader\n    research goals.</li>\n<li>10% for active participation (regular attendance and\n    contribution to discussions during\u00a0the Q&amp;A\n    sessions).</li>\n<li>70% for a group project report, with a word limit of 4000.\n    Either (1) an original research\u00a0proposal/report with a\n    hypothesis, review of related literature, and ideally\n    preliminary\u00a0findings, or, (2) reproduction and ideally\n    extension of an existing relevant paper.<br/>\n    Coursework reports are marked in line with general ACS\n    guidelines, reports receiving\u00a0top marks will have have\n    demonstrable research value (contain an original\n    research\u00a0idea, extension of existing work, or a thorough\n    reproduction effort which is valuable to\u00a0the research\n    community). Additionally, some projects will be suggested\n    during the first weeks of the course, although students are\n    encouraged to come up with their own ideas. Students may be\n    required to participate in group projects, with groups of size\n    2-3 (the class groups will be separated). For any given\n    project, individual contributions would be noted for assessment\n    though a viva component.</li>\n</ol>\n<h2>Relationship with related modules</h2>\n<p>This course can be considered as an advanced follow-up to the\n  Part IIB course on Deep Neural\u00a0Networks. That course\n  introduces some high level\u00a0concepts that this course\n  significantly expands on.</p>\n<p>This module complements L48: Machine Learning in the Physical\n  World and L46: Principles of\u00a0Machine Learning Systems, which\n  focus on applications and hardware/systems aspects of\n  ML\u00a0respectively.</p>\n<h2>Recommended reading</h2>\n<ul>\n<li><a href=\"https://www.pnas.org/cc/arthur-m-sackler-colloquium-on-the-science-of-deep-learning\">\n    PNAS Colloquium on the Science of Deep Learning</a></li>\n<li><a href=\"https://mml-book.github.io/\">Mathematics of\n    Machine Learning book by Marc Deisenroth, Aldo Faisal and Cheng\n    Soon Ong.</a></li>\n<li><a href=\"https://probml.github.io/pml-book/book1.html\">Probabilistic\n    Machine Learning: An Introduction book by Kevin Murphy</a></li>\n<li><a href=\"https://mjt.cs.illinois.edu/dlt/\">Matus\n    Telgarsky's lecture notes on deep learning\n    theory</a>\u00a0</li>\n</ul>\n<p>These are in addition to the papers which will be discussed in\n  the lectures.</p>\n", "course_name": "Theory of Deep Learning", "course_code": "R252", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/R252", "lecturers": [], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "L15": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This module aims to provide an introduction to topics in\n  complexity theory beyond that covered in the undergraduate course\n  and a grounding in research that connects this with methods from\n  logic. The topics covered in the last four lectures will focus on\n  current research and may vary from year to year.</p>\n<h2>Syllabus</h2>\n<ul>\n<li>Complexity theory\u2014a review of the major complexity classes\n    (space, time, nondeterministic, etc.) and their\n    interrelationships. [3 lectures]</li>\n<li>First-order and second-order logic: their expressive power\n    and computational complexity. [3 lectures]</li>\n<li>Lower bounds on expressive power: the use of games and\n    locality. [3 lectures]</li>\n<li>Fixed-point logics and descriptive complexity. [3\n    lectures]</li>\n<li>A selection of topics from the following [4 lectures]:\n      <ul>\n<li>finite-variable logics;</li>\n<li>complexity of constraint satisfaction problems;</li>\n<li>random structures;</li>\n<li>parameterized complexity;</li>\n<li>complexity of logical theories;</li>\n<li>logic and circuit complexity;</li>\n<li>logics of polynomial time computation;</li>\n<li>proof complexity.</li>\n</ul>\n</li>\n</ul>\n<h2>Objectives</h2>\n<p>On completion of this module, students should:</p>\n<ul>\n<li>be familiar with the basic relationship between the\n    expressive power of logic and computational complexity;</li>\n<li>be able to formulate simple game-based inexpressibility\n    arguments;</li>\n<li>be able to identify current research issues relating logic\n    to complexity.</li>\n</ul>\n<h2>Coursework and practical work</h2>\n<p>None.</p>\n<h2>Assessment</h2>\n<p>The assessment will be based on an essay completed during the\n  term, and a take-home test taken after the course, weighted as\n  follows:</p>\n<ul>\n<li>Essay: 30%</li>\n<li>Take-home Test: 70%</li>\n</ul>\n<h2>Recommended reading</h2>\n<p>Arora, S. and Barak, B. (2009). <em>Computational\n  complexity</em>. Cambridge University Press.<br/>\n  Gradel. E. <em>et al</em>. (2007). <em>Finite model theory and\n  its applications</em>. Springer.<br/>\n  Libkin, L. (2004). <em>Elements of finite model theory</em>.\n  Springer.<br/>\n  Immerman, N. (1999). <em>Descriptive complexity</em>.\n  Springer.<br/>\n  Ebbinghaus, H-D. and Flum, J. (1999). <em>Finite model\n  theory</em>. Springer.</p>\n", "course_name": "Topics in Logic and Complexity", "course_code": "L15", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/L15", "lecturers": ["ad260"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}, "P56": {"supervisions": 0, "prerequisite_for": [], "past_exam_questions": null, "description": "<h2>Aims</h2>\n<p>This is a practical course, actively building and extending\n  software tools to observe\u00a0the detailed behaviour of\n  transaction-oriented datacenter-like software. Students\n  will\u00a0observe and understand sources of user-facing tail\n  latency, including that stemming<br/>\n  from resource contention, cross-program interference, bad\n  software locking, and simple\u00a0design errors.<br/>\n  A 2-hour weekly hybrid, lecture/lab format permits students\n  continuous monitored\u00a0progress with complexity of tasks\n  building naturally upon the previous weeks learning.</p>\n<h2>Objectives</h2>\n<p>Upon successful completion of the course, students will be\n  able to:</p>\n<ul>\n<li>Make order-of-magnitude estimates of software, hardware,\n    and I/O speeds</li>\n<li>Make valid measurements of actual software, hardware, and\n    I/O speeds</li>\n<li>Create observation facilities, including logs and\n    dashboards, as part of a software system design</li>\n<li>Create tracing facilities to fully observe the execution of\n    complex software</li>\n<li>Time-align traces across multiple computers</li>\n<li>Display dense tracing information in meaningful ways</li>\n<li>Reason about the sources of real-time and transaction\n    delays, including cross-program\u00a0resource interference,\n    remote procedure call delays, and software locking\n    surprises</li>\n<li>Fix programs based on the above reasoning, making their\n    response times faster and more robust</li>\n</ul>\n<h2><br/>\n  Syllabus</h2>\n<p><u>Measurement</u><br/>\n  \u00a0 \u00a0Week 1 Intro, Measuring CPU time, rdtsc, Measuring\n  memory access times, Measuring disks,<br/>\n  \u00a0 \u00a0Week 2 gettimeofday, logs Measuring networks, Remote\n  Procedure Calls, Multi-threads, locks<br/>\n<u>Observation</u><br/>\n  \u00a0 \u00a0Week 3 RPC, logs, displaying traces,\n  interference<br/>\n  \u00a0 \u00a0Week 4 Antagonist programs, Logging, dashboards,\n  profiling.<br/>\n<u>KUtrace</u><br/>\n  \u00a0 \u00a0Week 5 Kernel patches, hello world,\n  post-processing<br/>\n  \u00a0 \u00a0Week 6 KUtrace multi-CPU time display<br/>\n  \u00a0 \u00a0Week 7 Client-server KUtrace, with antagonists and\n  interference<br/>\n  \u00a0 \u00a0Week 8 Other trace mysteries</p>\n<h2><br/>\n  Assessment</h2>\n<p>This is a Lab-based module; assessment is based upon reports\n  covering guided laboratory\u00a0work performed each\n  week.\u00a0Assessment will be via two submissions:</p>\n<ul>\n<li>20% assignment deadline week 4 based upon Lab work from\n    Weeks 1-4; word target\u00a01000, limit 2000</li>\n<li>80% assignment deadline week 8 based upon lab work from\n    weeks 5-8; word target\u00a02000, limit 4000</li>\n</ul>\n<p>The intent of the first assessment point is to provide rich\n  feedback to students\u00a0based upon a 20% assignment permitting\n  focussed and improved work to be executedfor the final\n  assignment.</p>\n<p>All work in this module is expected to be the effort of the\n  student. Enough equipment\u00a0is provisioned to allow each\n  student an independent set of apparatus. While\n  classmembers\u00a0may find sharing operational experience\n  valuable all assessment is based upon\u00a0a students sole\n  submission based upon. their own experiments and findings.</p>\n<h2>Reading Material</h2>\n<p><u>Core text</u></p>\n<ul>\n<li>Richard L. Sites, <em>Understanding Software Dynamics</em>,\n    Addison-Wesley Professional\u00a0Computing Series, 2022</li>\n</ul>\n<p>Further reading: papers and presentations that you might find\n  interesting. None are\u00a0required reading \u2013 they are\n  well-written and/or informative.</p>\n<ul>\n<li>John K. Ousterhout et al., <em>A trace-driven analysis of\n    the UNIX 4.2 BSD file system\u00a0ACM SIGOPS Operating Systems\n    Review</em>, Vol. 19, No. 5, Dec, 1985 <a href=\"https://dl.acm.org/doi/pdf/10.1145/323627.323631\">https://dl.acm.org/doi/pdf/10.1145/323627.323631</a></li>\n<li>Luiz Andr\u00b4e Barroso, Jimmy Clidaras, Urs H\u00a8olzle, <em>The\n    Datacenter as a Computer:\u00a0An Introduction to the Design of\n    Warehouse-Scale Machines</em>,\u00a0Second Edition</li>\n<li>John L. Hennessy, David A. Patterson, <em>Computer\n    Architecture, A Quantitative\u00a0Approach</em> 5th\n    Edition</li>\n<li>George Varghese, <em>Network Algorithmics</em>. Morgan\n    Kaufmann</li>\n<li>Actually keeping datacenter software up and running \u2013 how\n    Google runs production\u00a0systems Site Reliability\n    Engineering Edited by Betsy Beyer, Chris Jones,\n    Jennifer\u00a0Petoff and Niall Richard Murphy free PDF:\n    <a href=\"https://landing.google.com/sre/book.html\">https://landing.google.com/sre/book.html</a></li>\n<li>How NOT to run datacenters (27 minute video, funny/sad)\n    dotScale 2014 - Robert\u00a0Kennedy - <em>Life in the Trenches\n    of healthcare.gov</em> <a href=\"https://www.youtube.com/watch?v=GLQyj-kBRdo\">https://www.youtube.com/watch?v=GLQyj-kBRdo</a></li>\n</ul>\n<p>An extended (optional) reading list will also be provided.</p>\n", "course_name": "Understanding Networked-Systems Performance", "course_code": "P56", "course_url": "https://www.cl.cam.ac.uk/teaching/2324/P56", "lecturers": ["awm22"], "lectures": 16, "year": "2324", "tripos_part": "3", "michaelmas": false, "lent": true, "easter": false}}