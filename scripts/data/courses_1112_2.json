{"Bioinfo": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Bioinformatics.html", "description": "\n\n\n<a name=\"SECTION04021100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04021200000000000000\">Lectures</a>\n\n\n<li><b>Introduction to biological data and problems.</b> Ssequences and\nmicroarray data.\n\n<p></p></li>\n<li><b>Dynamic programming.</b> Longest common subsequence, DNA, RNA,\nprotein structure alignment, linear space alignment.\n\n<p></p></li>\n<li><b>Sequence database search.</b> Blast, Patternhunter I and II.\n\n<p></p></li>\n<li><b>Phylogeny - parsimony-based.</b> Fitch, Wagner, Sankoff parsimony.\n\n<p></p></li>\n<li><b>Phylogeny - distance-based.</b> UPGMA, Neighbour Joining.\n\n<p></p></li>\n<li><b>Clustering.</b> K-means, Markov Clustering algorithm.\n\n<p></p></li>\n<li><b>Hidden Markov Models applications in Bioinformatics.</b> Viterbi,\nForward-Backward, Baum-Welch.\n\n<p></p></li>\n<li><b>Searching Motifs.</b> Gibbs sampling.\n\n<p></p></li>\n<li><b>Biological networks I: reverse engineering.</b> Wagner, Aracne.\n\n<p></p></li>\n<li><b>Biological networks II: dynamics.</b> Gillespie.\n\n<p></p></li>\n\n\n<a name=\"SECTION04021300000000000000\">Objectives</a>\n\nAt the end of this course students should\n\n\n<li>understand Bioinformatics terminology;\n\n<p></p></li>\n<li>have mastered the most important algorithms in the field;\n\n<p></p></li>\n<li>be able to work with with bioinformaticians and biologists;\n\n<p></p></li>\n<li>be able to find data and literature in repositories.\n\n<p></p></li>\n\n\n<a name=\"SECTION04021400000000000000\">Recommended reading</a>\n\n* Jones, N.C. &amp; Pevzner, P.A. (2004). <em>An introduction to bioinformatics algorithms</em>. MIT Press.\n<br/>Felsenstein, J. (2003). <em>Inferring phylogenies</em>. Sinauer Associates.\n\n\n", "course_name": "Bioinformatics", "course_code": "Bioinfo", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/Bioinfo", "lecturers": ["pl219"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "CompSysMod": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComputerSystemsModelling.html", "description": "\n\n\n<a name=\"SECTION04022100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04022200000000000000\">Lectures</a>\n\n\n<li><b>Introduction to modelling.</b>\nOverview of analytic techniques and simulation. Little\u2019s law.\n\n<p></p></li>\n<li><b>Introduction to discrete event simulation.</b>\nApplicability to computer system modelling and other\nproblems. Advantages and limitations of simulation\napproaches.\n\n<p></p></li>\n<li><b>Random number generation methods and simulation techniques.</b> \nReview of statistical distributions.\nStatistical measures for simulations, confidence intervals and\nstopping criteria. Variance reduction techniques. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Simple queueing theory.</b> Stochastic processes:\nintroduction and examples. The Poisson process. Advantages and\nlimitations of analytic approaches. [2\u00a0lectures] \n\n<p></p></li>\n<li><b>Birth-death processes, flow balance equations.</b>\nBirth-death processes and their relation to queueing systems. The\nM/M/1 queue in detail: existence and when possible solution for\nequilibrium distribution, mean occupancy and mean residence\ntime. [2 lectures]\n\n<p></p></li>\n<li><b>Queue classifications, variants on the \nM/M/1 queue and applications to queueing networks.</b>\nExtensions to variants of the M/M/1 queue. Queueing networks. \n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>The M/G/1 queue and its application.</b> The\nPollaczek-Khintchine formula and related performance\nmeasures. [2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04022300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to build simple Markov models and \nunderstand the critical modelling assumptions;\n\n<p></p></li>\n<li>be able to solve simple birth-death \nprocesses;\n\n<p></p></li>\n<li>understand that in general as the utilization \nof a system increases towards unity then the response\ntime will tend to increase -- often dramatically so;\n\n<p></p></li>\n<li>understand the tradeoffs between different types of\nmodelling techniques;\n\n<p></p></li>\n<li>be aware of the issues in building a simulation of a computer\nsystem and analysing the results obtained.\n\n<p></p></li>\n\n\n<a name=\"SECTION04022400000000000000\">Reference books</a>\n\n* Ross, S.M. (2002). <em>Probability models for computer science</em>. Academic Press.\n<br/>Mitzenmacher, M. &amp; Upfal, E. (2005). <em>Probability and computing: randomized algorithms and probabilistic analysis</em>. Cambridge University Press. \n<br/>Jain, A.R. (1991). <em>The art of computer systems performance analysis</em>. Wiley.\n<br/>Kleinrock, L. (1975). <em>Queueing systems, vol. </em>1<em>. Theory</em>. Wiley.\n\n\n", "course_name": "Computer Systems Modelling", "course_code": "CompSysMod", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/CompSysMod", "lecturers": ["rg31"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "DSP": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-DigitalSignalProcessing.html", "description": "\n\n\n<a name=\"SECTION04023100000000000000\">\nAims</a>\n\n\n<a name=\"SECTION04023200000000000000\">\nLectures</a>\n\n\n<li><b>Signals and systems.</b> Discrete sequences and systems, their\n  types and properties. Linear time-invariant systems, convolution.\n\n<p>\n</p></li>\n<li><b>Phasors.</b> Eigen functions of linear time-invariant systems.\n  Review of complex arithmetic. Some examples from electronics, optics\n  and acoustics.\n\n<p>\n</p></li>\n<li><b>Fourier transform.</b> Phasors as orthogonal base functions.\n  Forms of the Fourier transform. Convolution theorem, Dirac\u2019s delta\n  function, impulse combs in the time and frequency domain.\n\n<p>\n</p></li>\n<li><b>Discrete sequences and spectra.</b> Periodic sampling of\n  continuous signals, periodic signals, aliasing, sampling and\n  reconstruction of low-pass and band-pass signals, spectral\n  inversion.\n\n<p>\n</p></li>\n<li><b>Discrete Fourier transform.</b> Continuous <em>versus</em>\n  discrete Fourier transform, symmetry, linearity, review of the FFT,\n  real-valued FFT.\n\n<p>\n</p></li>\n<li><b>Spectral estimation.</b> Leakage and scalloping phenomena,\n  windowing, zero padding.\n\n<p>\n</p></li>\n<li><b>Finite and infinite impulse-response filters.</b> Properties of\n  filters, implementation forms, window-based FIR design, use of\n  frequency-inversion to obtain high-pass filters, use of modulation\n  to obtain band-pass filters, FFT-based convolution, polynomial\n  representation, <em>z</em>-transform, zeros and poles, use of analog\n  IIR design techniques (Butterworth, Chebyshev I/II, elliptic\n  filters).\n\n<p>\n</p></li>\n<li><b>Digital modulation.</b> IQ representation of band-pass signals,\n  in particular AM, FM, MSK, QAM, and OFDM signals. Clock recovery,\n  symbol detection, matched filter, software-defined radio.\n\n<p>\n</p></li>\n<li><b>Random sequences and noise.</b> Random variables, stationary\n  processes, autocorrelation, crosscorrelation, deterministic\n  crosscorrelation sequences, filtered random sequences, white noise,\n  exponential averaging.\n\n<p>\n</p></li>\n<li><b>Correlation coding.</b> Random vectors, dependence <em>    versus</em> correlation, covariance, decorrelation, matrix\n  diagonalization, eigen decomposition, Karhunen-Lo\u00e8ve transform,\n  principal component analysis. Relation to orthogonal transform\n  coding using fixed basis vectors, such as DCT.\n\n<p>\n</p></li>\n<li><b>Lossy versus lossless compression.</b> What information is\n  discarded by human senses and can be eliminated by encoders?\n  Perceptual scales, masking, spatial resolution, colour coordinates,\n  some demonstration experiments.\n\n<p>\n</p></li>\n<li><b>Quantization, image coding standards.</b> A/mu-law coding,\n  delta coding, JPEG.\n\n<p>\n</p></li>\n\n\n<a name=\"SECTION04023300000000000000\">\nObjectives</a>\n\n\nBy the end of the course students should be able to \n\n\n\n<li>apply basic properties of time-invariant linear\n  systems;\n\n<p>\n</p></li>\n<li>understand sampling, aliasing, convolution, filtering, the\n  pitfalls of spectral estimation;\n\n<p>\n</p></li>\n<li>explain the above in time and frequency domain representations;\n\n<p>\n</p></li>\n<li>use filter-design software;\n\n<p>\n</p></li>\n<li>visualize and discuss digital filters in the <em>z</em>-domain;\n\n<p>\n</p></li>\n<li>use the FFT for convolution, deconvolution, filtering;\n\n<p>\n</p></li>\n<li>implement, apply and evaluate simple DSP applications in MATLAB;\n\n<p>\n</p></li>\n<li>apply transforms that reduce correlation between several signal\n  sources;\n\n<p>\n</p></li>\n<li>understand the basic principles of several widely-used\n  modulation and image coding techniques.\n\n<p>\n</p></li>\n\n\n<a name=\"SECTION04023400000000000000\">\nRecommended reading</a>\n\n\n* Lyons, R.G. (2010). <em>Understanding digital signal processing.</em> Prentice\u00a0Hall (3rd ed.).\n<br/>\nOppenheim, A.V. &amp; Schafer, R.W. (2007). <em>Discrete-time digital signal processing.</em> Prentice\u00a0Hall (3rd ed.).\n<br/>\nStein, J. (2000). <em>Digital signal processing - a computer science perspective.</em> Wiley.\n<br/>\nSalomon, D. (2002). <em>A guide to data compression methods.</em> Springer.\n\n\n\n", "course_name": "Digital Signal Processing", "course_code": "DSP", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/DSP", "lecturers": ["mgk25"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "HoareLogic": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-HoareLogic.html", "description": "\n\n\n<a name=\"SECTION04024100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04024200000000000000\">Lectures</a>\n\n<li><b>Formal specification of imperative programs.</b>  Formal versus\n  informal methods. Specification using preconditions and postconditions.\n\n<p></p></li>\n<li><b>Axioms and rules of inference.</b>  Hoare logic\n  for a simple language with assignments, sequences,\n  conditionals and while-loops.\n\n<p></p></li>\n<li><b>Loops and invariants.</b>\nVarious examples illustrating loop invariants and how they can be found.\n\n<p></p></li>\n<li><b>Partial and total correctness.</b>\nHoare logic for proving termination. Variants.\n\n<p></p></li>\n<li><b>Additional constructs.</b>\nArrays and <tt>FOR</tt>-commands.\n\n<p></p></li>\n<li><b>Semantics.</b>\nMathematical interpretation of Hoare logic. Deep and shallow semantic embedding.\n\n<p></p></li>\n<li><b>Metatheory.</b>\nSoundness, completeness and decidability.\n\n<p></p></li>\n<li><b>Mechanising program verification.</b>\nAssertions, annotation and verification conditions.\nProperty checking versus proof of correctness. \nInteractive versus automatic methods.\n\n<p></p></li>\n<li><b>Predicate transformers.</b>  \nWeakest preconditions and strongest postconditions; their\nrelationship to Hoare logic and its mechanisation.\n\n<p></p></li>\n<li><b>Program refinement.</b>  \nTransforming specifications to programs using refinement rules. Discussion of\ncorrect-by-construction methods versus post-hoc verification.\n\n<p></p></li>\n<li><b>Current reseach.</b>\nRecent developments in Hoare logic such as separation logic.\n\n<p></p></li>\n<li><b>Review and conclusions.</b>\nReview of course material covered. Worked examples. Miscellaneous advice \non answering examination questions.\n\n<p></p></li>\n\n\n<a name=\"SECTION04024300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to prove simple programs correct by hand and implement a\n  simple program verifier;\n\n<p></p></li>\n<li>be familiar with the theory and use of Hoare logic and its mechanisation;\n\n<p></p></li>\n<li>understand some of the core concepts underlying modern formal\n  program verification.\n\n<p></p></li>\n\n\n<a name=\"SECTION04024400000000000000\">Recommended reading</a>\n\nHuth, M. &amp; Ryan M. (2004). <em>Logic in computer science: modelling and reasoning about systems</em>. Cambridge University Press (2nd ed.).\n\n\n\n", "course_name": "Hoare Logic", "course_code": "HoareLogic", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/HoareLogic", "lecturers": ["mjcg"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "InfoTheory": {"supervisions": null, "lectures": 11, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-InformationTheoryandCoding.html", "description": "\n\n\n<a name=\"SECTION04025100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04025200000000000000\">Lectures</a>\n\n<li><b>Foundations:  probability, uncertainty, information.</b>\nHow concepts of randomness, redundancy,\ncompressibility, noise, bandwidth, and uncertainty are \nrelated to information.  \nEnsembles, random variables, marginal and conditional probabilities.\nHow the metrics of information are grounded in the rules\nof probability.\n\n<p></p></li>\n<li><b>Entropies defined, and why they are measures of information.</b> \nMarginal entropy, joint entropy, conditional entropy,\nand the Chain Rule for entropy.  Mutual information between ensembles\nof random variables.  Why entropy is the fundamental measure of\ninformation content.\n\n<p></p></li>\n<li><b>Source coding theorem; prefix, variable-, and fixed-length codes.</b>\nSymbol codes.  The binary symmetric channel.  Capacity of a noiseless\ndiscrete channel.  Error correcting codes.\n\n<p></p></li>\n<li><b>Channel types, properties, noise, and channel capacity.</b>\nPerfect communication through a noisy channel.  Capacity of a\ndiscrete channel as the maximum of its mutual information over\nall possible input distributions. \n\n<p></p></li>\n<li><b>Continuous information; density; noisy channel coding theorem.</b>\nExtensions of the discrete entropies and measures to the continuous\ncase.  Signal-to-noise ratio; power spectral density.  Gaussian channels.\nRelative significance of bandwidth and noise limitations.  \nThe Shannon rate limit and efficiency for noisy continuous channels.\n\n<p></p></li>\n<li><b>Fourier series, convergence, orthogonal representation.</b>\nGeneralized signal expansions in vector spaces.  Independence.\nRepresentation of continuous or discrete data by complex exponentials.\nThe Fourier basis.  Fourier series for periodic functions.  Examples.\n\n<p></p></li>\n<li><b>Useful Fourier theorems; transform pairs.  Sampling; aliasing.</b>\nThe Fourier transform for non-periodic functions.  Properties of the\ntransform, and examples.  Nyquist\u2019s Sampling Theorem derived, and the \ncause (and removal) of aliasing.\n\n<p></p></li>\n<li><b>Discrete Fourier transform. Fast Fourier Transform algorithms.</b>\nEfficient algorithms for computing Fourier transforms of discrete data.\nComputational complexity.  Filters, correlation, modulation, demodulation, \ncoherence.\n\n<p></p></li>\n<li><b>The quantized degrees-of-freedom in a continuous signal.</b>\nWhy a continuous signal of finite bandwidth and duration has a fixed\nnumber of degrees-of-freedom.  Diverse illustrations of the principle\nthat information, even in such a signal, comes in quantized, countable,\npackets.\n\n<p></p></li>\n<li><b>Gabor-Heisenberg-Weyl uncertainty relation.  Optimal \u201cLogons\u201d.</b>\nUnification of the time-domain and the frequency-domain as endpoints \nof a continuous deformation.  The Uncertainty Principle and its optimal\nsolution by Gabor\u2019s expansion basis of \u201clogons\u201d.  Multi-resolution \nwavelet codes.  Extension to images, for analysis and compression.\n\n<p></p></li>\n<li><b>Kolmogorov complexity.  Minimal description length.</b>\nDefinition of the algorithmic complexity of a data sequence, and \nits relation to the entropy of the distribution from which the data \nwas drawn.  Fractals.  Minimal description length, and why this measure\nof complexity is not computable.\n\n<p></p></li>\n\n\n<a name=\"SECTION04025300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to\n\n\n<li>calculate the information content of a random variable\nfrom its probability distribution;\n\n<p></p></li>\n<li>relate the joint, conditional, and marginal entropies \nof variables in terms of their coupled probabilities;\n\n<p></p></li>\n<li>define channel capacities and properties using Shannon\u2019s Theorems;\n\n<p></p></li>\n<li>construct efficient codes for data on imperfect communication channels;\n\n<p></p></li>\n<li>generalize the discrete concepts to continuous signals on continuous \nchannels;\n\n<p></p></li>\n<li>understand Fourier Transforms and the main ideas of efficient\nalgorithms for them;\n\n<p></p></li>\n<li>describe the information resolution, compression, and efficient coding\nproperties of wavelets.\n\n<p></p></li>\n\n\n<a name=\"SECTION04025400000000000000\">Recommended reading</a>\n\n* Cover, T.M. &amp; Thomas, J.A. (1991). <em>Elements of information theory</em>. New York: Wiley.\n\n\n", "course_name": "Information Theory and Coding", "course_code": "InfoTheory", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/InfoTheory", "lecturers": ["jgd1000"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "OptComp": {"supervisions": null, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-OptimisingCompilers.html", "description": "\n\n\n<a name=\"SECTION04026100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04026200000000000000\">Lectures</a>\n\n<li><b>Introduction and motivation.</b>\nOutline of an optimising compiler.\nOptimisation partitioned: <i>analysis</i> shows a property holds\nwhich enables a <em>transformation</em>.\nThe flow graph; representation of programming concepts including argument\nand result passing.\nThe phase-order problem.\n\n<p></p></li>\n<li><b>Kinds of optimisation.</b>\nLocal optimisation: peephole optimisation, instruction scheduling.\nGlobal optimisation: common sub-expressions, code motion.\nInterprocedural optimisation.\nThe call graph.\n\n<p></p></li>\n<li><b>Classical dataflow analysis.</b>\nGraph algorithms, <em>live</em> and <em>avail</em> sets.\nRegister allocation by register colouring.\nCommon sub-expression elimination.\nSpilling to memory; treatment of CSE-introduced temporaries.\nData flow anomalies.\nStatic Single Assignment (SSA) form.\n\n<p></p></li>\n<li><b>Higher-level optimisations.</b>\nAbstract interpretation,  Strictness analysis.\nConstraint-based analysis, Control flow analysis for lambda-calculus.\nRule-based inference of program properties,\nTypes and effect systems.\nPoints-to and alias analysis.\n\n<p></p></li>\n<li><b>Target-dependent optimisations.</b>\nInstruction selection.\nInstruction scheduling and its phase-order problem.\n\n<p></p></li>\n<li><b>Decompilation.</b>\nLegal/ethical issues.\nSome basic ideas, control flow and type reconstruction.\n</li>\n\n\n<a name=\"SECTION04026300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n<li>be able to explain program analyses as dataflow equations on a\nflowgraph;\n\n<p></p></li>\n<li>know various techniques for high-level optimisation of programs\nat the abstract syntax level;\n\n<p></p></li>\n<li>understand how code may be re-scheduled to improve execution speed;\n\n<p></p></li>\n<li>know the basic ideas of decompilation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04026400000000000000\">Recommended reading</a>\n\n* Nielson, F., Nielson, H.R. &amp; Hankin, C.L. (1999).  <em>Principles of program analysis</em>. Springer. Good on part A and part B.\n<br/>Appel, A. (1997). <em>Modern compiler implementation in Java/C/ML</em>  (3 editions).\n<br/>Muchnick, S. (1997). <em>Advanced compiler design and implementation</em>.  Morgan Kaufmann.\n<br/>Wilhelm, R. (1995). <em>Compiler design</em>. Addison-Wesley.\n<br/>Aho, A.V., Sethi, R. &amp; Ullman, J.D. (2007). <em>Compilers:  principles, techniques and tools</em>. Addison-Wesley (2nd ed.).\n\n", "course_name": "Optimising Compilers", "course_code": "OptComp", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/OptComp", "lecturers": ["am21"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "PrincComm": {"supervisions": null, "lectures": 24, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-PrinciplesofCommunications.html", "description": "\n\n\n<a name=\"SECTION04027100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04027200000000000000\">Lectures</a>\n\n\n<li><b>Introduction.</b>\nCourse overview. Abstraction, layering.\nThe structure of real networks, links, end systems and switching\nsystems. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Modular functionality for communications.</b>\nSome systems design paradigms, often orthogonal to layers. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Information, Noise, Interference, Capacity</b>\nWe briefly review relevant information theory and how the limit for the\ncapacity of a channel can be calculated.  [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Topology and Routing.</b>\nHow many ways can we work out how to get from A to B?\nWe review relevant graph theory, including recent advances in\nunderstanding the topology of the Internet and similar networks.\n[4\u00a0lectures]\n\n<p></p></li>\n<li><b>Error control.</b>\nWhat do we do when things go wrong?\nInformation can be coded and transmitted\nin a number of ways to survive interference.\nRetransmit, or pre-transmit? [2\u00a0lecture]\n\n<p></p></li>\n<li><b>Flow control.</b>\nControl theory is a branch of engineering familiar to people building dynamic machines. It can be\napplied to network traffic.\nStemming the flood, at source, sink, or in between? [3\u00a0lectures]\n\n<p></p></li>\n<li><b>Shared media networks.</b>\nEthernet and Radio networks: some special problems\nfor media access and so forth. We revisit the problem of capacity of a channel \nin the context of a radio network.\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>Switched networks.</b>\nWhat does a switch do and how?\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>Integrated Service Packet Networks for IP.</b>\nTraffic may be adaptive to feedback control, or it may be a given.\nCharacteristics may be quite complex in terms of time series.  This has an impact on the design\nchoices for scheduling and queue management algorithms for packet forwarding, including APIs to Quality of Service and routing with QoS.  [2\u00a0lectures]\n\n<p></p></li>\n<li><b>The big picture for managing traffic.</b>\nEconomics and policy are relevant to networks in many ways.\nOptimisation and game theory are both relevant topics discussed here.\n[2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04027300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to explain the\nunderlying design and behaviour of networks, including capacity,\ntopology, control and use.\n\n\n<a name=\"SECTION04027400000000000000\">Recommended reading</a>\n\n* Keshav, S. (2011). <em>Mathematical Foundations of Computer Networking</em>. to appear, Addison Wesley - available in draft from <a href=\"http://blizzard.cs.uwaterloo.ca/keshav/wiki/index.php/Book\" name=\"tex2html19\"><tt>http://blizzard.cs.uwaterloo.ca/keshav/wiki/index.php/Book</tt></a>. \n<br/>Background reading:\n<br/>Keshav, S. (1997). <em>An engineering approach to computer networking</em>. Addison-Wesley (1st ed.). ISBN 0201634422\n<br/>Stevens, W.R. (1994). <em>TCP/IP illustrated, vol.\u00a01: the protocols</em>. Addison-Wesley (1st ed.). ISBN 0201633469\n\n\n", "course_name": "Principles of Communications", "course_code": "PrincComm", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/PrincComm", "lecturers": ["jac22"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "QuantComp": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-QuantumComputing.html", "description": "\n\n\n<a name=\"SECTION04028100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04028200000000000000\">Lectures</a>\n\n<li><b>Bits and qubits.</b>\nIntroduction to quantum states with motivating examples.  Comparison\nwith classical discrete state systems.\n\n<p></p></li>\n<li><b>Linear algebra.</b>\nReview of linear algebra.  Vector spaces, linear operators, Dirac\nnotation. \n\n<p></p></li>\n<li><b>Quantum mechanics.</b>\nPostulates of quantum mechanics.  Evolution and measurement.\nEntanglement.\n\n<p></p></li>\n<li><b>Quantum computation.</b>\nModels of quantum computation.  Quantum circuits, finite state\nsystems, machines and algorithms.\n\n<p></p></li>\n<li><b>Some applications.</b>\nApplications of quantum infomation.\nBell States, quantum key exchange, quantum teleportation.\n\n<p></p></li>\n<li><b>Quantum search.</b>\nGrover\u2019s search algorithm.  Analysis and lower bounds.\n\n<p></p></li>\n<li><b>Factorisation.</b>\nShor\u2019s algorithm for factorising numbers and analysis.  Quantum\nFourier transform. \n\n<p></p></li>\n<li><b>Quantum complexity.</b>\nQuantum complexity classes and their relationship to classical\ncomplexity.  Comparison with probabilistic computation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04028300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>understand the quantum model of computation and how it relates\n  to quantum mechanics;\n\n<p></p></li>\n<li>be familiar with some basic quantum algorithms and their\n  analysis;\n\n<p></p></li>\n<li>see how the quantum model relates to classical models of\n  computation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04028400000000000000\">Recommended reading</a>\n\n* Nielsen, M.A. &amp; Chuang, I.L. (2010). <em>Quantum computation and quantum information</em>. Cambridge University Press (2nd ed.).\n<br/>Mermin, N.D. (2007).  <em>Quantum computer science</em>. Cambridge University Press.\n\n\n", "course_name": "Quantum Computing", "course_code": "QuantComp", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/QuantComp", "lecturers": ["ad260"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "Types": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Types.html", "description": "\n\n\n<a name=\"SECTION04029100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04029200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b>  The role of type systems in programming\n  languages. Formalizing type systems. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>ML polymorphism.</b>\nML-style polymorphism. Principal type schemes and type inference.\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>Polymorphic reference types.</b>  The pitfalls of combining ML\n  polymorphism with reference types.  [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Polymorphic lambda calculus.</b>  Syntax and reduction\n  semantics. Examples of datatypes definable in the polymorphic lambda\n  calculus. Applications. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Further topics.</b>  \n  The Curry-Howard correspondence as a\n  source of type systems. Dependent types. [2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04029300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>appreciate how type systems can be used to constrain or describe\n  the dynamic behaviour of programs;\n\n<p></p></li>\n<li>be able to use a rule-based specification of a type system to\n  infer typings and to establish type soundness results;\n\n<p></p></li>\n<li>appreciate the expressive power of the polymorphic lambda\n  calculus.\n\n<p></p></li>\n\n\n<a name=\"SECTION04029400000000000000\">Recommended reading</a>\n\n* Pierce, B.C. (2002). <em>Types and programming languages</em>. MIT Press.\n<br/>Cardelli, L. (1997). Type systems. In <em>CRC handbook of computer science and engineering</em>. CRC Press.\n<br/>Cardelli, L. (1987). Basic polymorphic typechecking. <em>Science of computer programming</em>, vol. 8, pp. 147-172.\n<br/>Girard, J-Y. (tr. Taylor, P. &amp; Lafont, Y.) (1989). <em>Proofs and types</em>. Cambridge University Press.\n\n\n", "course_name": "Types", "course_code": "Types", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/Types", "lecturers": ["amp12"], "year": "1112", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "ArtIntII": {"supervisions": null, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ArtificialIntelligence.html", "description": "\n\n\n<a name=\"SECTION04031100000000000000\">Aims</a>\n\nThe course aims to provide further tools and algorithms required to\nproduce AI systems able to exhibit limited human-like abilities, with\nan emphasis on the need to obtain better planning algorithms, and\nsystems able to deal with the uncertainty inherent in the environments\nthat most real agents might be expected to perform within.\n\n\n<a name=\"SECTION04031200000000000000\">Lectures</a>\n\n<li><b>Further planning.</b> Incorporating heuristics into\n  partial-order planning.  Planning graphs. The GRAPHPLAN algorithm.\n  Planning using propositional logic. Planning as a constraint\n  satisfaction problem. \n  [3\u00a0lectures]\n\n<p></p></li>\n<li><b>Uncertainty and Bayesian networks.</b> Review of probability\n  as applied to AI. Representing uncertain knowledge using Bayesian\n  networks. Inference in Bayesian networks using both exact and\n  approximate techniques. Other ways of dealing with\n  uncertainty. \n  [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Utility and decision-making.</b> The concept of\n  <span class=\"textit\">utility</span>. Utility and preferences. Deciding how to act by\n  maximising expected utility. Decision networks. The value of\n  information, and reasoning about when to gather more. \n  [1\u00a0lectures]\n\n<p></p></li>\n<li><b>Uncertain reasoning over time.</b> Markov processes,\n  transition and sensor models. Inference in temporal models:\n  filtering, prediction, smoothing and finding the most likely\n  explanation. The Viterbi algorithm. Hidden Markov models. \n  [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Reinforcement learning.</b> Learning from rewards and\n  punishments. Markov decision processes. The problems of temporal\n  credit assignment and exploration versus exploitation. Q-learning\n  and its convergence. How to choose actions. \n  [2\u00a0lecture]\n\n<p></p></li>\n<li><b>Further supervised learning I.</b> Bayes theorem as applied to\n  supervised learning. The maximum likelihood and maximum <span class=\"textit\">a\n    posteriori</span> hypotheses. What does this teach us about the\n  backpropagation algorithm?\n  [1\u00a0lecture]  \n\n<p></p></li>\n<li><b>How to classify optimally.</b> Bayesian decision theory and \n  Bayes optimal classification. What does this tell us about how \n  best to do supervised machine learning?\n  [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Further supervised learning II.</b> Applying the Bayes optimal\n  classification approach to neural networks. Markov chain Monte Carlo\n  methods, the evidence and how to choose hyperparameters.\n  [4\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04031300000000000000\">Objectives</a>\n\nAt the end of this course students should:\n\n\n<li>have gained a deeper appreciation of the way in which computer\n  science has been applied to the problem of AI, and in particular for\n  more recent techniques concerning knowledge representation, planning,\n  inference, uncertainty and learning;\n\n<p></p></li>\n<li>know how to model situations using a variety of knowledge\n  representation techniques;\n\n<p></p></li>\n<li>be able to design problem solving methods based on knowledge\n  representation, inference, planning, and learning techniques;\n\n<p></p></li>\n<li>know how probability theory can be applied in practice as a\n  means of handling uncertainty in AI systems.\n\n<p></p></li>\n\n\n<a name=\"SECTION04031400000000000000\">Recommended reading</a>\n\nThe recommended text is:\n\n* Russell, S. &amp; Norvig, P. (2010). <em>Artificial intelligence: a modern approach</em>. Prentice\u00a0Hall (3rd ed.).\n<br/>For some material you may find more specialised texts useful, in \nparticular:\n\nBishop, C.M. (2006). <em>Pattern recognition and machine learning</em>. Springer.\n<br/>Ghallab, M., Nau, D. &amp; Traverso, P. (2004). <span class=\"textit\">Automated planning: theory and practice</span>. Morgan Kaufmann.\n<br/>Sutton, R.S. &amp; Barto, A.G. (1998). <span class=\"textit\">Reinforcement learning: an introduction</span>. MIT Press.\n\n\n", "course_name": "Artificial Intelligence\u00a0II", "course_code": "ArtIntII", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/ArtIntII", "lecturers": ["sbh11"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "Business": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-BusinessStudies.html", "description": "\n\n\n<a name=\"SECTION04032100000000000000\">Aims</a>\n\nSee also Business Seminars in the Easter Term.\n\n\n<a name=\"SECTION04032200000000000000\">Lectures</a>\n\n<li><b>So you\u2019ve got an idea?</b>\nIntroduction. Why are you doing it and what is it? Types of\ncompany. Market analysis. The business plan. \n\n<p></p></li>\n<li><b>Money and tools for its management.</b>\nIntroduction to accounting: profit and loss, cash flow, balance sheet,\nbudgets. Sources of finance. Stocks and shares. Options and futures.\n\n<p></p></li>\n<li><b>Setting up: legal aspects.</b>\nCompany formation. Brief introduction to business law; duties of\ndirectors.  Shares, stock options, profit share schemes and the like.\nIntellectual Property Rights, patents, trademarks and\ncopyright. Company culture and management theory.\n\n<p></p></li>\n<li><b>People.</b>\nMotivating factors. Groups and teams. Ego. Hiring and firing:\nemployment law. Interviews. Meeting techniques.\n\n<p></p></li>\n<li><b>Project planning and management.</b>\nRole of a manager. PERT and GANTT charts, and critical path\nanalysis. Estimation techniques. Monitoring.\n\n<p></p></li>\n<li><b>Quality, maintenance and documentation.</b>\nDevelopment cycle. Productization. Plan for quality. Plan for\nmaintenance. Plan for documentation.\n\n<p></p></li>\n<li><b>Marketing and selling.</b>\nSales and marketing are different. Marketing; channels; marketing\ncommunications.  Stages in selling. Control and commissions.\n\n<p></p></li>\n<li><b>Growth and exit routes.</b>\nNew markets: horizontal and vertical expansion. Problems of growth;\nsecond system effects. Management structures. Communication. Exit\nroutes: acquisition, floatation, MBO or\nliquidation. Futures: some emerging\nideas for new computer businesses.\nSummary. Conclusion: now you do it!\n\n<p></p></li>\n\n\n<a name=\"SECTION04032300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to write and analyse a business plan;\n\n<p></p></li>\n<li>know how to construct PERT and GANTT diagrams and perform critical\npath analysis;\n\n<p></p></li>\n<li>appreciate the differences between profitability and cash flow, and\nhave some notion of budget estimation;\n\n<p></p></li>\n<li>have an outline view of company formation, share structure, capital\nraising, growth and exit routes;\n\n<p></p></li>\n<li>have been introduced to concepts of team formation and management;\n\n<p></p></li>\n<li>know about quality documentation and productization processes;\n\n<p></p></li>\n<li>understand the rudiments of marketing and the sales process.\n\n<p></p></li>\n\n\n<a name=\"SECTION04032400000000000000\">Recommended reading</a>\n\nLang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook: how to start and run a high-tech company</em>. FT.COM/Prentice\u00a0Hall.\n\nStudents will be expected to able to use Microsoft Excel and Microsoft\nProject.\n\nFor additional reading on a lecture-by-lecture basis, please see the course website.\n\nStudents are strongly recommended to enter the CU Entrepreneurs Business\nIdeas Competition <a href=\"http://www.cue.org.uk/\" name=\"tex2html20\"><tt>http://www.cue.org.uk/</tt></a>\n\n", "course_name": "Business Studies", "course_code": "Business", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/Business", "lecturers": [], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "CompArch": {"supervisions": null, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComparativeArchitectures.html", "description": "\n\n\n<a name=\"SECTION04033100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04033200000000000000\">Lectures</a>\n\n<li><b>Introduction</b>. \n The impact of technology scaling and market trends.\n\n<p></p></li>\n<li><b>Fundamentals of Computer Design</b>. \n Amdahl\u2019s law, energy/performance trade-offs, ISA design.\n\n<p></p></li>\n<li><b>Advanced pipelining</b>. \n Pipeline hazards; exceptions; optimal pipeline depth; branch prediction;\n the branch target buffer [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Superscalar techniques</b>.  \n Instruction-Level Parallelism\n (ILP); superscalar processor architecture [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Software approaches to exploiting ILP</b>.\n VLIW architectures; local and global instruction scheduling techniques;\n predicated instructions and support for speculative compiler optimisations.\n\n<p></p></li>\n<li><b>Multithreaded processors</b>.\n Coarse-grained, fine-grained, simultaneous multithreading\n\n<p></p></li>\n<li><b>The memory hierarchy</b>.\n Caches; programming for caches; prefetching [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Vector processors</b>.\n Vector machines; short vector/SIMD instruction set extensions; \n stream processing \n\n<p></p></li>\n<li><b>Chip multiprocessors</b>.\n  The communication model; memory consistency models;\n  false sharing; multiprocessor memory hierarchies; cache coherence protocols;\n  synchronization\n\n<p></p></li>\n<li><b>On-chip interconnection networks</b>.\n  Bus-based interconnects; on-chip packet switched networks\n\n<p></p></li>\n<li><b>Special-purpose architectures</b>. \n  Converging approaches to computer design\n\n<p></p></li>\n\n\n<a name=\"SECTION04033300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>understand what determines processor design goals;\n\n<p></p></li>\n<li>appreciate what constrains the design process and how\n      architectural trade-offs are made within these\n      constraints;\n\n<p></p></li>\n<li>be able to describe the architecture and operation of pipelined\n      and superscalar processors, including techniques such as \n      branch prediction, register renaming and out-of-order execution;\n\n<p></p></li>\n<li>have an understanding of vector, multithreaded and \n      multi-core processor architectures;\n\n<p></p></li>\n<li>for the architectures discussed, understand what \n      ultimately limits their performance and application domain.\n\n<p></p></li>\n\n\n<a name=\"SECTION04033400000000000000\">Recommended reading</a>\n\n* Hennessy, J. &amp; Patterson, D. (2006). <em>Computer architecture: a quantitative approach</em>. Elsevier (4th ed.) ISBN\u00a0978-0-12-370490-0. (3rd edition is also good) \n\n\n", "course_name": "Comparative Architectures", "course_code": "CompArch", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/CompArch", "lecturers": ["rdm34"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "CompVision": {"supervisions": null, "lectures": 15, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComputerVision.html", "description": "\n\n\n<a name=\"SECTION04034100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04034200000000000000\">Lectures</a>\n\n<li><b>Goals of computer vision; why they are so difficult.</b>\r\nHow images are formed, and the ill-posed problem of\r\nmaking 3D inferences from them about objects and their\r\nproperties. \n\n<p></p></li>\n<li><b>Image sensing, pixel arrays, CCD cameras.</b>\r\nImage coding and information measures.  Elementary operations on image arrays.\n\n<p></p></li>\n<li><b>Biological visual mechanisms, from retina to cortex.</b>\r\nPhotoreceptor sampling; receptive field profiles; stochastic impulse \r\ncodes; channels and pathways.  Neural image encoding operators. \n\n<p></p></li>\n<li><b>Mathematical operators for extracting image structure.</b>\r\nFinite differences and directional derivatives.\r\nFilters; convolution; correlation.  2D Fourier domain theorems.\n\n<p></p></li>\n<li><b>Edge detection operators; the information revealed by edges.</b>\r\nThe Laplacian operator and its zero-crossings.  Logan\u2019s theorem.\n\n<p></p></li>\n<li><b>Multi-resolution representations.</b>  Gaussian pyramids and SIFT \r\n(scale-invariant feature transform).  Active contours; energy-minimising snakes.  \r\n2D wavelets as visual primitives.  \n\n<p></p></li>\n<li><b>Higher visual operations in brain cortical areas.</b>\r\nMultiple parallel mappings; streaming and divisions of labour;\r\nreciprocal feedback across the visual system. \n\n<p></p></li>\n<li><b>Texture, colour, stereo, and motion descriptors.</b>\r\nDisambiguation and the achievement of invariances when inferring\r\nobject properties from images.\n\n<p></p></li>\n<li><b>Lambertian and specular surfaces; reflectance maps.</b>\r\nGeometric analysis of image formation from surfaces.  Discounting the \r\nilluminant when inferring 3D structure from image properties.\n\n<p></p></li>\n<li><b>Shape representation.</b>  Inferring 3D shape from shading;\r\nsurface geometry.  Boundary descriptors; codons.  Object-centred\r\ncoordinates and the \u201c2.5-Dimensional\" sketch.\n\n<p></p></li>\n<li><b>Perceptual psychology and visual cognition.</b>  Vision\r\nas model-building and graphics in the brain.  Learning to see.\n\n<p></p></li>\n<li><b>Lessons from visual illusions and from neurological trauma.</b>\r\nVisual agnosias and illusions, and what they may imply about how vision works.\n\n<p></p></li>\n<li><b>Bayesian inference in vision; knowledge-driven interpretations.</b>  \r\nClassifiers and pattern recognition.  Probabilistic methods in vision.\n\n<p></p></li>\n<li><b>Vision as a set of inverse problems.</b>  Mathematical methods\r\nfor solving them:  energy minimization, \r\nrelaxation, regularization.  Active models.\n\n<p></p></li>\n<li><b>Applications of machine learning in computer vision.</b>  \r\nDiscriminative and generative methods.  Content based image retrieval.\n\n<p></p></li>\n<li><b>Approaches to face detection, face recognition, and facial\r\ninterpretation.</b>  Appearance <em>versus</em> model-based methods (2D and\r\n3D approaches).  Cascaded detectors.\n\n<p></p></li>\n\n\n<a name=\"SECTION04034300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>understand visual processing from both \u201cbottom-up\u201d (data oriented) and\r\n\u201ctop-down\u201d (goals oriented) perspectives;\n\n<p></p></li>\n<li>be able to decompose visual tasks into sequences of image analysis\r\noperations, representations, specific algorithms, and inference principles;\n\n<p></p></li>\n<li>understand the roles of image transformations and their invariances\r\nin pattern recognition and classification;\n\n<p></p></li>\n<li>be able to analyse the robustness, brittleness, generalizability,\r\nand performance of different approaches in computer vision;\n\n<p></p></li>\n<li>be able to describe key aspects of how biological visual systems work;\r\nand be able to think of ways in which biological visual strategies might be\r\nimplemented in machine vision, despite the enormous differences in hardware;\n\n<p></p></li>\n<li>understand the roles of machine learning in computer vision today,\r\nincluding probabilistic inference, discriminative and generative methods; \n\n<p></p></li>\n<li>understand in depth at least one major practical application problem,\r\nsuch as face recognition, detection, and interpretation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04034400000000000000\">Recommended reading</a>\n\n* Shapiro, L. &amp; Stockman, G. (2001).  <em>Computer vision</em>. Prentice\u00a0Hall.\r\n\n\n", "course_name": "Computer Vision", "course_code": "CompVision", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/CompVision", "lecturers": ["jgd1000"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "DenotSem": {"supervisions": null, "lectures": 10, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-DenotationalSemantics.html", "description": "\n\n\n<a name=\"SECTION04035100000000000000\">Aims</a>\n\nThe aims of this course are to introduce domain theory and denotational\nsemantics, and to show how they provide a mathematical basis for reasoning\nabout the behaviour of programming languages.\n\n\n<br/>\n<a name=\"SECTION04035200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b>\nThe denotational approach to the semantics of programming languages.\nRecursively defined objects as limits of successive approximations.\n\n<p></p></li>\n<li><b>Least fixed points.</b>\nComplete \npartial orders\u00a0(cpos) and least elements.\nContinuous \nfunctions and least fixed points.\n\n<p></p></li>\n<li><b>Constructions on domains.</b>\nFlat domains.\nProduct domains. \nFunction domains.\n\n<p></p></li>\n<li><b>Scott induction.</b>\nChain-closed and admissible subsets of cpos and domains.\nScott\u2019s fixed-point induction principle. \n\n<p></p></li>\n<li><b>PCF.</b>\nThe Scott-Plotkin language\u00a0PCF.\nEvaluation. \nContextual equivalence.\n\n<p></p></li>\n<li><b>Denotational semantics of PCF.</b>\nDenotation of types and terms. \nCompositionality. \nSoundness with respect to evaluation. [2\u00a0lectures].\n\n<p></p></li>\n<li><b>Relating denotational and operational semantics.</b>\nFormal approximation relation and its fundamental property.\nComputational adequacy of the PCF denotational semantics with respect to\nevaluation. \nExtensionality properties of contextual equivalence. [2\u00a0lectures].\n\n<p></p></li>\n<li><b>Full abstraction.</b>\nFailure of full abstraction for the domain model.  PCF with parallel\u00a0or.\n\n<p></p></li>\n\n\n<br/>\n<a name=\"SECTION04035300000000000000\">Objectives</a>\n\n<br/>\nAt the end of the course students should\n\n\n<li>be familiar with basic domain theory: cpos, continuous functions,\nadmissible subsets, least fixed points, basic constructions on domains;\n\n<p></p></li>\n<li>be able to give denotational semantics to simple programming languages\nwith simple types;\n\n<p></p></li>\n<li>be able to apply denotational semantics; in particular, to understand the\nuse of least fixed points to model recursive programs and be able to\nreason about least fixed points and simple recursive programs using\nfixed point induction;\n\n<p></p></li>\n<li>understand the issues concerning the relation between denotational and\noperational semantics, adequacy and full abstraction, especially with\nrespect to the language\u00a0PCF.\n\n<p></p></li>\n\n\n<br/>\n<a name=\"SECTION04035400000000000000\">Recommended reading</a>\n\n<br/>\nWinskel, G. (1993). <em>The formal semantics of programming languages: an introduction</em>. MIT Press.\n<br/>Gunter, C. (1992). <em>Semantics of programming languages: structures and techniques</em>. MIT Press.\n<br/>Tennent, R. (1991). <em>Semantics of programming languages</em>.  Prentice Hall.\n\n\n\n", "course_name": "Denotational Semantics", "course_code": "DenotSem", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/DenotSem", "lecturers": ["amp12"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "InfoRtrv": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-InformationRetrieval.html", "description": "\n\n", "course_name": "Information Retrieval", "course_code": "InfoRtrv", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/InfoRtrv", "lecturers": ["sht25"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "NLP": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-NaturalLanguageProcessing.html", "description": "\n\n\n<a name=\"SECTION04037100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04037200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b>\nBrief history of NLP research, current applications, \ngeneric NLP system architecture.\n\n<p></p></li>\n<li><b>Finite-state techniques.</b>\nInflectional\nand derivational morphology, finite-state automata in NLP, finite-state\ntransducers. \n\n<p></p></li>\n<li><b>Prediction and part-of-speech tagging.</b>\nCorpora, simple N-grams, word prediction, stochastic tagging,\nevaluating system performance.\n\n<p></p></li>\n<li><b>Parsing and generation.</b> Generative grammar, context-free\ngrammars, parsing and generation with context-free grammars, weights\nand probabilities.\n\n<p></p></li>\n<li><b>Parsing with constraint-based grammars.</b> Constraint-based grammar,\nunification.\n\n<p></p></li>\n<li><b>Compositional and lexical semantics.</b>  \nSimple compositional semantics in constraint-based grammar.\nSemantic relations, WordNet, word senses,\nword sense disambiguation.\n\n<p></p></li>\n<li><b>Discourse and dialogue.</b>  Anaphora\nresolution, discourse relations.\n\n<p></p></li>\n<li><b>Applications.</b> Combination of components into applications.\n\n<p></p></li>\n\n\n<a name=\"SECTION04037300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to discuss the current and likely future performance of\n  several NLP applications;\n\n<p></p></li>\n<li>be able to describe briefly a fundamental technique for\n  processing language for several subtasks, such as\n  morphological processing, parsing, word sense disambiguation etc.;\n\n<p></p></li>\n<li>understand how these techniques draw on and relate to other\n  areas of computer science.\n\n<p></p></li>\n\n\n<a name=\"SECTION04037400000000000000\">Recommended reading</a>\n\n* Jurafsky, D. &amp; Martin, J. (2008). <em>Speech and language processing</em>. Prentice Hall.\n\nFor background reading, one of:\n<br/>Pinker, S. (1994). <i>The language instinct</i>. Penguin.\n<br/>Matthews, P. (2003). <i>Linguistics: a very short introduction</i>.  OUP.\n\nAlthough the NLP lectures don\u2019t assume any exposure to linguistics,\nthe course will be easier to follow if students have some\nunderstanding of basic linguistic concepts.\n\nFor reference purposes:\n<br/><em>The Internet Grammar of English</em>, <a href=\"http://www.ucl.ac.uk/internet-grammar/home.htm\" name=\"tex2html22\"><tt>http://www.ucl.ac.uk/internet-grammar/home.htm</tt></a>\n\n", "course_name": "Natural Language Processing", "course_code": "NLP", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/NLP", "lecturers": ["sht25"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "SecurityII": {"supervisions": null, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-SecurityII.html", "description": "\n\n\n<a name=\"SECTION04038100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04038200000000000000\">Lectures</a>\n\n<li><b>What is security?</b>\nIntroduction and definitions: different meanings of principal, system,\npolicy, trust. Diversity of applications. Relationship with\ndistributed system issues such as fault-tolerance and naming.\n\n<p></p></li>\n<li><b>Multilevel security.</b>\nThe Bell-LaPadula policy model; similar formulations such as the\nlattice model, non-interference and non-deducibility. Composability. Real\nMLS systems and their problems: covert channels, the cascade problem,\npolyinstantiation, dynamic and non-monotonic labelling.  Flexibility,\nusability and compatibility.\n\n<p></p></li>\n<li><b>Multilateral security policy models.</b> \nCompartmented systems, Chinese Wall, the BMA policy. Inference\nsecurity: query controls, trackers, cell suppression, randomization,\nstateful controls, and active attacks.\n\n<p></p></li>\n<li><b>Banking and bookkeeping systems.</b>\nDouble-entry bookkeeping, the Clark-Wilson policy model. Separation \nof duties, and its implementation problems. Payment systems and how\nthey fail: SWIFT, ATMs.\n\n<p></p></li>\n<li><b>Monitoring systems.</b>\nAlarms. Sensor defeats; feature interactions; attacks on\ncommunications; attacks on trust. Examples: antivirus software,\ntachographs, prepayment electricity meters.  Seals; electronic postal\nindicia.\n\n<p></p></li>\n<li><b>Telecommunications security.</b>\nAttacks on metering, signalling, switching and configuration. Attacks\non end systems. Feature interactions. Mobile phone issues: protection\nissues in GSM, GPRS, 3g. Surveillance technology and practice. Models of\nattacks on communications systems. \n\n<p></p></li>\n<li><b>Anonymity and peer-to-peer systems.</b>\nDining cryptographers; mix-nets. Models of opponents. Surveillance\n<em>versus</em> service denial. Peer-to-peer systems; resilience and censorship\nresistance.\n\n<p></p></li>\n<li><b>Hardware engineering issues.</b>\nTamper resistance: smartcards, cryptoprocessors. Mechanical and optical\nprobing, fault induction, power analysis, emission security, timing attacks.\n\n<p></p></li>\n<li><b>Software engineering issues.</b>\nClasses of software vulnerabilities: stack overflows, buffer overflows, \nnamespace and protocol issues, concurrency vulnerabilties. History, examples,\nexploits, and prevention.\n\n<p></p></li>\n<li><b>Stream ciphers.</b>  \nHistorical systems: Caesar, Vigen\u00e8re, Playfair. Revision of\ninformation theory: unicity distance, the one-time-pad, attacks in\ndepth. Shift register based systems: the multiplexer generator, RC4,\nA5. Attacks on these systems: divide and conquer, fast correlation.\n\n<p></p></li>\n<li><b>Block ciphers.</b>\nDesign of block ciphers: SP-networks and Feistel ciphers. Differential\nand linear cryptanalysis. AES; Serpent; DES. Revision of the random\noracle model: modes of operation. Splicing and collision attacks.\nMessage authentication codes and hash functions.\n\n<p></p></li>\n<li><b>Symmetric cryptographic protocols.</b>\nNeedham-Schroder, Otway-Rees, Kerberos, the wide-mouthed frog. The \nBAN logic. Applying BAN to verify a payment protocol. API security.\n\n<p></p></li>\n<li><b>Asymmetric cryptosystems.</b>\nRevision of public-key mathematics: RSA, ElGamal, Diffie-Hellman.\nElliptic curve systems, factoring algorithms. Advanced primitives:\nidentity-based schemes; threshold schemes; zero knowledge; blind\nsignatures.\n\n<p></p></li>\n<li><b>Asymmetric cryptographic protocols.</b>\nNeedham-Schroder, Denning-Sacco, TMN. Applications including SSL/TLS, \nSSH and PGP. The BAN logic applied to public key systems.\n\n<p></p></li>\n<li><b>Rights management and competition.</b>\nCopyright management systems; accessory control systems; the Trusted\nComputing architecture. Tensions between security and competition.\n\n<p></p></li>\n<li><b>Security engineering.</b>  \nWhy is security management hard? Security economics: the effects of\nmarket races, externalities, coordination problems, correlated risks, \nthe patching cycle, and supply chain effects. Problems with\ncertification including the Common Criteria. Behavioural and\norganisational effects. Interaction with the regulatory environment.\n\n<p></p></li>\n\n\n<a name=\"SECTION04038300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to tackle an\ninformation protection problem by drawing up a threat model,\nformulating a security policy, and designing specific protection\nmechanisms to implement the policy.\n\n\n<a name=\"SECTION04038400000000000000\">Recommended reading</a>\n\n* Anderson, R. (2008). <em>Security engineering</em>. Wiley (2nd ed.). First edition (2001) available at\u00a0\u00a0\u00a0\u00a0<a href=\"http://www.cl.cam.ac.uk/users/rja14/book.html\" name=\"tex2html23\"><tt>http://www.cl.cam.ac.uk/users/rja14/book.html</tt></a>\n<br/>Stinson, D.R. (2002). <em>Cryptography: theory and practice</em>. Chapman &amp; Hall (2nd ed.).\n<br/>Schneier, B. (1995). <em>Applied cryptography: protocols, algorithms, and source code in C</em>. Wiley (2nd ed.).\n\nFurther reading:\n\nKahn, D. (1966). <em>The codebreakers: the story of secret writing</em>.  Weidenfeld and Nicolson.\n<br/>Cheswick, W.R., Bellovin, S.M. &amp; Rubin, A.D. (2003). <em>Firewalls and Internet security: repelling the wily hacker</em>. Addison-Wesley (2nd ed.)\n<br/>Howard, M. &amp; leBlanc, D. (2003). <em>Writing secure code</em>. Microsoft Press  (2nd ed.)\n<br/>Gollmann, D. (2010). <em>Computer security</em>. Wiley (3rd ed.).\nKoblitz, N. (1994). <em>A course in number theory and cryptography</em>.  Springer-Verlag (2nd\u00a0ed.).\n<br/>Neumann, P. (1994). <em>Computer related risks</em>. Addison-Wesley.\n<br/>Biham, E. &amp; Shamir, A. (1993). <em>Differential cryptanalysis of the data encryption standard</em>. Springer-Verlag.\n<br/>Leveson, N.G. (1995). <em>Safeware: system safety and computers</em>.  Addison-Wesley.\n<br/>Konheim, A.G. (2007). <em>Computer security and cryptography</em>. Wiley.\n<br/>de Leeuw, K. &amp; Bergstra, J. (2007). <em>The history of information security</em>. Elsevier.\n\n\n", "course_name": "Security\u00a0II", "course_code": "SecurityII", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/SecurityII", "lecturers": ["fms27", "sjm217"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "TempLogic": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-TemporalLogicandModelChecking.html", "description": "\n\n\n<a name=\"SECTION04039100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04039200000000000000\">Lectures</a>\n\n<li><b>State transition systems.</b>\nRepresentation of state spaces. Reachable states. \n\n<p></p></li>\n<li><b>Checking reachability properties</b>\nFixed-point calculations. Symbolic methods using binary decision diagrams. Finding counter-examples.\n\n<p></p></li>\n<li><b>Examples.</b>\nVarious uses of reachability calculations.\n\n<p></p></li>\n<li><b>Temporal properties.</b>\nLinear and branching time. Intervals. Path quantifiers.\n\n<p></p></li>\n<li><b>Temporal logic.</b>  Brief history (Prior to Pnueli). CTL and LTL.\nStandarised logics: PSL.\n\n<p></p></li>\n<li><b>Model checking.</b>\nSimple algorithms for verifying that temporal properties hold. Reachability analysis as a special case.\n\n<p></p></li>\n<li><b>Applications.</b>\nSoftware and hardware examples.\n\n<p></p></li>\n<li><b>Advanced methods.</b>  Brief introduction to recent\n  development, e.g. Counter-example guided abstraction refinement\n  (CEGAR).\n\n<p></p></li>\n\n\n<a name=\"SECTION04039300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to write properties in a variety of temporal logic;\n\n<p></p></li>\n<li>be familiar with the core ideas of model checking;\n\n<p></p></li>\n<li>understand what commercial model checking tools can be used for.\n\n<p></p></li>\n\n\n<a name=\"SECTION04039400000000000000\">Recommended reading</a>\n\nHuth, M. &amp; Ryan M. (2004). <em>Logic in Computer Science: Modelling and Reasoning about Systems</em>. Cambridge University Press (2nd ed.).\n\n\n\n", "course_name": "Temporal Logic and Model Checking", "course_code": "TempLogic", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/TempLogic", "lecturers": ["mjcg"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "TopIssues": {"supervisions": null, "lectures": 19, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-TopicalIssues.html", "description": "\n\n\n<a name=\"SECTION040310100000000000000\">Aims</a>\n\n\n<a name=\"SECTION040310200000000000000\">Lectures</a>\n\nThis course provides an introduction to wide range of topical Computer\nScience subjects and provides coverage of topics not lectured in Part\nII due to sabbatical leave. In 2011-12 Topical issues will include:\n\n\n<li>3 lectures on Human-Computer Interaction\n\n<p></p></li>\n<li>4 lectures on the handling of large datasets\n\n<p></p></li>\n<li>12 lectures on topics that will be based on the\n  <a href=\"http://www.cl.cam.ac.uk/teaching/1011/TopIssues/\" name=\"tex2html24\">2010-11\n    course</a>\nbut are\n  subject to change in order to remain topical\n\n<p></p></li>\n\n\n<a name=\"SECTION040310300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>realise that the range of issues affecting the computer\n  community is very broad;\n\n<p></p></li>\n<li>be able to take part in discussions on several subjects at the\nfrontier of modern computer engineering.\n\n<p></p></li>\n\n\n", "course_name": "Topical Issues", "course_code": "TopIssues", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/TopIssues", "lecturers": ["rkh23"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": true}, "AdvGraph": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-AdvancedGraphics.html", "description": "\n\n\n<a name=\"SECTION04041100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04041200000000000000\">Lectures</a>\n\n\n<li><b>Revision and commercial context.</b>  Revision of the ray tracing\n  and polygon scan conversion methods of making images from 3D\n  models. The standard graphics pipeline and graphics cards.\n  Current uses of computer graphics in animation, visual effects,\n  Computer-Aided Design and marketing. [NAD, 1\u00a0lecture]\n\n<p></p></li>\n<li><b>Splines for modelling arbitrary 3D geometry.</b> (splines are\n  the standard 3D modelling mechanism for Computer-Aided Design).\n  Features required of surface models in a Computer-Aided Design\n  package.  Bezier curves and surfaces. B-splines, from uniform,\n  non-rational B-splines through to non-uniform, rational B-splines\n  (NURBS).  [NAD, 3\u00a0lectures]\n\n<p></p></li>\n<li><b>Subdivision surfaces.</b> (an alternative mechanism for\n  representing arbitrary 3D geometry, now widely used in the animation\n  industry). Introduction to subdivision. Pros and cons when compared\n  to NURBS. [NAD, 2\u00a0lectures]\n\n<p></p></li>\n<li><b>Geometric methods for ray tracing.</b> The fundamentals of \nraycasting and constructive solid geometry (CSG). [PAB, 1\u00a0lecture]\n\n<p></p></li>\n<li><b>Illumination: Ray tracing effects and global lighting.</b> Visual \neffects, radiosity and photon mapping. [PAB, 1\u00a0lecture]\n\n<p></p></li>\n<li><b>Computational geometry.</b> The mathematics of discrete geometry: \nwhat can you know, and how well can you know it? [PAB, 1\u00a0lecture]\n\n<p></p></li>\n<li><b>Implicit surfaces, voxels and particle systems.</b> A sampler of \nspecial effects techniques. [PAB, 1\u00a0lecture]\n\n<p></p></li>\n<li><b>OpenGL and shaders.</b> Tools and technologies available today; \npreviews of what\u2019s coming tomorrow. [PAB, 2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04041300000000000000\">Objectives</a>\n\nOn completing the course, students should be able to\n\n<li>compare and contrast ray tracing with polygon scan conversion;\n\n<p></p></li>\n<li>define NURBS basis functions, and explain how NURBS curves\n   and surfaces are used in 2D and 3D modelling;\n\n<p></p></li>\n<li>describe the underlying theory of subdivision and\n   define the Catmull-Clark and Doo-Sabin subdivision methods;\n\n<p></p></li>\n<li>understand the core technologies of ray tracing, constructive\n   solid geometry, computational geometry, implicit surfaces, voxel\n   rendering and particle systems;\n\n<p></p></li>\n<li>understand several global illumination technologies such as\n   radiosity and photon mapping, and be able to discuss each in detail;\n\n<p></p></li>\n<li>be able to describe current graphics technology and discuss\n   future possibilities.\n\n<p></p></li>\n\n\n<a name=\"SECTION04041400000000000000\">Recommended reading</a>\n\nStudents should expect to refer to one or more of these books, but\nshould not find it necessary to purchase any of them.\n\n* Slater, M., Steed, A. &amp; Chrysanthou, Y. (2002). <em>Computer graphics and virtual environments: from realism to real-time</em>. Addison-Wesley.\n<br/>Watt, A. (1999). <em>3D Computer graphics</em>. Addison-Wesley (3rd ed).\n<br/>de Berg, M., Cheong, O., van Kreveld, M. &amp; Overmars, M. (2008). <em>Computational geometry: algorithms and applications</em>. Springer (3rd ed.).\n<br/>Rogers, D.F. &amp; Adams, J.A. (1990). <em>Mathematical elements for computer graphics</em>. McGraw-Hill (2nd ed.).\n<br/>Warren, J. &amp; Weimer, H. (2002). <i>Subdivision methods for geometric design</i>. Morgan Kaufmann.\n\n\n", "course_name": "Advanced Graphics", "course_code": "AdvGraph", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/AdvGraph", "lecturers": ["nad10"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "BusSeminrs": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": null, "description": "\n\n\n<a name=\"SECTION04042100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04042200000000000000\">Lectures</a>\n\nEight lectures by eight different entrepreneurs.\n\n\n<a name=\"SECTION04042300000000000000\">Objectives</a>\n\nAt the end of the course students should have a better knowledge of the\npleasures and pitfalls of starting a high tech company.\n\n\n<a name=\"SECTION04042400000000000000\">Recommended reading</a>\n\nLang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook: how to start and run a high-tech company</em>. FT.COM/Prentice Hall.\n\nSee also the additional reading list on the Business Studies web page.\n\n\n", "course_name": "Business Studies Seminars", "course_code": "BusSeminrs", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/BusSeminrs", "lecturers": [], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "ECommerce": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-E-Commerce.html", "description": "\n\n\n<a name=\"SECTION04043100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04043200000000000000\">Lectures</a>\n\n<li><b>The history of electronic commerce.</b> Mail order; EDI;\n  web-based businesses, credit card processing, PKI, identity and\n  other hot topics.\n\n<p></p></li>\n<li><b>Network economics.</b> Real and virtual networks, supply-side\n  <em>versus</em> demand-side scale economies, Metcalfe\u2019s law, the dominant\n  firm model, the differentiated pricing model Data Protection Act,\n  Distance Selling regulations, business models.\n\n<p></p></li>\n<li><b>Web site design.</b> Stock and price control; domain names,\n  common mistakes, dynamic pages, transition diagrams, content\n  management systems, multiple targets.\n\n<p></p></li>\n<li><b>Web site implementation.</b> Merchant systems, system design\n  and sizing, enterprise integration, payment mechanisms, CRM and help\n  desks. Personalisation and internationalisation.\n\n<p></p></li>\n<li><b>The law and electronic commerce.</b> Contract and tort;\n  copyright; binding actions; liabilities and remedies. Legislation:\n  RIP; Data Protection; EU Directives on Distance Selling and\n  Electronic Signatures.\n\n<p></p></li>\n<li><b>Putting it into practice.</b> Search engine interaction,\n  driving and analysing traffic; dynamic pricing models. Integration\n  with traditional media. Logs and audit, data mining modelling the\n  user. collaborative filtering and affinity marketing brand value,\n  building communities, typical behaviour.\n\n<p></p></li>\n<li><b>Finance.</b> How business plans are put together. Funding\n  Internet ventures; the recent hysteria; maximising shareholder\n  value. Future trends.\n\n<p></p></li>\n<li><b>UK and International Internet Regulation.</b> Data Protection\n  Act and US Privacy laws; HIPAA, Sarbanes-Oxley, Security Breach\n  Disclosure, RIP Act 2000, Electronic Communications Act 2000,\n  Patriot Act, Privacy Directives, data retention; specific issues:\n  deep linking, Inlining, brand misuse, phishing.\n\n<p></p></li>\n\n\n<a name=\"SECTION04043300000000000000\">Objectives</a>\n\nAt the end of the course students should know how to apply their\ncomputer science skills to the conduct of e-commerce with some\nunderstanding of the legal, security, commercial, economic, marketing\nand infrastructure issues involved.\n\n\n<a name=\"SECTION04043400000000000000\">Recommended reading</a>\n\nShapiro, C. &amp; Varian, H. (1998). <em>Information rules</em>. Harvard Business School Press.\n\nAdditional reading:\n\nStandage, T. (1999). <em>The Victorian Internet</em>. Phoenix Press.\nKlemperer, P. (2004). <em>Auctions: theory and practice</em>. Princeton Paperback ISBN 0-691-11925-2.\n\n\n", "course_name": "E-Commerce", "course_code": "ECommerce", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/ECommerce", "lecturers": [], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "MobSensSys": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-MobileandSensorSystems.html", "description": "\n\n\n<a name=\"SECTION04044100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04044200000000000000\">Lectures</a>\n\n\n<li><b>Wireless propagation and MAC Layer.</b>\nDifferences in transmission in wired and wireless medium. Introduction to MAC layer protocols of wireless and mobile systems.\n\n<p></p></li>\n<li><b>Mobile phones architectures and communication.</b>\nIntroduction to existing mobile phones and operating systems for mobiles.\n\n<p></p></li>\n<li><b>Mobile Infrastructure communication  and opportunistic networking protocol.</b>\nDescription of common communication architectures and protocols for mobile phones and introduction to models of opportunistic networking.\n\n<p></p></li>\n<li><b>Introduction to sensor systems architecture.</b>\nsensor systems challenges and applications.\n\n<p></p></li>\n<li><b>Sensor systems MAC layer protocols.</b>\nIntroduction to concepts related to duty cycling and energy preservation \nprotocols.\n\n<p></p></li>\n<li><b>Sensor systems routing protocols.</b>\nCommunication protocols, data aggregation and dissemination in sensor \nnetworks.\n\n<p></p></li>\n<li><b>Sensor systems programming and reprogramming.</b>\nMotivation of sensor reprogramming and approaches to sensor network \nmanagement and update.\n\n<p></p></li>\n<li><b>Mobile sensing and participatory sensing.</b>\nMobile sensor networks and use of mobile phones as sensors. \n\n<p></p></li>\n\n\n<a name=\"SECTION04044300000000000000\">Objectives</a>\n\nOn completing the course, students should be able to\n\n\n<li>describe similarities and differences between standard\n distributed systems and mobile and sensor systems;\n\n<p></p></li>\n<li>explain the fundamental tradeoffs related to energy limitations\n and communication needs in these systems;\n\n<p></p></li>\n<li>argue for and against different mobile and sensor systems\n architectures and protocols.\n\n<p></p></li>\n\n\n<a name=\"SECTION04044400000000000000\">Recommended reading</a>\n\n\n* Schiller, J. (2003). <em>Mobile communications</em>. Pearson (2nd ed.).\n<br/>* Karl, H. &amp; Willig, A. (2005). <em>Protocols and architectures for wireless sensor networks</em>. Wiley.\n<br/>Agrawal, D. &amp; Zheng, Q. (2006). <em>Introduction to wireless and mobile systems</em>. Thomson.\n\n\n", "course_name": "Mobile and Sensor Systems", "course_code": "MobSensSys", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/MobSensSys", "lecturers": ["cm542"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "SysOnChip": {"supervisions": null, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-System-on-ChipDesign.html", "description": "\n\n\n<a name=\"SECTION04045100000000000000\">Aims</a>\n\nA percentage of each lecture is used to develop a running example.\nOver the course of the lectures, the example evolves into a System On\nChip demonstrator with CPU and bus models, device models and device\ndrivers. All code and tools are available online so the examples can\nbe reproduced and exercises undertaken.  The main languages used are\nVerilog and C++ using the SystemC library.\n\n\n<a name=\"SECTION04045200000000000000\">Lectures</a>\n\n<li><b>Verilog RTL design with examples.</b>  Event-driven simulation\n  with and without delta cycles, basic gate synthesis\n  algorithm and design examples.  Structural hazards, pipelining,\n  memories and multipliers. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>SystemC overview.</b> The major components of the SystemC C++\n  class library for hardware modelling are covered with code fragments\n  and demonstrations. Queuing/contention delay modelling. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Basic bus structures.</b>  Bus structure. I/O device\n  structure. Interrupts, DMA and device drivers. Examples. Basic bus\n  bridging.\n\n<p></p></li>\n<li><b>ESL + transactional modelling.</b> Electronic systems level\n  (ESL) design.  Architectural exploration.  Firmware modelling\n  methods. Blocking and non-blocking transaction styles.  Approximate\n  and loose timing styles. Examples. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>ABD: assertions and monitors.</b>  Types of assertion\n  (imperative, safety, liveness, data conservation). Assertion-based\n  design (ABD).  PSL/SVA assertions.  Temporal logic compilation of\n  fragments to monitoring FSM.  [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Further bus structures.</b>  Busses used in today\u2019s SoCs\n  (OPB/BVCI, AHB and AXI).  Glue logic synthesis. Transactor\n  synthesis. Pipeline Tolerance. Network on chip.\n\n<p></p></li>\n<li><b>Engineering aspects: FPGA and ASIC design flow.</b> Cell\n  libraries. Market breakdown: CPU/Commodity/ASIC/FPGA.  Further tools\n  used for design of FPGA and ASIC (timing and power modelling, place\n  and route, memory generators, power gating, clock tree, self-test\n  and scan insertion).  Dynamic frequency and voltage scaling.\n\n<p></p></li>\n<li><b>Future approaches</b> <em>Only presented if time\n  permits. Non-examinable.</em> Recent developments: BlueSpec, IP-XACT,\n  Kiwi, Custom processor synthesis.\n\n<p></p></li>\n\nIn addition to these topics, the running example will demonstrate\na few practical aspects of device bus interface design, on chip\ncommunication and device control software.  Students are encouraged\nto try out and expand the examples in their own time.\n\n\n<a name=\"SECTION04045300000000000000\">Objectives</a>\n\nAt the end of the course students should \n\n\n<li>be familiar with how a complex gadget containing multiple processors,\nsuch as an iPod or Satnav, is designed and developed;\n\n<p></p></li>\n<li>understand the hardware and software structures used \nto implement and model inter-component communication in such devices;\n\n<p></p></li>\n<li>have basic exposure to SystemC programming and PSL assertions.\n\n<p></p></li>\n\n\n<a name=\"SECTION04045400000000000000\">Recommended reading</a>\n\n* OSCI. <span class=\"textit\">SystemC tutorials and whitepapers</span>. Download from OSCI <tt><a href=\"http://www.systemc.org\" name=\"tex2html25\">http://www.systemc.org</a></tt> or copy from course web site.\n<br/>Ghenassia, F. (2010). <span class=\"textit\">Transaction-level modeling with SystemC: TLM concepts and applications for embedded systems</span>. Springer.\n<br/>Eisner, C. &amp; Fisman, D. (2006). <span class=\"textit\">A practical introduction to PSL</span>. Springer (Series on Integrated Circuits and Systems).\n<br/>Foster, H.D. &amp; Krolnik, A.C. (2008). <span class=\"textit\">Creating assertion-based IP</span>. Springer (Series on Integrated Circuits and Systems).\n<br/>Grotker, T., Liao, S., Martin, G. &amp; Swan, S. (2002). <span class=\"textit\">System design with SystemC</span>. Springer.\n<br/>Wolf, W. (2009). <span class=\"textit\">Modern VLSI design (System-on-chip design)</span>. Pearson Education (4th ed.).\n\n\n", "course_name": "System-on-Chip Design", "course_code": "SysOnChip", "course_url": "https://www.cl.cam.ac.uk/teaching/1112/SysOnChip", "lecturers": ["djg11"], "year": "1112", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}}