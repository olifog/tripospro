{"Bioinfo": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Bioinformatics.html", "description": "\n\n\n<a name=\"SECTION04021100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04021200000000000000\">Lectures</a>\n\n\n<li><b>Introduction to biological data:</b> Bioinformatics as an interesting\nfield in computer science. \n\n<p></p></li>\n<li><b>Dynamic programming.</b> Longest common subsequence, DNA global and\nlocal alignment, linear space alignment, Nussinov algorithm for RNA, heuristics\nfor multiple alignment.\n\n<p></p></li>\n<li><b>Sequence database search.</b> Blast.\n\n<p></p></li>\n<li><b>Genome sequencing.</b> De Bruijn graph.\n\n<p></p></li>\n<li><b>Phylogeny.</b> Distance based algorithms (UPGMA, Neighbour-Joining).\nParsimony-based algorithms.\n\n<p></p></li>\n<li><b>Clustering.</b> Hard and soft K-means clustering, use of Expectation\nMaximization in clustering, Hierarchical clustering, Markov clustering\nalgorithm.\n\n<p></p></li>\n<li><b>Genomics Pattern Matching.</b> Suffix Tree String Compression and the\nBurrows-Wheeler Transform.\n\n<p></p></li>\n<li><b>Hidden Markov Models.</b> The Viterbi algorithm, profile HMMs for\nsequence alignment, classifying proteins with profile HMMs, soft decoding\nproblem, Baum-Welch learning\n\n<p></p></li>\n\n\n<a name=\"SECTION04021300000000000000\">Objectives</a>\n\nAt the end of this course students should\n\n\n<li>understand Bioinformatics terminology;\n\n<p></p></li>\n<li>have mastered the most important algorithms in the field;\n\n<p></p></li>\n<li>be able to work with bioinformaticians and biologists;\n\n<p></p></li>\n<li>be able to find data and literature in repositories.\n\n<p></p></li>\n\n\n<a name=\"SECTION04021400000000000000\">Recommended reading</a>\n\n* Compeau, P. &amp; Pevzner, P.A. (2015). <em>Bioinformatics algorithms: an\nactive learning approach</em>. Active Learning Publishers.\n<br/>Durbin, R., Eddy, S., Krough, A. &amp; Mitchison, G. (1998). <em>Biological sequence analysis: probabilistic models of proteins and\nnucleic acids</em>. Cambridge University Press.\n<br/>Jones, N.C. &amp; Pevzner, P.A. (2004). <em>An introduction to bioinformatics\nalgorithms</em>. MIT Press.\n<br/>Felsenstein, J. (2003). <em>Inferring phylogenies</em>. Sinauer Associates.\n\n\n", "course_name": "Bioinformatics", "course_code": "Bioinfo", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/Bioinfo", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "Business": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-BusinessStudies.html", "description": "\n\n\n<a name=\"SECTION04022100000000000000\">Aims</a>\n\nSee also Business Seminars in the Easter Term.\n\n\n<a name=\"SECTION04022200000000000000\">Lectures</a>\n\n<li><b>So you\u2019ve got an idea?</b>\nIntroduction. Why are you doing it and what is it? Types of\ncompany. Market analysis. The business plan. \n\n<p></p></li>\n<li><b>Money and tools for its management.</b>\nIntroduction to accounting: profit and loss, cash flow, balance sheet,\nbudgets. Sources of finance. Stocks and shares. Options and futures.\n\n<p></p></li>\n<li><b>Setting up: legal aspects.</b>\nCompany formation. Brief introduction to business law; duties of\ndirectors.  Shares, stock options, profit share schemes and the like.\nIntellectual Property Rights, patents, trademarks and\ncopyright. Company culture and management theory.\n\n<p></p></li>\n<li><b>People.</b>\nMotivating factors. Groups and teams. Ego. Hiring and firing:\nemployment law. Interviews. Meeting techniques.\n\n<p></p></li>\n<li><b>Project planning and management.</b>\nRole of a manager. PERT and GANTT charts, and critical path\nanalysis. Estimation techniques. Monitoring.\n\n<p></p></li>\n<li><b>Quality, maintenance and documentation.</b>\nDevelopment cycle. Productization. Plan for quality. Plan for\nmaintenance. Plan for documentation.\n\n<p></p></li>\n<li><b>Marketing and selling.</b>\nSales and marketing are different. Marketing; channels; marketing\ncommunications.  Stages in selling. Control and commissions.\n\n<p></p></li>\n<li><b>Growth and exit routes.</b>\nNew markets: horizontal and vertical expansion. Problems of growth;\nsecond system effects. Management structures. Communication. Exit\nroutes: acquisition, floatation, MBO or\nliquidation. Futures: some emerging\nideas for new computer businesses.\nSummary. Conclusion: now you do it!\n\n<p></p></li>\n\n\n<a name=\"SECTION04022300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to write and analyse a business plan;\n\n<p></p></li>\n<li>know how to construct PERT and GANTT diagrams and perform critical\npath analysis;\n\n<p></p></li>\n<li>appreciate the differences between profitability and cash flow, and\nhave some notion of budget estimation;\n\n<p></p></li>\n<li>have an outline view of company formation, share structure, capital\nraising, growth and exit routes;\n\n<p></p></li>\n<li>have been introduced to concepts of team formation and management;\n\n<p></p></li>\n<li>know about quality documentation and productization processes;\n\n<p></p></li>\n<li>understand the rudiments of marketing and the sales process.\n\n<p></p></li>\n\n\n<a name=\"SECTION04022400000000000000\">Recommended reading</a>\n\nLang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook: how to start and run a high-tech company</em>. FT.COM/Prentice\u00a0Hall.\n\nStudents will be expected to be able to use Microsoft Excel and Microsoft\nProject.\n\nFor additional reading on a lecture-by-lecture basis, please see the course\nwebsite.\n\nStudents are strongly recommended to enter the CU Entrepreneurs Business\nIdeas Competition <a href=\"http://www.cue.org.uk/\" name=\"tex2html22\"><tt>http://www.cue.org.uk/</tt></a>\n\n", "course_name": "Business Studies", "course_code": "Business", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/Business", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "DenotSem": {"supervisions": 3, "lectures": 10, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-DenotationalSemantics.html", "description": "\n\n\n<a name=\"SECTION04023100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04023200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b>\nThe denotational approach to the semantics of programming languages.\nRecursively defined objects as limits of successive approximations.\n\n<p></p></li>\n<li><b>Least fixed points.</b>\nComplete \npartial orders\u00a0(cpos) and least elements.\nContinuous \nfunctions and least fixed points.\n\n<p></p></li>\n<li><b>Constructions on domains.</b>\nFlat domains.\nProduct domains. \nFunction domains.\n\n<p></p></li>\n<li><b>Scott induction.</b>\nChain-closed and admissible subsets of cpos and domains.\nScott\u2019s fixed-point induction principle. \n\n<p></p></li>\n<li><b>PCF.</b>\nThe Scott-Plotkin language\u00a0PCF.\nEvaluation. \nContextual equivalence.\n\n<p></p></li>\n<li><b>Denotational semantics of PCF.</b>\nDenotation of types and terms. \nCompositionality. \nSoundness with respect to evaluation. [2\u00a0lectures].\n\n<p></p></li>\n<li><b>Relating denotational and operational semantics.</b>\nFormal approximation relation and its fundamental property.\nComputational adequacy of the PCF denotational semantics with respect to\nevaluation. \nExtensionality properties of contextual equivalence. [2\u00a0lectures].\n\n<p></p></li>\n<li><b>Full abstraction.</b>\nFailure of full abstraction for the domain model.  PCF with parallel\u00a0or.\n\n<p></p></li>\n\n\n<a name=\"SECTION04023300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be familiar with basic domain theory: cpos, continuous functions,\nadmissible subsets, least fixed points, basic constructions on domains;\n\n<p></p></li>\n<li>be able to give denotational semantics to simple programming languages\nwith simple types;\n\n<p></p></li>\n<li>be able to apply denotational semantics; in particular, to understand the\nuse of least fixed points to model recursive programs and be able to\nreason about least fixed points and simple recursive programs using\nfixed point induction;\n\n<p></p></li>\n<li>understand the issues concerning the relation between denotational and\noperational semantics, adequacy and full abstraction, especially with\nrespect to the language\u00a0PCF.\n\n<p></p></li>\n\n\n<a name=\"SECTION04023400000000000000\">Recommended reading</a>\n\nWinskel, G. (1993). <em>The formal semantics of programming languages: an introduction</em>. MIT Press.\n<br/>Gunter, C. (1992). <em>Semantics of programming languages: structures and techniques</em>. MIT Press.\n<br/>Tennent, R. (1991). <em>Semantics of programming languages</em>.  Prentice Hall.\n\n\n\n", "course_name": "Denotational Semantics", "course_code": "DenotSem", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/DenotSem", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "DSP": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-DigitalSignalProcessing.html", "description": "\n\n\n<a name=\"SECTION04024100000000000000\">\nAims</a>\n\n\n<a name=\"SECTION04024200000000000000\">\nLectures</a>\n\n\n<li><b>Signals and systems.</b> Discrete sequences and systems, their\n  types and properties. Linear time-invariant systems, convolution.\n\n<p>\n</p></li>\n<li><b>Phasors.</b> Eigen functions of linear time-invariant systems.\n  Review of complex arithmetic. Some examples from electronics, optics\n  and acoustics.\n\n<p>\n</p></li>\n<li><b>Fourier transform.</b> Phasors as orthogonal base functions.\n  Forms and properties of the Fourier transform. Convolution theorem.\n\n<p>\n</p></li>\n<li><b>Dirac\u2019s delta function.</b> Fourier representation of sine\n  waves, impulse combs in the time and frequency domain.\n\n<p>\n</p></li>\n<li><b>Discrete sequences and spectra.</b> Periodic sampling of\n  continuous signals, periodic signals, aliasing, interpolation,\n  sampling and reconstruction of low-pass and band-pass signals,\n  spectral inversion.\n\n<p>\n</p></li>\n<li><b>Digital modulation.</b> IQ representation of band-pass signals,\n  in particular AM, FM, PSK, and QAM signals.\n\n<p>\n</p></li>\n<li><b>Discrete Fourier transform.</b> Continuous <em>versus</em>\n  discrete Fourier transform, symmetry, linearity, review of the FFT,\n  real-valued FFT.\n\n<p>\n</p></li>\n<li><b>Spectral estimation.</b> Short-time Fourier transform, leakage\n  and scalloping phenomena, windowing, zero padding.\n\n<p>\n</p></li>\n<li><b>Finite impulse-response filters.</b> Properties of\n  filters, implementation forms, window-based FIR design, use of\n  frequency-inversion to obtain high-pass filters, use of modulation\n  to obtain band-pass filters, FFT-based convolution.\n\n<p>\n</p></li>\n<li><b>Infinite impulse-response filters.</b> Sequences as\n  polynomials, <em>z</em>-transform, zeros and poles, some analog IIR design\n  techniques (Butterworth, Chebyshev I/II, elliptic filters).\n\n<p>\n</p></li>\n<li><b>Random sequences and noise.</b> Random variables, stationary\n  processes, autocorrelation, crosscorrelation, deterministic\n  crosscorrelation sequences, filtered random sequences, white noise,\n  exponential averaging.\n\n<p>\n</p></li>\n<li><b>Correlation coding.</b> Random vectors, dependence <em>    versus</em> correlation, covariance, decorrelation, matrix\n  diagonalization, eigen decomposition, Karhunen-Lo\u00e8ve transform,\n  principal component analysis. Relation to orthogonal transform\n  coding using fixed basis vectors, such as DCT.\n\n<p>\n</p></li>\n\n\n<a name=\"SECTION04024300000000000000\">\nObjectives</a>\n\n\nBy the end of the course students should be able to \n\n\n\n<li>apply basic properties of time-invariant linear\n  systems;\n\n<p>\n</p></li>\n<li>understand sampling, aliasing, convolution, filtering, the\n  pitfalls of spectral estimation;\n\n<p>\n</p></li>\n<li>explain the above in time and frequency domain representations;\n\n<p>\n</p></li>\n<li>use filter-design software;\n\n<p>\n</p></li>\n<li>visualize and discuss digital filters in the <em>z</em>-domain;\n\n<p>\n</p></li>\n<li>use the FFT for convolution, deconvolution, filtering;\n\n<p>\n</p></li>\n<li>implement, apply and evaluate simple DSP applications in MATLAB;\n\n<p>\n</p></li>\n<li>apply transforms that reduce correlation between several signal\n  sources;\n\n<p>\n</p></li>\n<li>explain the basic principles of some widely-used\n  modulation and image-coding techniques.\n\n<p>\n</p></li>\n\n\n<a name=\"SECTION04024400000000000000\">\nRecommended reading</a>\n\n\n* Lyons, R.G. (2010). <em>Understanding digital signal processing.</em> Prentice\u00a0Hall (3rd ed.).\n<br/>\nOppenheim, A.V. &amp; Schafer, R.W. (2007). <em>Discrete-time digital signal processing.</em> Prentice\u00a0Hall (3rd ed.).\n<br/>\n\n\n", "course_name": "Digital Signal Processing", "course_code": "DSP", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/DSP", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "HCI": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Human-ComputerInteraction.html", "description": "\n\n\n<a name=\"SECTION04025100000000000000\">Aims</a>\n\n<br/>\n<a name=\"SECTION04025200000000000000\">Lectures</a>\n\n<li><b>The scope and challenges of HCI and Interaction Design.</b>\n<p></p></li>\n<li><b>Visual representation.</b> Segmentation and variables of the\n  display plane. Modes of correspondence.\n\n<p></p></li>\n<li><b>Text and gesture interaction.</b> Evolution of interaction\n  hardware.  Measurement and assessment of novel methods.\n\n<p></p></li>\n<li><b>Inference-based approaches.</b> Bayesian strategies for data\n  entry, and programming by example.\n\n<p></p></li>\n<li><b>Augmented reality and tangible user interfaces.</b> Machine\n  vision, fiducial markers, paper interfaces, mixed reality.\n\n<p></p></li>\n<li><b>Usability of programming languages.</b> End-user programming,\n  programming for children, cognitive dimensions of notations.\n\n<p></p></li>\n<li><b>User-centred design research.</b> Contextual observation,\n  prototyping, think-aloud protocols, qualitative data in the design\n  cycle.\n\n<p></p></li>\n<li><b>Usability evaluation methods.</b> Formative and summative methods.  \nEmpirical measures. Evaluation of Part II projects.\n\n<p></p></li>\n\n<br/>\n<a name=\"SECTION04025300000000000000\">Objectives</a>\n\nOn completing the course, students should be able to\n\n\n<li>propose design approaches that are suitable to different classes of\nuser and application;\n\n<p></p></li>\n<li>identify appropriate techniques for analysis and critique of user\ninterfaces;\n\n<p></p></li>\n<li>be able to design and undertake quantitative and qualitative studies\nin order to improve the design of interactive systems;\n\n<p></p></li>\n<li>understand the history and purpose of the features of contemporary user \ninterfaces.\n\n<p></p></li>\n\n\n<a name=\"SECTION04025400000000000000\">Recommended reading</a>\n\n* Sharp, H., Rogers, Y. &amp; Preece, J. (2007). <i>Interaction design: beyond human-computer interaction</i>. Wiley (2nd ed.).\n\nFurther reading:\n\nCarroll, J.M. (ed.) (2003). <em>HCI models, theories and frameworks: toward a multi-disciplinary science</em>. Morgan Kaufmann.\n<br/>Cairns, P. &amp; Cox, A. (eds.) (2008). <em>Research methods for human-computer interaction</em>. Cambridge University Press.\n\n\n", "course_name": "Human\u2013Computer Interaction", "course_code": "HCI", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/HCI", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "InfoTheory": {"supervisions": 0, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-InformationTheory.html", "description": "\n\n\n<a name=\"SECTION04026100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04026200000000000000\">Lectures</a>\n\n<li><b>Foundations:  probability, uncertainty, information.</b>\nHow concepts of randomness, redundancy, compressibility, noise,\nbandwidth, and uncertainty are related to information.  Ensembles,\nrandom variables, marginal and conditional probabilities.  How the\nmetrics of information are grounded in the rules of probability.\n\n<p></p></li>\n<li><b>Entropies defined, and why they are measures of information.</b> \nMarginal entropy, joint entropy, conditional entropy,\nand the Chain Rule for entropy.  Mutual information between ensembles\nof random variables.  Why entropy is the fundamental measure of\ninformation content.\n\n<p></p></li>\n<li><b>Source coding theorem; prefix, variable-, and fixed-length codes.</b>\nMarkov sources.  Entropy rate of a Markov process.  Symbol codes. \nHuffman codes and the prefix property.  Binary symmetric channels. \nCapacity of a noiseless discrete channel.\n\n<p></p></li>\n<li><b>Discrete channel properties, noise, and channel capacity.</b>\nPerfect communication through a noisy channel:  error-correcting codes.\nCapacity of a discrete channel as the maximum of its mutual information \nover all possible input distributions. \n\n<p></p></li>\n<li><b>Spectral properties of continuous-time signals and channels.</b>\nSignals represented as combinations of complex exponential eigenfunctions;\nchannels represented as spectral filters that add noise.  Applying\nFourier analysis to signal communication.  Continuous versus discrete, and\nperiodic versus aperiodic signals and their transforms.  Duality properties.\n\n<p></p></li>\n<li><b>Continuous information; density; noisy channel coding theorem.</b>\nExtensions of discrete entropies and measures to the continuous case.\nSignal-to-noise ratio; power spectral density.  Gaussian channels.\nRelative significance of bandwidth and noise limitations.  \nThe Shannon rate limit for noisy continuous channels.\n\n<p></p></li>\n<li><b>Signal coding and transmission schemes using Fourier theorems.</b>\nNyquist Sampling Theorem.   Aliasing and its prevention.\nModulation and shift theorems; multiple carriers; frequency and\nphase modulation codes; ensembles.  Filters, coherence, demodulation;\nnoise removal by correlation.\n\n<p></p></li>\n<li><b>The quantized degrees-of-freedom in a continuous signal.</b>\nWhy a continuous signal of finite bandwidth and duration has a fixed\nnumber of degrees-of-freedom.  Diverse illustrations of the principle\nthat information, even in such a signal, comes in quantized, countable,\npackets.\n\n<p></p></li>\n<li><b>Gabor-Heisenberg-Weyl uncertainty relation.  Optimal \u201cLogons\u201d.</b>\nUnification of the time-domain and the frequency-domain as endpoints \nof a continuous deformation.  The Uncertainty Principle and its optimal\nsolution by Gabor\u2019s expansion basis of \u201clogons\u201d.  Multi-resolution \nwavelet codes.  Extension to images, for analysis and compression.\n\n<p></p></li>\n<li><b>Data compression codes and protocols.</b>\nRun-length coding; dictionary methods on strings; vector quantisation;\nJPEG and JP2K image compression; orthogonal subspace projections;\npredictive coding; the Laplacian pyramid; and wavelet scalar\nquantisation.\n\n<p></p></li>\n<li><b>Kolmogorov complexity.  Minimal description length.</b>\nDefinition of the algorithmic complexity of a data sequence, and \nits relation to the entropy of the distribution from which the data \nwas drawn.  Fractals.  Minimal description length, and why this measure\nof complexity is not computable.\n\n<p></p></li>\n<li><b>Applications of information theory in other sciences.</b>\nUse of information metrics and analysis in:  genomics; neuroscience;\nastrophysics; noisy signal classification; and pattern recognition\nincluding biometrics.\n\n<p></p></li>\n\n\n<a name=\"SECTION04026300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to\n\n\n<li>calculate the information content of a random variable\nfrom its probability distribution;\n\n<p></p></li>\n<li>relate the joint, conditional, and marginal entropies \nof variables in terms of their coupled probabilities;\n\n<p></p></li>\n<li>define channel capacities and properties using Shannon\u2019s Theorems;\n\n<p></p></li>\n<li>construct efficient codes for data on imperfect communication channels;\n\n<p></p></li>\n<li>generalize the discrete concepts to continuous signals on continuous \nchannels;\n\n<p></p></li>\n<li>understand encoding and communication schemes in terms of\nthe spectral properties of signals and channels;\n\n<p></p></li>\n<li>describe compression schemes, and efficient coding using wavelets\nand other representations for data.\n\n<p></p></li>\n\n\n<a name=\"SECTION04026400000000000000\">Recommended reading</a>\n\n* Cover, T.M. &amp; Thomas, J.A. (2006). <em>Elements of information theory</em>. New York: Wiley.\n\n\n", "course_name": "Information Theory", "course_code": "InfoTheory", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/InfoTheory", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "TeX+MATLAB": {"supervisions": 1, "lectures": 2, "prerequisite_for": [], "past_exam_questions": null, "description": "\n\n\n<a name=\"SECTION04027100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04027200000000000000\">Lectures</a>\n\n<li><b><span class=\"logo,LaTeX\">L<sup><small>A</small></sup>T<small>E</small>X</span>.</b> Workflow example, syntax, typesetting conventions,\n  non-ASCII characters, document structure, packages, mathematical\n  typesetting, graphics and figures, cross references, build tools.\n\n<p></p></li>\n<li><b>MATLAB.</b> Tools for technical computing and visualization.\n  The matrix type and its operators, 2D/3D plotting, common functions,\n  function definitions, toolboxes, vectorized audio demonstration.\n\n<p></p></li>\n\n\n<a name=\"SECTION04027300000000000000\">Objectives</a>\n\nStudents should be able to avoid the most common <span class=\"logo,LaTeX\">L<sup><small>A</small></sup>T<small>E</small>X</span> mistakes,\nto prototype simple image and signal processing\nalgorithms in MATLAB, and to visualize the results.\n\n\n<a name=\"SECTION04027400000000000000\">Recommended reading</a>\n\n* Lamport, L. (1994). <em><span class=\"logo,LaTeX\">L<sup><small>A</small></sup>T<small>E</small>X</span> - a documentation preparation system user\u2019s guide and reference manual</em>. Addison-Wesley (2nd ed.).\n\nMittelbach, F., et al. (2004). <em>The <span class=\"logo,LaTeX\">L<sup><small>A</small></sup>T<small>E</small>X</span> companion</em>. Addison-Wesley (2nd ed.).\n\n\n", "course_name": "LaTeX and MATLAB", "course_code": "TeX+MATLAB", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/TeX+MATLAB", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "NLP": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-NaturalLanguageProcessing.html", "description": "\n\n\n<a name=\"SECTION04028100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04028200000000000000\">Lectures</a>\n\nThe order of delivery of the lectures is provisional.\n\n\n<li><b>Introduction.</b>\nBrief history of NLP research, current applications, \ncomponents of NLP systems.\n\n<p></p></li>\n<li><b>Finite-state techniques.</b>\nInflectional\nand derivational morphology, finite-state automata in NLP, finite-state\ntransducers. \n\n<p></p></li>\n<li><b>Prediction and part-of-speech tagging.</b>\nCorpora, simple N-grams, word prediction, stochastic tagging,\nevaluating system performance.\n\n<p></p></li>\n<li><b>Context-free grammars and parsing.</b> Generative grammar, context-free\ngrammars, parsing with context-free grammars, weights\nand probabilities. Limitations of context-free grammars. Dependencies.\n\n<p></p></li>\n<li><b>Lexical semantics.</b>  \nSemantic relations, WordNet, word senses,\nword sense disambiguation.\n\n<p></p></li>\n<li><b>Distributional semantics 1.</b>\nRepresenting lexical meaning with distributions. Similarity metrics.\n\n<p></p></li>\n<li><b>Distributional semantics 2.</b>\nGeneralisation and clustering. Selectional preference induction. Multimodal semantics.\n\n<p></p></li>\n<li><b>Compositional semantics.</b> \nCompositional semantics with FOPL and lambda calculus. Compositional distributional semantics. Inference and entailment.\n\n<p></p></li>\n<li><b>Discourse processing.</b>  Anaphora\nresolution, discourse relations.\n\n<p></p></li>\n<li><b>Language generation and regeneration.</b>\nComponents of a generation system. Summarisation.\n\n<p></p></li>\n<li><b>Applications.</b> \nExamples of practical applications of NLP techniques.\n\n<p></p></li>\n<li><b>Recent trends in NLP research.</b> \nRecent trends in NLP research.\n\n<p></p></li>\n\n\n<a name=\"SECTION04028300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to discuss the current and likely future performance of\n  several NLP applications;\n\n<p></p></li>\n<li>be able to describe briefly a fundamental technique for\n  processing language for several subtasks, such as\n  morphological processing, parsing, word sense disambiguation etc.;\n\n<p></p></li>\n<li>understand how these techniques draw on and relate to other\n  areas of computer science.\n\n<p></p></li>\n\n\n<a name=\"SECTION04028400000000000000\">Recommended reading</a>\n\n* Jurafsky, D. &amp; Martin, J. (2008). <em>Speech and language processing</em>. Prentice Hall.\n\nFor background reading, one of:\n<br/>Pinker, S. (1994). <i>The language instinct</i>. Penguin.\n<br/>Matthews, P. (2003). <i>Linguistics: a very short introduction</i>.  OUP.\n\nAlthough the NLP lectures don\u2019t assume any exposure to linguistics,\nthe course will be easier to follow if students have some\nunderstanding of basic linguistic concepts.\n\nFor reference purposes:\n<br/><em>The Internet Grammar of English</em>, <a href=\"http://www.ucl.ac.uk/internet-grammar/home.htm\" name=\"tex2html23\"><tt>http://www.ucl.ac.uk/internet-grammar/home.htm</tt></a>\n\n", "course_name": "Natural Language Processing", "course_code": "NLP", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/NLP", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "PrincComm": {"supervisions": 6, "lectures": 24, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-PrinciplesofCommunications.html", "description": "\n\n\n<a name=\"SECTION04029100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04029200000000000000\">Lectures</a>\n\n\n<li><b>Introduction.</b>\nCourse overview. Abstraction, layering.\nReview of structure of real networks, links, end systems and switching\nsystems. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Graphs.</b>\nBasic Graph Properties, Different Small Worlds.\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>Routing.</b>\nCentral versus Distributed Routing\nPolicy Routing.\nMulticast Routing\nCircuit Routing\n[6\u00a0lectures]\n\n<p></p></li>\n<li><b>Error control.</b>\nCoding and packet transport [1\u00a0lectures]\n\n<p></p></li>\n<li><b>Flow control and resource optimisation.</b>\nControl theory is a branch of engineering familiar to people building dynamic machines. It can be\napplied to network traffic.\nStemming the flood, at source, sink, or in between? Optimisation as\na model of network&amp; user. TCP in the wild. [3\u00a0lectures]\n\n<p></p></li>\n<li><b>Packet Scheduling.</b>\nDesign choices for scheduling and queue management\nalgorithms for packet forwarding, and fairness.  \n[1\u00a0lectures]\n\n<p></p></li>\n<li><b>Switching.</b>\nWhat does a switch have to do, and how?\n[1\u00a0lectures]\n\n<p></p></li>\n<li><b>Data Centers.</b>\nTopology, Traffic, Control.\n[1\u00a0lectures]\n\n<p></p></li>\n<li><b>Shared media networks, planned and Ad Hoc.</b>\nWe revisit the problem of capacity of a channel \nin the context of a radio network.\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>The big picture for managing traffic.</b>\nEconomics and policy are relevant to networks in many ways.\nOptimisation and game theory are both relevant topics discussed here.\n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>System Structures and Summary.</b>\nAbstraction, layering.\nThe structure of real networks, links, end systems and switching.\n[2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04029300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to explain the\nunderlying design and behaviour of protocols and networks, including capacity,\ntopology, control and use. Several specific mathematical approaches\nare covered (control theory, graph theory).\n\n\n<a name=\"SECTION04029400000000000000\">Recommended reading</a>\n\n* Keshav, S. (2012). <em>Mathematical Foundations of Computer Networking</em>. Addison Wesley. ISBN 9780321792105\n<br/>Background reading:\n<br/>Keshav, S. (1997). <em>An engineering approach to computer networking</em>. Addison-Wesley (1st ed.). ISBN 0201634422\n<br/>Stevens, W.R. (1994). <em>TCP/IP illustrated, vol.\u00a01: the protocols</em>. Addison-Wesley (1st ed.). ISBN 0201633469\n\n\n", "course_name": "Principles of Communications", "course_code": "PrincComm", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/PrincComm", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "QuantComp": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-QuantumComputing.html", "description": "\n\n\n<a name=\"SECTION040210100000000000000\">Aims</a>\n\n\n<a name=\"SECTION040210200000000000000\">Lectures</a>\n\n<li><b>Bits and qubits.</b>\nIntroduction to quantum states and measurements with motivating examples.\nComparison with discrete classical states.\n\n<p></p></li>\n<li><b>Linear algebra.</b>\nReview of linear algebra: vector spaces, linear operators, Dirac\nnotation, tensor product. \n\n<p></p></li>\n<li><b>Quantum mechanics.</b>\nPostulates of quantum mechanics.  Evolution and measurement.\nEntanglement.\n\n<p></p></li>\n<li><b>Quantum computation.</b>\nThe model of quantum computation.  Quantum gates and circuits.\nDeutsch-Jozsa algorithm.\n\n<p></p></li>\n<li><b>Some applications.</b>\nApplications of quantum information:\nquantum key distribution, superdense coding and quantum teleportation.\n\n<p></p></li>\n<li><b>Quantum search.</b>\nGrover\u2019s search algorithm: analysis and lower bounds.\n\n<p></p></li>\n<li><b>Factoring.</b>\nShor\u2019s algorithm for factoring, its analysis.  Quantum\nFourier transform. \n\n<p></p></li>\n<li><b>Quantum complexity.</b>\nQuantum complexity classes and their relationship to classical\ncomplexity.  Comparison with probabilistic computation.\n\n<p></p></li>\n\n\n<a name=\"SECTION040210300000000000000\">Objectives</a>\n\nAt the end of the course students should:\n\n\n<li>understand the quantum model of computation and the basic principles of quantum mechanics;\n\n<p></p></li>\n<li>be familiar with basic quantum algorithms and their analysis;\n\n<p></p></li>\n<li>be familiar with basic quantum protocols such as teleportation and superdense coding;\n\n<p></p></li>\n<li>see how the quantum model relates to classical models of deterministic and probabilistic computation.\n\n<p></p></li>\n\n\n<a name=\"SECTION040210400000000000000\">Recommended reading</a>\n\n<span class=\"textbf\">Books:</span>\nKaye P., Laflamme R., Mosca M. (2007). <em>An Introduction to Quantum Computing</em>. Oxford University Press.\n<br/>Nielsen M.A., Chuang I.L. (2010). <em>Quantum Computation and Quantum Information</em>. Cambridge University Press.\n<br/>Mermin N.D. (2007). <em>Quantum Computer Science: An Introduction</em>. Cambridge University Press.\n<br/>Hirvensalo M. (2001). <em>Quantum Computing</em>. Springer.\n\n\n<span class=\"textbf\">Papers:</span>\nBraunstein S.L. (2003). <em>Quantum computation tutorial</em>. Available at: <tt><a href=\"https://www-users.cs.york.ac.uk/~schmuel/comp/comp_best.pdf\" name=\"tex2html24\">https://www-users.cs.york.ac.uk/~schmuel/comp/comp_best.pdf</a></tt>\n<br/>Aharonov D., Quantum computation [arXiv:quant-ph/9812037]\n<br/>Steane A., Quantum computing [arXiv:quant-ph/9708022]\n\n\n<span class=\"textbf\">Other lecture notes:</span>\nUmesh Vazirani (UC Berkeley):\n<tt><a href=\"http://www-inst.eecs.berkeley.edu/~cs191/sp12/\" name=\"tex2html25\">http://www-inst.eecs.berkeley.edu/~cs191/sp12/</a></tt>\n<br/>John Preskill (Caltech):\n<tt><a href=\"http://www.theory.caltech.edu/people/preskill/ph229/\" name=\"tex2html26\">http://www.theory.caltech.edu/people/preskill/ph229/</a></tt>\n<br/>Andrew Childs (University of Maryland):\n<tt><a href=\"http://cs.umd.edu/~amchilds/qa/\" name=\"tex2html27\">http://cs.umd.edu/~amchilds/qa/</a></tt>\n<br/>John Watrous (University of Waterloo):\n<tt><a href=\"https://cs.uwaterloo.ca/~watrous/TQI/\" name=\"tex2html28\">https://cs.uwaterloo.ca/~watrous/TQI/</a></tt>\n\n", "course_name": "Quantum Computing", "course_code": "QuantComp", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/QuantComp", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "TopConc": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-TopicsinConcurrency.html", "description": "\n\n\n<a name=\"SECTION040211100000000000000\">Aims</a>\n\nThe aim of this course is to introduce fundamental concepts and\ntechniques in the theory of concurrent processes.  It will provide\nlanguages, models, logics and methods to formalise and reason about\nconcurrent systems.\n\n\n<br/>\n<a name=\"SECTION040211200000000000000\">Lectures</a>\n\n\n<li><b>Simple parallelism and nondeterminism.</b>\nDijkstra\u2019s guarded commands. Communication by shared variables:\nA language of parallel commands. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Communicating processes.</b>\nMilner\u2019s Calculus of Communicating Processes (CCS).\nPure CCS. Labelled-transition-system semantics.\nBisimulation equivalence. Equational consequences and examples.\n[3\u00a0lectures]\n\n<p></p></li>\n<li><b>Specification and model-checking.</b>\nThe modal mu-calculus.  Its relation with Temporal Logic, CTL.\nModel checking the modal mu-calculus.  Bisimulation checking.\nExamples. [3\u00a0lectures]\n\n<p></p></li>\n<li><b>Introduction to Petri nets.</b>\nPetri nets, basic definitions and concepts.\nPetri-net semantics of CCS. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Cryptographic protocols.</b>\nCryptographic protocols informally.  A language for cryptographic\nprotocols.  Its Petri-net semantics. Properties of cryptographic\nprotocols: secrecy, authentication.  Examples with proofs of\ncorrectness. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Mobile computation.</b>\nAn introduction to process languages with process passing and name\ngeneration.  [2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION040211300000000000000\">Objectives</a>\n\n<br/>\nAt the end of the course students should\n\n\n<li>know the basic theory of concurrent processes:\nnon-deterministic and parallel commands, the process language CCS, its\ntransition-system semantics, bisimulation, the modal mu-calculus,\nPetri nets, languages for cryptographic protocols and mobile\ncomputation;\n\n<p></p></li>\n<li>be able to \nformalise and to some extent analyse concurrent processes: establish\nbisimulation or its absence in simple cases, express and establish\nsimple properties of transition systems in the modal mu-calculus, \nargue with respect to a process language semantics for secrecy or\nauthentication properties of a small cryptographic protocol, formalise\nmobile computation.\n\n<p></p></li>\n\n\n<br/>\n<a name=\"SECTION040211400000000000000\">Recommended reading</a>\n\n<br/>\nComprehensive notes will be provided.  \n\n\n<br/>Further reading:\n\n<br/>\n* Aceto, L., Ingolfsdottir, A., Larsen,  K.G. &amp; Srba, J. (2007). <em>Reactive systems: modelling, specification and verification</em>. Cambridge University Press.\n<br/>Milner, R. (1989). <em>Communication and concurrency</em>. Prentice Hall. \n<br/>Milner, R. (1999). <em>Communicating and mobile systems: the Pi-calculus</em>. Cambridge University Press.\n<br/>Winskel, G. (1993). <em>The formal semantics of programming languages, an introduction</em>.  MIT Press.\n\n\n", "course_name": "Topics in Concurrency", "course_code": "TopConc", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/TopConc", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "Types": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-Types.html", "description": "\n\n\n<a name=\"SECTION040212100000000000000\">Aims</a>\n\n\n<a name=\"SECTION040212200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b>  The role of type systems in programming\n  languages. Review of rule-based formalisation of type\n  systems. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>ML polymorphism.</b>  ML-style polymorphism. Principal type\n  schemes and type inference. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Polymorphic reference types.</b>  The pitfalls of combining ML\n  polymorphism with reference types. [1\u00a0lecture]\n\n<p></p></li>\n<li><b>Polymorphic lambda calculus (PLC).</b>  Explicit versus\n  implicitly typed languages. PLC syntax and reduction\n  semantics. Examples of datatypes definable in the polymorphic lambda\n  calculus. [3\u00a0lectures]\n\n<p></p></li>\n<li><b>Dependent types.</b> Dependent function types. Pure type\n  systems. System F-omega. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Propositions as types.</b> Example of a non-constructive\n  proof. The Curry-Howard correspondence between intuitionistic\n  second-order propositional calculus and PLC. The calculus of\n  Constructions. Inductive types. [3\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION040212300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to use a rule-based specification of a type system to\n  carry out type checking and type inference;\n\n<p></p></li>\n<li>understand by example the Curry-Howard correspondence between\n  type systems and logics;\n\n<p></p></li>\n<li>appreciate the expressive power of parametric polymorphism and\n  dependent types.\n\n<p></p></li>\n\n\n<a name=\"SECTION040212400000000000000\">Recommended reading</a>\n\n* Pierce, B.C. (2002). <em>Types and programming languages</em>. MIT\nPress.\n<br/>Pierce, B. C. (Ed.) (2005). <em>Advanced Topics in Types and\n  Programming Languages</em>. MIT Press.\n<br/>Girard, J-Y. (tr. Taylor, P. &amp; Lafont, Y.) (1989). <em>Proofs and\n  types</em>. Cambridge University Press. \n\n\n", "course_name": "Types", "course_code": "Types", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/Types", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": true, "lent": false, "easter": false}, "AdvGraph": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-AdvancedGraphics.html", "description": "\n\n\n<a name=\"SECTION04031100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04031200000000000000\">Lectures</a>\n\nThe order of delivery of lectures is provisional and subject to change.\n\n\n<li><b>Graphics hardware.</b> Programmable graphics pipeline, OpenGL and GLSL. [2 lectures]\n\n<p></p></li>\n<li><b>Ray tracing.</b> The fundamentals of raycasting, ray-object intersection, acceleration data structures, supersampling, texture mapping. [2 lectures]\n\n<p></p></li>\n<li><b>Computational geometry.</b> Subdivision surfaces; tessellation; normal at the vertex; skinning, surface reconstruction, surface simplification, isosurfaces. [2 lectures]\n\n<p></p></li>\n<li><b>Global illumination.</b> Radiosity; path tracing; photon mapping; ambient occlusion. [1 lecture]\n\n<p></p></li>\n<li><b>Animation.</b> Key-frames; rigging and skinning; physics-based animation; particle systems. [1 lecture]\n\n<p></p></li>\n<li><b>GPGPU</b> Introduction to OpenCL. [1 lecture] \n\n<p></p></li>\n<li><b>Light, colour, and dynamic range.</b> Color vision; CIE XYZ; chromatic adaptation; photometric units; gamma correction; high dynamic range vs. standard dynamic range; scotopic &amp; photopic vision. [1 lecture]\n\n<p></p></li>\n<li><b>Reflection models</b>. Diffuse, translucent and layered materials; microfacets; BRDF, BSSRDF, BTDF, SVBRDF; BRDF models; subsurface scattering; (SV)-BRDF acquisition. [1 lecture]\n\n<p></p></li>\n<li><b>Advanced image processing.</b> Multi-scale processing; gradient-based methods. [1 lecture]\n\n<p></p></li>\n<li><b>Tone-mapping.</b> Forward and inverse display model; glare and blooming; arithmetic of HDR images; major approaches to tone-mapping. [2 lectures]\n\n<p></p></li>\n<li><b>Applied visual perception.</b> Detection &amp; discrimination; t.v.i. &amp; CSF; simulation of night vision. [1 lecture]\n\n<p></p></li>\n<li><b>Selected topics of computational photography.</b> HDR capture; light fields. [1 lecture]\n\n<p></p></li>\n\n\n<a name=\"SECTION04031300000000000000\">Objectives</a>\n\nOn completing the course, students should be able to\n\n\n<li>program custom vertex and fragment processing with GLSL;\n\n<p></p></li>\n<li>create parallelized code using a GPGPU framework (OpenCL);\n\n<p></p></li>\n<li>describe the underlying theory of subdivision and\n   define the Catmull-Clark and Doo-Sabin subdivision methods;\n\n<p></p></li>\n<li>understand the core technologies of ray tracing, computational geometry, implicit surfaces, and  particle systems;\n\n<p></p></li>\n<li>understand several global illumination technologies such as\n   radiosity, path tracing, photon mapping, ambient occlusion, and be able to discuss each in detail;\n\n<p></p></li>\n<li>discuss and contrast different reflection models;\n\n<p></p></li>\n<li>choose the right animation technique for a given problem and discuss it;\n\n<p></p></li>\n<li>describe current graphics technology and discuss\n   future possibilities;\n\n<p></p></li>\n<li>differentiate between different measures of light and colour, know which measure \nto apply to a particular problem;\n\n<p></p></li>\n<li>choose a tone-mapping algorithm for a given rendering problem;\n\n<p></p></li>\n<li>demonstrate how selected image processing problems can be solved either using multi-scale representation or in the gradient domain; \n\n<p></p></li>\n<li>explain how the limitations of the visual system can be utilized in practical problems in graphics and imaging applications;\n\n<p></p></li>\n<li>explain the concept of light fields and give examples of light field rendering. \n\n<p></p></li>\n\n\n<a name=\"SECTION04031400000000000000\">Recommended reading</a>\n\nStudents should expect to refer to one or more of these books, but\nshould not find it necessary to purchase any of them.\n<br/>* Shirley, P. &amp; Marschner, S. (2009). <em>Fundamentals of Computer Graphics</em>. CRC Press (3rd ed.).\n<br/>Slater, M., Steed, A. &amp; Chrysanthou, Y. (2002). <em>Computer graphics and virtual environments: from realism to real-time</em>. Addison-Wesley.\n<br/>Watt, A. (1999). <em>3D Computer graphics</em>. Addison-Wesley (3rd ed).\n<br/>Rogers, D.F. &amp; Adams, J.A. (1990). <em>Mathematical elements for computer graphics</em>. McGraw-Hill (2nd ed.).\n<br/>Boreskov, A. &amp; Shikin, E. (2013). <em>Computer Graphics: From Pixels to Programmable Graphics Hardware</em>. CRC Press.\n<br/>Reinhard, E., Heidrich, W., Debevec, P., Pattanaik, S. , Ward, G.  &amp; Myszkowski, K. (2010). <em>High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting</em>, 2nd edition. Morgan Kaufmann.\n\n\n\n", "course_name": "Advanced Graphics", "course_code": "AdvGraph", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/AdvGraph", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "CompArch": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComparativeArchitectures.html", "description": "\n\n\n<a name=\"SECTION04032100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04032200000000000000\">Lectures</a>\n\n<li><b>Introduction</b>. \n The impact of technology scaling and market trends.\n\n<p></p></li>\n<li><b>Fundamentals of Computer Design</b>. \n Amdahl\u2019s law, energy/performance trade-offs, ISA design.\n\n<p></p></li>\n<li><b>Advanced pipelining</b>. \n Pipeline hazards; exceptions; optimal pipeline depth; branch prediction;\n the branch target buffer [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Superscalar techniques</b>.  \n Instruction-Level Parallelism\n (ILP); superscalar processor architecture [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Software approaches to exploiting ILP</b>.\n VLIW architectures; local and global instruction scheduling techniques;\n predicated instructions and support for speculative compiler optimisations.\n\n<p></p></li>\n<li><b>Multithreaded processors</b>.\n Coarse-grained, fine-grained, simultaneous multithreading\n\n<p></p></li>\n<li><b>The memory hierarchy</b>.\n Caches; programming for caches; prefetching [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Vector processors</b>.\n Vector machines; short vector/SIMD instruction set extensions; \n stream processing \n\n<p></p></li>\n<li><b>Chip multiprocessors</b>.\n  The communication model; memory consistency models;\n  false sharing; multiprocessor memory hierarchies; cache coherence protocols;\n  synchronization [2\u00a0lectures]\n\n<p></p></li>\n<li><b>On-chip interconnection networks</b>.\n  Bus-based interconnects; on-chip packet switched networks\n\n<p></p></li>\n<li><b>Special-purpose architectures</b>. \n  Converging approaches to computer design\n\n<p></p></li>\n\n\n<a name=\"SECTION04032300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>understand what determines processor design goals;\n\n<p></p></li>\n<li>appreciate what constrains the design process and how\n      architectural trade-offs are made within these\n      constraints;\n\n<p></p></li>\n<li>be able to describe the architecture and operation of pipelined\n      and superscalar processors, including techniques such as \n      branch prediction, register renaming and out-of-order execution;\n\n<p></p></li>\n<li>have an understanding of vector, multithreaded and \n      multi-core processor architectures;\n\n<p></p></li>\n<li>for the architectures discussed, understand what \n      ultimately limits their performance and application domain.\n\n<p></p></li>\n\n\n<a name=\"SECTION04032400000000000000\">Recommended reading</a>\n\n* Hennessy, J. &amp; Patterson, D. (2012). <em>Computer architecture: a quantitative approach</em>. Elsevier (5th ed.) ISBN\u00a09780123838728. (the 3rd and 4th editions are also good) \n\n\n", "course_name": "Comparative Architectures", "course_code": "CompArch", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/CompArch", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "CompSysMod": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComputerSystemsModelling.html", "description": "\n\n\n<a name=\"SECTION04033100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04033200000000000000\">Lectures</a>\n\n\n<li><b>Introduction to modelling.</b>\nOverview of analytic techniques and simulation. Little\u2019s law.\n\n<p></p></li>\n<li><b>Introduction to discrete event simulation.</b>\nBasic approaches and applications to the modelling computer systems.\n\n<p></p></li>\n<li><b>Random number generation methods and simulation techniques.</b> \nStatistical aspects of simulations: confidence intervals,\nstopping criteria, variance reduction techniques. [2\u00a0lectures]\n\n<p></p></li>\n<li><b>Simple stochastic processes.</b> Introduction and examples. \nThe Poisson process. [2\u00a0lectures] \n\n<p></p></li>\n<li><b>Birth-death processes, flow balance equations.</b>\nBirth-death processes and their relation to queueing systems. The\nM/M/1 queue in detail: the equilibrium distribution with conditions for\nexistence and common performance metrics. [2 lectures]\n\n<p></p></li>\n<li><b>Queue classifications, variants on the \nM/M/1 queue and applications to queueing networks.</b>\nExtensions to variants of the M/M/1 queue. Queueing networks. \n[2\u00a0lectures]\n\n<p></p></li>\n<li><b>The M/G/1 queue and its application.</b> The\nPollaczek-Khintchine formula and related performance\nmeasures. [2\u00a0lectures]\n\n<p></p></li>\n\n\n<a name=\"SECTION04033300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to build simple Markov models and \nunderstand the critical modelling assumptions;\n\n<p></p></li>\n<li>be able to solve simple birth-death \nprocesses;\n\n<p></p></li>\n<li>understand that in general as the utilization \nof a system increases towards unity then the response\ntime will tend to increase--often dramatically so;\n\n<p></p></li>\n<li>understand the tradeoffs between different types of\nmodelling techniques;\n\n<p></p></li>\n<li>be aware of the issues in building a simulation of a computer\nsystem and analysing the results obtained.\n\n<p></p></li>\n\n\n<a name=\"SECTION04033400000000000000\">Reference books</a>\n\n* Ross, S.M. (2002). <em>Probability models for computer\n  science</em>. Academic Press.\n<br/>Harchol-Balter, M. (2013). <em>Performance modeling and design of\n  computer systems: queueing theory in action</em>. Cambridge University Press.\n<br/>Jain, A.R. (1991). <em>The art of computer systems performance analysis</em>. Wiley.\n<br/>Kleinrock, L. (1975). <em>Queueing systems, vol. </em>1<em>. Theory</em>. Wiley.\n<br/>Mitzenmacher, M. &amp; Upfal, E. (2005). <em>Probability and computing:\n  randomized algorithms and probabilistic analysis</em>. Cambridge University Press. \n\n\n", "course_name": "Computer Systems Modelling", "course_code": "CompSysMod", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/CompSysMod", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "CompVision": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-ComputerVision.html", "description": "\n\n\n<a name=\"SECTION04034100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04034200000000000000\">Lectures</a>\n\n<li><b>Goals of computer vision; why they are so difficult.</b>\nHow images are formed, and the ill-posed problem of\nmaking 3D inferences from them about objects and their\nproperties. \n\n<p></p></li>\n<li><b>Image sensing, pixel arrays, CCD cameras.</b>\nImage coding and information measures.  Elementary operations on image arrays.\n\n<p></p></li>\n<li><b>Biological visual mechanisms, from retina to cortex.</b>\nPhotoreceptor sampling; receptive field profiles; stochastic impulse \ncodes; channels and pathways.  Neural image encoding operators. \n\n<p></p></li>\n<li><b>Mathematical operations for extracting image structure.</b>\nFinite differences and directional derivatives.\nFilters; convolution; correlation.  2D Fourier domain theorems.\n\n<p></p></li>\n<li><b>Edge detection operators; the information revealed by edges.</b>\nThe Laplacian operator and its zero-crossings.  Logan\u2019s theorem.\n\n<p></p></li>\n<li><b>Multi-scale feature detection and matching.</b>   SIFT\n(scale-invariant feature transform); pyramids. 2D wavelets as visual \nprimitives.  Energy-minimising snakes; active contours.\n\n<p></p></li>\n<li><b>Higher visual operations in brain cortical areas.</b>\nMultiple parallel mappings; streaming and divisions of labour;\nreciprocal feedback through the visual system. \n\n<p></p></li>\n<li><b>Texture, colour, stereo, and motion descriptors.</b>\nDisambiguation and the achievement of invariances. \nImage and motion segmentation.\n\n<p></p></li>\n<li><b>Lambertian and specular surfaces; reflectance maps.</b>\nGeometric analysis of image formation from surfaces.  Discounting the \nilluminant when inferring 3D structure and surface properties.\n\n<p></p></li>\n<li><b>Shape representation.</b>  Inferring 3D shape from shading;\nsurface geometry.  Boundary descriptors; codons.  Object-centred\ncoordinates and the \u201c2.5-Dimensional\" sketch.\n\n<p></p></li>\n<li><b>Perceptual organisation and cognition.</b>  Vision\nas model-building and graphics in the brain.  Learning to see.\n\n<p></p></li>\n<li><b>Lessons from neurological trauma and visual deficits.</b>\nVisual agnosias and illusions, and what they may imply about how vision works.\n\n<p></p></li>\n<li><b>Bayesian inference in vision; knowledge-driven interpretations.</b>  \nClassifiers, decision-making, and pattern recognition.  \n\n<p></p></li>\n<li><b>Model estimation.</b> Machine learning and statistical methods\nin vision.\n\n<p></p></li>\n<li><b>Applications of machine learning in computer vision.</b>  \nDiscriminative and generative methods.  Content based image retrieval.\n\n<p></p></li>\n<li><b>Approaches to face detection, face recognition, and facial\ninterpretation.</b>  Cascaded detectors.  Appearance <em>versus</em> model-based\nmethods (2D and 3D approaches).  \n\n<p></p></li>\n\n\n<a name=\"SECTION04034300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>understand visual processing from both \u201cbottom-up\u201d (data oriented) and\n\u201ctop-down\u201d (goals oriented) perspectives;\n\n<p></p></li>\n<li>be able to decompose visual tasks into sequences of image analysis\noperations, representations, specific algorithms, and inference principles;\n\n<p></p></li>\n<li>understand the roles of image transformations and their invariances\nin pattern recognition and classification;\n\n<p></p></li>\n<li>be able to describe and contrast techniques for extracting and representing\nfeatures, edges, shapes, and textures;\n\n<p></p></li>\n<li>be able to describe key aspects of how biological visual systems work;\nand be able to think of ways in which biological visual strategies might be\nimplemented in machine vision, despite the enormous differences in hardware;\n\n<p></p></li>\n<li>be able to analyse the robustness, brittleness, generalizability,\nand performance of different approaches in computer vision;\n\n<p></p></li>\n<li>understand the roles of machine learning in computer vision today,\nincluding probabilistic inference, discriminative and generative methods; \n\n<p></p></li>\n<li>understand in depth at least one major practical application problem,\nsuch as face recognition, detection, or interpretation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04034400000000000000\">Recommended reading</a>\n\n* Forsyth, D. A. &amp; Ponce, J. (2003).  <em>Computer Vision: A Modern Approach</em>.\nPrentice\u00a0Hall.\n\nShapiro, L. &amp; Stockman, G. (2001).  <em>Computer vision</em>. Prentice\u00a0Hall.\n\n\n", "course_name": "Computer Vision", "course_code": "CompVision", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/CompVision", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "ECommerce": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-E-Commerce.html", "description": "\n\n\n<a name=\"SECTION04035100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04035200000000000000\">Lectures</a>\n\n<li><b>The history of electronic commerce.</b> Mail order; EDI;\n  web-based businesses, credit card processing, PKI, identity and\n  other hot topics.\n\n<p></p></li>\n<li><b>Network economics.</b> Real and virtual networks, supply-side\n  <em>versus</em> demand-side scale economies, Metcalfe\u2019s law, the dominant\n  firm model, the differentiated pricing model Data Protection Act,\n  Distance Selling regulations, business models.\n\n<p></p></li>\n<li><b>Web site design.</b> Stock and price control; domain names,\n  common mistakes, dynamic pages, transition diagrams, content\n  management systems, multiple targets.\n\n<p></p></li>\n<li><b>Web site implementation.</b> Merchant systems, system design\n  and sizing, enterprise integration, payment mechanisms, CRM and help\n  desks. Personalisation and internationalisation.\n\n<p></p></li>\n<li><b>The law and electronic commerce.</b> Contract and tort;\n  copyright; binding actions; liabilities and remedies. Legislation:\n  RIP; Data Protection; EU Directives on Distance Selling and\n  Electronic Signatures.\n\n<p></p></li>\n<li><b>Putting it into practice.</b> Search engine interaction,\n  driving and analysing traffic; dynamic pricing models. Integration\n  with traditional media. Logs and audit, data mining modelling the\n  user. collaborative filtering and affinity marketing brand value,\n  building communities, typical behaviour.\n\n<p></p></li>\n<li><b>Finance.</b> How business plans are put together. Funding\n  Internet ventures; the recent hysteria; maximising shareholder\n  value. Future trends.\n\n<p></p></li>\n<li><b>UK and International Internet Regulation.</b> Data Protection\n  Act and US Privacy laws; HIPAA, Sarbanes-Oxley, Security Breach\n  Disclosure, RIP Act 2000, Electronic Communications Act 2000,\n  Patriot Act, Privacy Directives, data retention; specific issues:\n  deep linking, Inlining, brand misuse, phishing.\n\n<p></p></li>\n\n<br/>\n<a name=\"SECTION04035300000000000000\">Objectives</a>\n\nAt the end of the course students should know how to apply their\ncomputer science skills to the conduct of e-commerce with some\nunderstanding of the legal, security, commercial, economic, marketing\nand infrastructure issues involved.\n\n<br/>\n<a name=\"SECTION04035400000000000000\">Recommended reading</a>\n\nShapiro, C. &amp; Varian, H. (1998). <em>Information rules</em>. Harvard Business School Press.\n\nAdditional reading:\n\nStandage, T. (1999). <em>The Victorian Internet</em>. Phoenix Press.\nKlemperer, P. (2004). <em>Auctions: theory and practice</em>. Princeton Paperback ISBN 0-691-11925-2.\n\n\n", "course_name": "E-Commerce", "course_code": "ECommerce", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/ECommerce", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "InfoRtrv": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-InformationRetrieval.html", "description": "\n\n\n<a name=\"SECTION04036100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04036200000000000000\">Lectures</a>\n\n<li><b>Introduction.</b> (Chapters 1; 2.3)\n Key problems and concepts. Information need. Boolean Operators. \n\n<p></p></li>\n<li><b>Boolean Retrieval and Indexing.</b> (Chapters 2.2; 2.4)  and\n Implementation of Boolean Operators. Term manipulations; equivalence\n classes, stemming.  \n\n<p></p></li>\n<li><b>Index representation and Tolerant Retrieval.</b> (Chapter\n   3, 4.2-4.4). Index construction. Wildcards. Spelling Correction. \n\n<p></p></li>\n<li><b>The Vector Space Model.</b> (Chapter 6). VSM and Term weighting. \n\n<p></p></li>\n<li><b>Language Models for Information Retrieval and Classification.</b> (Chapters 12; 13). Query-likelihood, Smoothing. Naive Bayes Classification.\n\n<p></p></li>\n<li><b>Evaluation.</b> (Chapter 8, p. 139-148).  Test\n   Collections. Relevance. Precision, Recall, MAP, 11pt interpolated\n   average precision.\n\n<p></p></li>\n<li><b>Relevance Feedback and Query Expansion</b> (Chapters 9, 11.3.4). Rocchio algorithm, Relevance models, Expansion Techniques. \n\n<p></p></li>\n<li><b>Link Analysis.</b> (Chapter 21.1, 21.2).\n PageRank.\n\n<p></p></li>\n\n\n<a name=\"SECTION04036300000000000000\">Objectives</a>\n\nAt the end of this course, students should be able to\n\n\n<li>define the tasks of information retrieval, web search and\n  classification, and the differences between them;\n\n<p></p></li>\n<li>understand the main concepts, challenges and strategies used in\n  IR, in particular the retrieval models currently used.\n\n<p></p></li>\n<li>develop strategies suited for specific retrieval and\n  classification situations, and recognise the limits of these strategies;\n\n<p></p></li>\n<li>understand (the reasons for) the evaluation strategies developed\n  for the tasks covered.\n\n<p></p></li>\n\n\n<a name=\"SECTION04036400000000000000\">Recommended reading</a>\n\n* Manning, C.D., Raghavan, P. &amp; Sch\u00fctze, H. (2008). <em>Introduction to information retrieval</em>. Cambridge University Press.  Available at <a href=\"http://nlp.stanford.edu/IR-book/\" name=\"tex2html29\"><tt>http://nlp.stanford.edu/IR-book/</tt></a>.\n\n\n\n", "course_name": "Information Retrieval", "course_code": "InfoRtrv", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/InfoRtrv", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "MLBayInfer": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-MachineLearningandBayesianInference.html", "description": "\n\n\n<a name=\"SECTION04037100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04037200000000000000\">Lectures</a>\n\n<li><b>Introduction to learning and inference.</b> Supervised,\nunsupervised, semi-supervised and reinforcement learning. Bayesian\ninference in general. What the naive Bayes method actually does.\nReview of backpropagation. Other kinds of learning and inference.\n</li>\n<li><b>How to classify optimally.</b> Treating learning\nprobabilistically. Bayesian decision theory and Bayes optimal\nclassification. Generative and discriminativemodels. Likelihood\nfunctions and priors. Bayes theorem as applied to supervised learning.\nThe maximum likelihood and maximum a posteriori hypotheses. What does\nthis teach us about the backpropagation algorithm?\n</li>\n<li><b>Linear classifiers I.</b> Supervised learning via error\nminimization. Iterative reweighted least squares.  The maximum margin\nclassifier.\n</li>\n<li><b>Support vector machines (SVMs).</b> The kernel trick. Problem\nformulation. Constrained optimization and the dual problem. SVM\nalgorithm.\n</li>\n<li><b>Practical issues.</b> Hyperparameters. Measuring performance.\nCross-validation. Experimental methods.  Multiple classes.\n</li>\n<li><b>Linear classifiers II.</b> The Bayesian approach to neural networks.\n</li>\n<li><b>Gaussian processes.</b> Learning and inference for regression\nusing Gaussian process models.\n</li>\n<li><b>Unsupervised learning I.</b> The k-means algorithm. Clustering\nas a maximum likelihood problem.\n</li>\n<li><b>Unsupervised learning II.</b> The EM algorithm and its\napplication to clustering.\n</li>\n<li><b>Deep networks.</b> Combining unsupervised and supervised\ntraining. Convolutional networks.\n</li>\n<li><b>Semi-supervised learning.</b>\n</li>\n<li><b>Reinforcement learning I.</b> Learning from rewards and\npunishments. Markov decision processes.  The problems of temporal\ncredit assignment and exploration versus exploitation.\n</li>\n<li><b>Reinforcement Learning II.</b> Q-learning and its convergence.\nHow to choose actions.\n</li>\n<li><b>Bayesian networks I.</b> Representing uncertain knowledge using\nBayesian networks. Conditional independence. Exact inference in\nBayesian networks.\n</li>\n<li><b>Bayesian networks II.</b> Markov random fields. Approximate\ninference. Markov chain Monte Carlo methods.\n</li>\n<li><b>Uncertain reasoning over time.</b> Markov processes, transition and\nsensor models. Hidden Markov models (HMMs). Inference in temporal models:\nfiltering, prediction, smoothing and finding the most likely explanation.\nThe Viterbi algorithm.\n</li>\n\n\n<a name=\"SECTION04037300000000000000\">Objectives</a>\n\nAt the end of this course students should:\n\n\n<li>Understand how learning and inference can be captured within a\nprobabilistic framework, and know how probability theory can be\napplied in practice as a means of handling uncertainty in AI systems.\n\n<p></p></li>\n<li>Understand several state-of-the-art algorithms for machine\nlearning and apply those methods in practice with proper regard for\ngood experimental practice.\n</li>\n\n\n<a name=\"SECTION04037400000000000000\">Recommended reading</a>\n\nIf you are going to buy a single book for this course we recommend:\n\n* Bishop, C.M. (2006). <span class=\"textit\">Pattern recognition and machine learning</span>.\nSpringer.\n<br/>These cover some relevant material, but often in insufficient detail:\n\nMitchell, T.M. (1997). <span class=\"textit\">Machine Learning</span>. McGraw-Hill.\n<br/>Russell, S. &amp; Norvig, P. (2010). <span class=\"textit\">Artificial intelligence: a\nmodern approach</span>. Prentice\u00a0Hall (3rd ed.).\n<br/>Recently a few new books have appeared that cover a lot of relevant ground\nwell:\n\nBarber, D. (2012). <span class=\"textit\">Bayesian Reasoning and Machine Learning</span>.\nCambridge University Press.\n<br/>Flach, P. (2012). <span class=\"textit\">Machine Learning: The Art and Science of Algorithms\nthat Make Sense of Data</span>. Cambridge University Press.\n<br/>Murphy, K.P. (2012). <span class=\"textit\">Machine Learning: A Probabilistic Perspective</span>.\nMIT Press.\n<br/>\n", "course_name": "Machine Learning and Bayesian Inference", "course_code": "MLBayInfer", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/MLBayInfer", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "MobSensSys": {"supervisions": 2, "lectures": 8, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-MobileandSensorSystems.html", "description": "\n\n\n<a name=\"SECTION04038100000000000000\">Aims</a>\n\n<a name=\"SECTION04038200000000000000\">Lectures</a>\n\n\n<li><b>Introduction to Mobile Systems. MAC Layer concepts.</b>\nExamples of mobile systems, differences with non mobile systems. \nIntroduction to MAC layer protocols of wireless and mobile systems.\n\n<p></p></li>\n<li><b>Mobile Infrastructure Communication  and Opportunistic Networking.</b>\nDescription of common communication architectures and protocols for mobile and introduction to models of opportunistic networking.\n\n<p></p></li>\n<li><b>Introduction to Sensor Systems and MAC Layer concepts.</b>\nSensor systems challenges and applications. Concepts related to duty cycling and energy preservation protocols.\n\n<p></p></li>\n<li><b>Sensor Systems Routing Protocols.</b>\nCommunication protocols, data aggregation and dissemination in sensor \nnetworks. Sensor Reprogramming and Management.\n\n<p></p></li>\n<li><b>Mobile Sensing: Modelling and Inference</b>\nMobile and wearable sensing. Inference of activity.  Modelling.\n\n<p></p></li>\n<li><b>Mobile Sensing: Systems Considerations</b>\nConsiderations of energy preservation.  Local computation vs cloud computation. \n\n<p></p></li>\n<li><b>Privacy in Mobile and Sensor Systems</b>\nConcepts of location privacy. Privacy and sensor based activity inference. \n\n<p></p></li>\n<li><b>Internet of Things and Sensor Integration</b>\nProtocols for networking in IoT. Sensor fusion in IoT. Examples.\n</li>\n\n\n<a name=\"SECTION04038300000000000000\">Objectives</a>\n\nOn completing the course, students should be able to\n\n\n<li>describe similarities and differences between standard\n distributed systems and mobile and sensor systems;\n\n<p></p></li>\n<li>explain the fundamental tradeoffs related to energy limitations\n and communication needs in these systems;\n\n<p></p></li>\n<li>argue for and against different mobile and sensor systems\n architectures and protocols.\n\n<p></p></li>\n\n\n<a name=\"SECTION04038400000000000000\">Recommended reading</a>\n\n* Schiller, J. (2003). <em>Mobile communications</em>. Pearson (2nd ed.).\n<br/>* Karl, H. &amp; Willig, A. (2005). <em>Protocols and architectures for wireless sensor networks</em>. Wiley.\n<br/>Agrawal, D. &amp; Zheng, Q. (2006). <em>Introduction to wireless and mobile systems</em>. Thomson.\n\n\n", "course_name": "Mobile and Sensor Systems", "course_code": "MobSensSys", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/MobSensSys", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "OptComp": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-OptimisingCompilers.html", "description": "\n\n\n<a name=\"SECTION04039100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04039200000000000000\">Lectures</a>\n\n<li><b>Introduction and motivation.</b>\nOutline of an optimising compiler.\nOptimisation partitioned: <i>analysis</i> shows a property holds\nwhich enables a <em>transformation</em>.\nThe flow graph; representation of programming concepts including argument\nand result passing.\nThe phase-order problem.\n\n<p></p></li>\n<li><b>Kinds of optimisation.</b>\nLocal optimisation: peephole optimisation, instruction scheduling.\nGlobal optimisation: common sub-expressions, code motion.\nInterprocedural optimisation.\nThe call graph.\n\n<p></p></li>\n<li><b>Classical dataflow analysis.</b>\nGraph algorithms, <em>live</em> and <em>avail</em> sets.\nRegister allocation by register colouring.\nCommon sub-expression elimination.\nSpilling to memory; treatment of CSE-introduced temporaries.\nData flow anomalies.\nStatic Single Assignment (SSA) form.\n\n<p></p></li>\n<li><b>Higher-level optimisations.</b>\nAbstract interpretation,  Strictness analysis.\nConstraint-based analysis, Control flow analysis for lambda-calculus.\nRule-based inference of program properties,\nTypes and effect systems.\nPoints-to and alias analysis.\n\n<p></p></li>\n<li><b>Target-dependent optimisations.</b>\nInstruction selection.\nInstruction scheduling and its phase-order problem.\n\n<p></p></li>\n<li><b>Decompilation.</b>\nLegal/ethical issues.\nSome basic ideas, control flow and type reconstruction.\n</li>\n\n\n<a name=\"SECTION04039300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n<li>be able to explain program analyses as dataflow equations on a\nflowgraph;\n\n<p></p></li>\n<li>know various techniques for high-level optimisation of programs\nat the abstract syntax level;\n\n<p></p></li>\n<li>understand how code may be re-scheduled to improve execution speed;\n\n<p></p></li>\n<li>know the basic ideas of decompilation.\n\n<p></p></li>\n\n\n<a name=\"SECTION04039400000000000000\">Recommended reading</a>\n\n* Nielson, F., Nielson, H.R. &amp; Hankin, C.L. (1999).  <em>Principles of program analysis</em>. Springer. Good on part A and part B.\n<br/>Appel, A. (1997). <em>Modern compiler implementation in Java/C/ML</em>  (3 editions).\n<br/>Muchnick, S. (1997). <em>Advanced compiler design and implementation</em>.  Morgan Kaufmann.\n<br/>Wilhelm, R. (1995). <em>Compiler design</em>. Addison-Wesley.\n<br/>Aho, A.V., Sethi, R. &amp; Ullman, J.D. (2007). <em>Compilers:  principles, techniques and tools</em>. Addison-Wesley (2nd ed.).\n\n", "course_name": "Optimising Compilers", "course_code": "OptComp", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/OptComp", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "SecurityII": {"supervisions": 4, "lectures": 16, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-SecurityII.html", "description": "\n\n\n<a name=\"SECTION040310100000000000000\">Aims</a>\n\n\n<a name=\"SECTION040310200000000000000\">Lectures</a>\n\nPart 1: Security Engineering [lecturer: Frank Stajano and others]\n\n\n<li><b>Security, human factors and psychology.</b> Usability failures.\n  Incompatibility between security requests and work practices.\n  Thinking like an attacker/victim. Social engineering. Phishing. Why\n  do scams work? Social psychology. Decision under risk. Prospect\n  theory as a critique of Expected Utility theory. Framing.\n<br/>  [Refs: \u201cWhy Johnny can\u2019t encrypt\u201d, \u201cUsers are not the enemy\u201d,\n  <span class=\"textit\">The art of deception</span>, \u201cUnderstanding scam victims\u201d,\n  <span class=\"textit\">Influence: science and practice</span>, \u201cThe compliance budget\u201d,\n  \u201cMaps of bounded rationality\u201d] [2.5 lectures]\n\n<p></p></li>\n<li><b>Security policies.</b> Terminology: policy, profile, target.\n  Vaporware policies. Influential security policies: Bell-LaPadula\n  (multi-level security, lattices, covert channels, downgrading),\n  Biba, Clark-Wilson (double-entry bookkeeping, separation of duties),\n  Resurrecting Duckling (ubiquitous computing, bootstrapping a\n  security association). [1.5 lectures]\n\n<p></p></li>\n<li><b>Passwords.</b> Usability and security problems of passwords.\n  Taxonomy of replacement schemes and their salient features. Why\n  passwords continue to dominate. [Refs: \u201cThe quest to replace\n  passwords\u201d, \u201cPico: no more passwords\u201d, \u201cThe password thicket\u201d].\n\n<p></p></li>\n<li><b>Physical security.</b> Relevance in systems security\n  context. Pin tumbler locks. Lockpicking. Bumping. \u201cCryptology and\n  physical security: rights amplification in master-keyed mechanical\n  locks\u201d. Burglar alarms. Sensor defeats; feature interactions;\n  attacks on communications; attacks on trust.\n\n<p></p></li>\n<li><b>Security economics.</b>  Why is security management hard?\n  Misaligned incentives. Asymmetric\n  information. Externalities. Adverse selection. Case studies:\n  security seals, markets for vulnerabilities, phishing website\n  takedown, cost of cybercrime.\n\n<p></p></li>\n<li><b>Anonymity and censorship resistance.</b>  Censorship on the\n  web: goals, technology (DNS tampering, IP blocking etc). Blocking\n  through laws or intimidation. Why privacy and anonymity? Remailers,\n  mix networks, attacks. Censorship resistance tools and their\n  architecture: Tor, Freenet, Psiphon.\n\n<p></p></li>\n\nPart 2: Cryptography [lecturer: Markus Kuhn]\n\n\n<li><b>Secure hash functions.</b> One-way functions, collision\n  resistance, Merkle-Damg\u00e5rd construction, padding, MD5, SHA.\n\n<p></p></li>\n<li><b>Applications of secure hash functions.</b> HMAC, stream\n  authentication, Merkle tree, commitment protocols.\n\n<p></p></li>\n<li><b>Key distribution problem.</b> Needham-Schroeder protocol,\n  Kerberos, hardware-security modules, public-key encryption schemes,\n  CPA and CCA security for asymmetric encryption.\n\n<p></p></li>\n<li><b>Number theory and finite groups.</b>\n  Modular arithmetic, greatest common divisor,\n  Euclid\u2019s algorithm, modular inversion, groups, rings, fields, finite\n  groups, cyclic groups, generators, Euler\u2019s theorem, Chinese\n  remainder theorem, modular roots, subgroup of quadratic residues,\n  modular exponentiation, easy and difficult problems. [2 lectures]\n\n<p></p></li>\n<li><b>Discrete logarithm problem.</b> Diffie-Hellman key exchange,\n  ElGamal encryption, hybrid cryptography, elliptic-curve systems.\n\n<p></p></li>\n<li><b>Trapdoor permutations.</b> Security definition, turning one\n  into a public-key encryption scheme, RSA, attacks on \u201ctextbook\u201d\n  RSA, RSA as a trapdoor permutation, optimal asymmetric encryption\n  padding, common factor attacks.\n\n<p></p></li>\n<li><b>Digital signatures.</b> one-time signatures, ElGamal\n  signatures, DSA, RSA signatures, Certificates, PKI.\n\n<p></p></li>\n\n\n<a name=\"SECTION040310300000000000000\">Objectives</a>\n\nAt the end of the course students should be able to tackle an\ninformation protection problem by drawing up a threat model,\nformulating a security policy, and designing specific protection\nmechanisms to implement the policy. They also should understand the\nproperties and main applications of secure hash functions, as well as\nthe properties of, and some implementation options for, asymmetric\nciphers and signature schemes, based on the discrete-logarithm and RSA\nproblems.\n\n\n<a name=\"SECTION040310400000000000000\">Recommended reading</a>\n\n* Anderson, R. (2008). <em>Security engineering</em>. Wiley (2nd\ned.). Freely downloadable in PDF from <a href=\"http://www.cl.cam.ac.uk/users/rja14/book.html\" name=\"tex2html30\"><tt>http://www.cl.cam.ac.uk/users/rja14/book.html</tt></a>\n<br/>* Katz, J., Lindell, Y. (2015). <em>Introduction to modern cryptography</em>. Chapman &amp; Hall/CRC (2nd ed.).\n\nFurther reading:\n<br/>Gollmann, D. (2010). <em>Computer security</em>. Wiley (3rd ed.).\n<br/>Cialdini, R. (2008). <em>Influence: science and practice</em>. Pearson\n(5th ed.)\n<br/>Stajano, F. (2002). <em>Security for ubiquitous computing</em>. Wiley.\n<br/>Kahneman, D. (2012). <em>Thinking fast and slow</em>. Penguin.\n\n\n", "course_name": "Security\u00a0II", "course_code": "SecurityII", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/SecurityII", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "SysOnChip": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-System-on-ChipDesign.html", "description": "\n\n\n<a name=\"SECTION040311100000000000000\">Aims</a>\n\nIn this course we examine the basic energy and performance metrics for\ntoday\u2019s chip multi-processors (CMPs), caches, busses and DRAM banks and examine\nthe need for, design of and integration of custom accelerators. We briefly visit\nall of the IP blocks found on a typical SoC, as used in the Raspberry Pi. We look\nat the future of reconfigurable computing and the role of FPGA in the datacentre.\n\nExamples will assume knowledge of three languages, C, Verilog and assembly language but not require any degree of proficiency in these languages.\n\n\n<a name=\"SECTION040311200000000000000\">Lecture Topics</a>\n\n<li><b>Current-day SoC Tour of IP Blocks.</b>  CPU, Co-processor, Cache, Counter/timers, DRAM controller, interrupt dispatcher, I/O devices.\n\n<p></p></li>\n<li><b>Masked versus Configurable Logic.</b>  Chip design flow. Field programmable gate array (FPGA) with hardened IP blocks. Zynq example.\n\n<p></p></li>\n<li><b>Energy use in Digital Hardware.</b>  Energy and delay tradeoff. Computation versus communication. Switching activity, DVFS, DRAM.\n\n<p></p></li>\n<li><b>Register Transfer Language.</b>  RTL simulation and logic synthesis. Structural hazards. Critical Path. Pipelining.\n\n<p></p></li>\n<li><b>High-level Synthesis (HLS).</b> Goals, tool structure, profile-directed feedback, examples.\n\n<p></p></li>\n<li><b>Architectural Exploration.</b>  High-level modelling to predict energy use and performance. Transactional modelling.\n\n<p></p></li>\n<li><b>System Specification and Validation.</b> Bus protocols, formal specification, design environments and glue-logic synthesis.\n\n<p></p></li>\n\nCompared with last year, the following changes have been made: SystemC and PSL de-emphasised. Co-design and device drivers removed. HLS and FPGA emphasised.\n\n\n<a name=\"SECTION040311300000000000000\">Objectives</a>\n\nBy the end of the course you should have a working knowledge of the problems faced\nby today\u2019s hardware engineers designing mobile phones and server blades.  You should\nunderstand how energy is used in computing systems and the tensions between general-purpose, fixed-function\nand reconfigurable hardware.\n\n\n<a name=\"SECTION040311400000000000000\">Recommended reading</a>\n\n* Keating, M. (2011). <span class=\"textit\">The Simple art of SoC design</span>. Springer. ISBN 9781441985859.\n<br/>* OSCI. <span class=\"textit\">SystemC tutorials and whitepapers</span>. Download from OSCI <tt><a href=\"http://accellera.org/community/systemc\" name=\"tex2html31\">http://accellera.org/community/systemc</a></tt> or copy from course web site.\n<br/>Ghenassia, F. (2010). <span class=\"textit\">Transaction-level modeling with SystemC: TLM concepts and applications for embedded systems</span>. Springer.\n<br/>Eisner, C. &amp; Fisman, D. (2006). <span class=\"textit\">A practical introduction to PSL</span>. Springer (Series on Integrated Circuits and Systems).\n<br/>Foster, H.D. &amp; Krolnik, A.C. (2008). <span class=\"textit\">Creating assertion-based IP</span>. Springer (Series on Integrated Circuits and Systems).\n<br/>Grotker, T., Liao, S., Martin, G. &amp; Swan, S. (2002). <span class=\"textit\">System design with SystemC</span>. Springer.\n<br/>Wolf, W. (2009). <span class=\"textit\">Modern VLSI design (System-on-chip design)</span>. Pearson Education (4th ed.).\n\n\n", "course_name": "System-on-Chip Design", "course_code": "SysOnChip", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/SysOnChip", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "TopIssues": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-TopicalIssues.html", "description": "\n\n\n<a name=\"SECTION040312100000000000000\">Aims</a>\n\n\n<a name=\"SECTION040312200000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>realise that the range of issues affecting the computer\n  community is very broad;\n\n<p></p></li>\n<li>be able to take part in discussions on several subjects at the\nfrontier of modern computer engineering.\n\n<p></p></li>\n\n\n", "course_name": "Topical Issues", "course_code": "TopIssues", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/TopIssues", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": true, "easter": false}, "AdvAlgo": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-AdvancedAlgorithms.html", "description": "\n\n\n<a name=\"SECTION04041100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04041200000000000000\">Lectures</a>\n\n\n<li><b>Sorting Networks.</b> Zero-one principle. Merging Network, Bitonic\nSorter. [CLRS2, Chapter 27]\n\n<p></p></li>\n<li><b>Parallel Algorithms.</b> Dynamic multithreading. Modelling framework:\nwork and span. Greedy scheduler. [CLRS3, Chapter 27]\n\n<p></p></li>\n<li><b>Matrix Multiplication.</b> Strassen\u2019s algorithm. Parallel Matrix\nMultiplication. [CLRS3, Chapters 4, 27 and 28]\n\n<p></p></li>\n<li><b>Linear Programming.</b> Definitions and Applications. Formulating\nLinear Programs. The Simplex Algorithm. Finding Initial Solutions.\n[CLRS3, Chapter 29]\n\n<p></p></li>\n<li><b>Approximation Algorithms.</b> (Fully) Polynomial-Time Approximation\nSchemes. Design Techniques. Applications: Vertex Cover, Subset-Sum, Parallel\nMachine Scheduling, Travelling Salesman Problem (including a practical\ndemonstration how to solve a TSP instance exactly using linear programming),\nHardness of Approximation. [CLRS3, Chapter 35]\n\n<p></p></li>\n<li><b>Randomised Approximation Algorithms.</b> Randomised Approximation\nSchemes. Linearity of Expectations and Randomised Rounding of Linear Programs.\nApplications: MAX3-CNF problem, Weighted Vertex Cover, Weighted Set Cover.\n[CLRS3, Chapter 35]\n\n<p></p></li>\n\n\n<a name=\"SECTION04041300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>have an understanding of algorithm design for\nparallel computers;\n\n<p></p></li>\n<li>be able to formulate, analyse and solve linear programs;\n\n<p></p></li>\n<li>have learned a variety of tools to design efficient (approximation) algorithms.\n\n<p></p></li>\n\n\n<a name=\"SECTION04041400000000000000\">Recommended reading</a>\n\n* Cormen, T.H., Leiserson, C.D., Rivest, R.L. &amp; Stein,\nC. (2009). <em>Introduction to Algorithms</em>. MIT Press (3rd ed.). ISBN\n978-0-262-53305-8\n<br/>\n", "course_name": "Advanced Algorithms", "course_code": "AdvAlgo", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/AdvAlgo", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "BusSeminrs": {"supervisions": null, "lectures": 8, "prerequisite_for": [], "past_exam_questions": null, "description": "\n\n\n<a name=\"SECTION04042100000000000000\">Aims</a>\n\n\n<a name=\"SECTION04042200000000000000\">Lectures</a>\n\nEight lectures by eight different entrepreneurs.\n\n\n<a name=\"SECTION04042300000000000000\">Objectives</a>\n\nAt the end of the course students should have a better knowledge of the\npleasures and pitfalls of starting a high tech company.\n\n\n<a name=\"SECTION04042400000000000000\">Recommended reading</a>\n\nLang, J. (2001). <em>The high-tech entrepreneur\u2019s handbook: how to start and run a high-tech company</em>. FT.COM/Prentice Hall.\n<br/>Maurya, A. (2012). <em>Running Lean: Iterate from Plan A to a Plan That Works</em>. O\u2019Reilly.\n<br/>Osterwalder, A. &amp; Pigneur, Y. (2010). <em>Business Model Generation: A Handbook for Visionaires, Game Changers, and Challengers</em>. Wiley.\n<br/>Kim, W. &amp; Mauborgne, R. (2005). <em>Blue Ocean Strategy</em>.  Harvard Business School Press.\n\nSee also the additional reading list on the Business Studies web page.\n\n\n", "course_name": "Business Studies Seminars", "course_code": "BusSeminrs", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/BusSeminrs", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}, "HLog+ModC": {"supervisions": 3, "lectures": 12, "prerequisite_for": [], "past_exam_questions": "http://www.cl.cam.ac.uk/teaching/exams/pastpapers/t-HoareLogicandModelChecking.html", "description": "\n\n\n<a name=\"SECTION04043100000000000000\">Aims</a>\n\nOne main aim is to introduce Hoare logic for a simple imperative language\nand then to show how it can be used to formally specify programs\n(along with discussion of soundness and completeness),\nand also how to use it in a mechanised program verifier.\n\nThe second thrust is to introduce temporal properties, show how\nthese can describe the behaviour of systems, and finally to\nintroduce model-checking algorithms which\ndetermine whether properties hold or find counter-examples.\n\nCurrent research trends also will be outlined.\n\n\n<a name=\"SECTION04043200000000000000\">Lectures</a>\n\n<li><b>Part 1: Formal specification of imperative programs.</b>  \nFormal versus informal methods. Specification using preconditions and\npostconditions.\n\n<p></p></li>\n<li><b>Axioms and rules of inference.</b>  \nHoare logic for a simple language with assignments, sequences,\nconditionals and while-loops.  Syntax-directedness.\n\n<p></p></li>\n<li><b>Loops and invariants.</b>  \nVarious examples illustrating loop invariants and how they can be\nfound. <tt>FOR</tt>-loops and derived rules.  Arrays and aliasing.\n\n<p></p></li>\n<li><b>Partial and total correctness.</b>  \nHoare logic for proving termination. Variants.\n\n<p></p></li>\n<li><b>Semantics, metatheory, mechanisation</b>\nMathematical interpretation of Hoare logic.\nSoundness, completeness and decidability.\nAssertions, annotation and verification conditions.\nWeakest preconditions and strongest postconditions;\ntheir relationship to Hoare logic and its mechanisation.\n\n<p></p></li>\n<li><b>Additional topics.</b>  \nDiscussion of correct-by-construction methods versus post-hoc\nverification. Proof of correctness versus property checking. Recent\ndevelopments in Hoare logic such as separation logic.\n\n<p></p></li>\n<li><b>Part 2: Specifying state transition systems.</b>\nRepresentation of state spaces. Reachable states. \n\n<p></p></li>\n<li><b>Checking reachability properties.</b>\nFixed-point calculations. Symbolic methods using binary decision\ndiagrams. Finding counter-examples.\n\n<p></p></li>\n<li><b>Examples.</b>\nVarious uses of reachability calculations.\n\n<p></p></li>\n<li><b>Temporal properties and logic</b>.\nLinear and branching time. Intervals. Path quantifiers.\nBrief history.  CTL and LTL.  PSL for clocked hardware.\n\n<p></p></li>\n<li><b>Model checking.</b>\nSimple algorithms for verifying that temporal properties\nhold. Reachability analysis as a special case.\n\n<p></p></li>\n<li><b>Applications and more recent developments</b>\nSimple software and hardware examples.\nCEGAR (counter-example guided abstraction refinement).\n\n<p></p></li>\n\n\n<a name=\"SECTION04043300000000000000\">Objectives</a>\n\nAt the end of the course students should\n\n\n<li>be able to prove simple programs correct by hand and implement a\n  simple program verifier;\n\n<p></p></li>\n<li>be familiar with the theory and use of Hoare logic and its mechanisation;\n\n<p></p></li>\n<li>be able to write properties in a variety of temporal logics;\n\n<p></p></li>\n<li>be familiar with the core ideas of model checking.\n\n<p></p></li>\n\n\n<a name=\"SECTION04043400000000000000\">Recommended reading</a>\n\nHuth, M. &amp; Ryan M. (2004). <em>Logic in Computer Science: Modelling and Reasoning about Systems</em>. Cambridge University Press (2nd ed.).\n\n\n\n", "course_name": "Hoare Logic and Model Checking", "course_code": "HLog+ModC", "course_url": "https://www.cl.cam.ac.uk/teaching/1617/HLog+ModC", "lecturers": [], "year": "1617", "tripos_part": "2", "michaelmas": false, "lent": false, "easter": true}}